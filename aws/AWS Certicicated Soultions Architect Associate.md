# AWS Certificated Solutions Architect Associate

**AWS 자격증 Udemy 강의 요약** 



# Section 04. IAM

### IAM Section 

- IAM: Idenitity and Access Management => 글로벌 서비스
- 루트 계정
  - 기본으로 생성
  - 오직 계정을 생성할 때만 사용되어야 하며, 그 후에는 루트 계정을 더 이상 사용해서도, 공유해서도 안됨
- 사용자 생성
  - 하나의 사용자는 조직 내의 한 사람에 해당
  - 필요하다면 사용자들을 그룹으로 묶을 수 있음
- 그룹
  - 그룹에는 사용자만 배치할 수 있으며, 다른 그룹을 포함시킬 순 없음
  - 하나의 사용자가 다수의 그룹에 속할 수도 있음
- IAM: Permission
  - 사용자 또는 그룹에게 정책, 또는 IAM이라고 불리는 JSON 문서를 지정할 수 있음
  - 이 정책들을 사용해 사용자들의 권한을 정의할 수 있게 됨
  - AWS에서는 모든 사용자에게 모든 권한을 허용하지 않음 => 보안 문제 및 비용 문제
  - 최소 권한의 원칙을 적용
    - 사용자가 꼭 필요로 하는 것 이상의 권한을 주지 않음



### IAM Policies

- IAM Pocicies Structure

  - 구성 요소

    - Version: 정책 언어 버전, 항상 '2012-10-17'이 포함
    - Id: 정책을 식별하는 ID (optional)
    - Statement: 한개 이상의 문장 (required)

  - Statement의 구성 요소

    - Sid: 문장 ID로 문장의 식별자 (optional)
    - 효과(Effect): 문장이 특정 API에 접근하는걸 허용할지 거부할지에 대한 내용 (Allow / Deny)
    - 원칙(Principal): 특정 정책이 적용될 사용자, 계정, 혹은 역할로 구성
    - 조치(Action): effect에 기반해 허용 및 거부되는 API 호출의 목록
    - 리소스(Resource): 적용될 action의 리소스 목록
    - 컨디션(Condition): statement가 언제 적용될지를 결정 (optional)

    ```json
    {
      "Version": "2012-10-17",
      "Id": "S3-Account-Permissions",
      "Statememt": [
        {
          "Sid": "1",
          "Effect": "Allow",
          "Pricipal": {
            "AWS": ["arn:aws:iam:123456789012:root"]
          },
          "Action": [
            "s3:GetObject",
            "s3:PutObject"
          ],
          "Resource": ["arn:aws:s3::mybucket/*"]
        }
      ]
    }
    ```



### IAM MFA

- Password Policy
  - Strong passwords = 계정의 보안을 높여줌
  - AWS password policy 세팅 방법
    - 비밀번호 최소 길이 설정
    - 특정 유형의 글자 사용 요구
    - IAM 사용자들의 비밀번호 변경 허용 및 금지
    - 일정 기간이 지나면 새 비밀번호 설정 요구
    - 사용자의 비밀번호 재사용을 막기
- MFA (Multi Factor Authentication)
  - 유저들은 AWS 계정에 접근할 수 있고 리소스들을 변경하고 삭제할 수도 있으므로 이 위험에서 계정을 보호해야함
  - MFA = password you know + security device you own
- AWS에서 MFA 장치 옵션
  - 가상 MFA 장치 (Virtual MFA device)
    - Google Authenticator (phone only)
    - Authy (multi- device)
    - 하나의 장치에서 여러 계정 및 사용자를 지원함
  - 범용 두 번째 인자 보안 키 (U2F - Universion 2nd Factor Security Key)
    - 물리적 장치
    - Yubico(AWS 제3자 회사) 의 YubiKey
    - 하나의 보안 키로 여러 루트 계정과 IAM 유저를 지원
  - 하드웨어 키 팝 MFA 장치 (Hardware Key Fob MFA Device)
    - 물리적 장치
    - Gemalto(AWS 제3자 회사)
  - 하드웨어 키 팝 MFA 장치 (미국 정부 AWS GovCloud 전용)
    - SurePassID(AWS 제3자 회사)



### AWS 엑세스 키, CLI 및 SDK

- 유저가 AWS에 접근하는 방법
  - AWS Management Console (protected by password + MFA)
  - AWS Command Line Interface (CLI): protected by access keys
  - AWS Software Developer Kit (SDK): for code -> protected by access keys
- 액세스 키 생성 방법
  - AWS Console을 사용해서 생성할 수 있음
  - 사용자들이 자신들의 액세스 키를 직접 관리
  - 액세스 키는 비밀번호와 마찬가지로 암호와 같음 
  - 액세스 키는 절대 공유 되면 안됨
  - Access Key ID ~= username
  - Secret Access Key ~= password
- AWS CLI
  - 명령줄 셀에서 명령어를 사용하여 AWS 서비스들과 상호작용할 수 있도록 해 주는 도구
  - 모든 명령어가 aws로 시작
  - CLI를 사용하면 AWS 서비스의 공용 API로 직접 액세스가 가능
  - CLI를 통해 리소스를 관리하는 스크립트 개발해 일부 작업을 자동화할 수 있음
- AWS SDK
  - 소프트웨어 개발 키트
  - 특정 언어로 된 라이브러리의 집합 => 프로그래밍 언어에 따라 개별 SDK가 존재
  - SDK를 사용하면 AWS 서비스의 공용 API로 직접 액세스가 가능
  - 터미널을 통한 접근이 아니라 코딩을 통해 애플리케이션 내에 심어두는 방식
  - 다양한 프로그래밍 언어 지원 (JavaScript, Python, PHP, .NET, Ruby, Java, Go, Node.js, C++)
  - 모바일 SDKs (Android, iOS, ...)
  - IoT Device SDKs (Embedded C, Ariduino, ...)
  - 예시: AWS CLI는 파이썬 AWS SDK로 구성 돼 있음



### AWS 클라우드쉘

- 특정 지역에서만 가능
- AWS 클라우드에서 무료로 사용 가능한 터미널같은 개념
- 장점
  - CLI를 사용할 때 API 호출을 반환 
    - --region 을 이용해 API 호출을 할 리전을 지정할 수도 있음
    - 클라우드쉘에서 기본 리전은 현재 로그인 된 리전
  - 전체 저장소가 있음
  - 구성이 가능
    - 글씨 크기, 테마 선택, 안전하게 붙여넣기 기능
    - 파일 업로드 및 다운로드 가능
    - 탭 구성 가능



### AWS 서비스에 대한 IAM Role

- AWS 서비스 몇 가지는 우리의 계정에서 실행해야 하며, 이를 위해서는 사용자와 마찬가지로 어떤 권한이 필요함
- IAM Role은 사용자와 같지만 실제 사람이 사용하도록 만들어진 것이 아니고 AWS 서비스에 의해 사용되도록 만들어짐



### IAM 보안 도구

- IAM 자격 증명 보고서(Credentials Report)
  - 계정 수준(account- level)에서 가능
  - 보고서는 계정에 있는 사용자와 다양한 자격 증명의 상태를 포함
- IAM 액세스 관리자(Access Adviser)
  - 사용자 수준(user-level)에서 가능
  - 사용자에게 부여된 서비스의 권한과 해당 서비스에 마지막으로 엑세스한 시간이 보임
  - 해당 도구를 사용하여 어떤 권한이 사용되지 않는지 볼 수 있고 따라서 사용자의 권한을 줄여 최소권한의 원칙을 지킬 수 있음



## Section 05. EC2 기초

### EC2 기초

- EC2(Elastic Compute Cloud): AWS에서 제공하는 서비스형 인프라스트럭처
- 포함하고 있는 서비스
  - 가상 머신 임대 (EC2) => EC2 인스턴스
  - 데이터를 가상 드라이브 또는 EBS 볼륨에 저장 (EBS)
  - 엘라스틱 로드 밸런서로 로드를 분산 (ELB)
  - 오토 스케일링 그룹을 통해 서비스를 확장(ASG)
- EC2의 사용법을 아는 것은 클라우드 작동 방식을 이해할 때 필수적
- EC2 사이징(Sizing) & 설정 옵션(configuration options)
  - Operating System (OS): Linux, Windows or Mac OS
  - CPU: 컴퓨티 성능과 코어의 양
  - RAM: 램덤 엑세스 메모리의 양
  - 용량 공간
    - 네트워크를 통해 연결할 스토리지 필요 여부 (EBS & EFS)
    - 하드웨어 (EC2 인스턴스 스토어)
  - 네트워크 카드: 속도가 빠른 카드, 어떤 종류의 공용 IP
  - 방화병 규칙: 보안 그룹
  - 부트스트랩 스크립트 (처음에 설정): EC2 사용자 데이터
- EC2 사용자 데이터
  - EC2 사용자 데이터 스크립트를 사용하여 인스턴스를 부트스트래핑할 수 있음
  - 부트스트래핑: 머신이 작동될 때 명령을 시작하는 것
  - 스크립트는 처음 시작할 때 한 번만 실행됨
  - EC2 사용자 데이터가 자동화하는 작업들
    - 업데이트
    - 소프트웨어 설치
    - 일반적인 파일들을 인터넷에서 다운로드
    - 우리가 생각하는 모든 것들
  - EC2 사용자 데이터 스크립트는 루트 계정에서 실행 => 모든 명령문은 sudo로 해야 함
- EC2 인스턴스를 재실행시, 사설 IP는 항상 같은 상태로 유지되지만 공용 IP는 변경될 수 있음



### EC2 인스턴스 유형 기본 사항

- EC2 인스턴스 유형 - 개요
  - https://aws.amazon.com/ec2/instance-types/
  - m5.2xlarge 의미
    - m: 인스턴스 클래스
    - 5: 인스턴스의 세대(generation)
    - 2xlarge: 인스턴스 클래스의 사이즈 => 크기가 클수록 더 높은 메모리와 CPU 개수를 가짐
- 범용 인스턴스
  - 웹 서버나 코드 저장소와 같은 다양한 작업에 적합
  - 컴퓨팅, 메모리, 네트워킹 간의 균형도 잘 맞음
  - t2.micro 도 범용 인스턴스
- 컴퓨팅 최적화 인스턴스
  - 컴퓨터 집약적인 작업에 최적화된 인스턴스
  - 사용 사례
    - 일부 데이터의 일괄 처리
    - 미디어 트랜스코딩 작업 시
    - 고성능 웹 서버가 필요할 때
    - 고성능 컴퓨팅이라는 HPC 작업을 할 때
    - 과학적 모델링 & 머신 러닝
    - 전용 게임 서버
  -  Computing을 나타내는 C로 시작하는 이름을 가지고 있음
- 메모리 최적화 인스턴스
  - 메모리에서 대규모 데이터셋을 처리하는 유형에 빠른 성능을 제공
  - 사용 사례
    - 고성능의 관계형 / 비관계형 데이터베이스
    - 분산 웹스케일 캐시 저장소
    - BI(business intelligence)에 최적화된 인 메모리 데이터베이스
    - 대규모 비정형 데이터의 실시간 처리를 실행하는 애플리케이션
  - 보통 Ram을 나타내는 R로 시작하는 이름을 가지고 있음 (X1 이나 대용량 메모리, Z1도 있음)
- 스토리지 최적화 인스턴스
  - 로컬 스토리지에서 대규모의 데이터셋에 엑세스할 때 적합한 인스턴스
  - 사용 사례
    - 고주파 온라인 트랜잭션 처리(OLTP) 시스템
    - 관계형 & NoSQL 데이터베이스
    - 메모리 데이터베이스의 캐시 (ex - Redis)
    - 데이터 웨어하우징 애플리케이션
    - 분산 파일 시스템
  - I, G, H1으로 시작하는 이름을 가지고 있음

- 인스턴스 정보 보는 사이트: https://www.ec2instances.info/



### 보안 그룹 및 클래식 포트 개요

- 보안 그룹 개요
  - 보안 그룹은 AWS 클라우드에서 네트워크 보안을 실행하는데 핵심이 됨
  - EC2 인스턴스에 들어오고 나가는 트래픽을 제어
  - 보안 그룹은 오직 허용 규칙만 포함함
  - 보안 그룹 또는 IP 주소를 참조해 규칙을 만들 수 있음

- 보안 그룹 딥 다이브
  - 보안 그룹은 EC2 인스턴스의 방화벽
  - 규제 목록
    - 포트로의 엑세스 통제
    - 인증된 IP 주소의 범위를 확인해 IPv4인지 IPv6인지 확인
    - 외부에서 인스턴스로 들어오는 인바운드 네트워크 통제
    - 인스턴스에서 외부로 나가는 아웃바운드 네트워크 통제
  - 타입, 프로토콜, 포트 범위, 소스, 설명으로 구성
- 보안 그룹에 대해 알아야 하는 것 
  - 여러 인스턴스에 연결할 수 있음 => 보안 그룹과 인스턴스 간의 일대일 관계는 없음
  - 보안 그룹은 지역과 VPC 결합으로 통제되어 있음
  - 보안 그룹은 EC2 외부에 있음 => 트래픽이 차단되면 EC2 인스턴스는 확인할 수 없음
  - SSH 액세스를 위해 하나의 별도 보안 그룹을 유지하는 것이 좋음
  - 타임아웃으로 애플리케이션에 접근할 수 없으면 보안 그룹의 문제
  - 어떤 포트에 연결을 시도하는데 컴퓨터가 계속 멈추고 대기하기만 한다면 보안 그룹의 문제
  - ''연결 거부'' 오류가 발생하면 보안 그룹은 실행됐고 트래픽은 통과했지만 애플리케이션에 문제가 생겼거나 실행되지 않은 등 문제가 발생한 것
  - 기본적으로 모든 인바운드 트래픽은 차단되어 있고, 모든 아웃바운드 트래픽은 허용되어 있음
- 알아야 하는 포트
  - 22번 포트 => SSH(Secure Shell): Linux에서 EC2 인스턴스로 로그인하도록 함
  - 21번 포트 => FPT(File Transfer Protocol): 파일 공유 시스템에 파일을 업로드하는데 사용
  - 22번 포트 => SFTP (Secure FIle Transfer Protocol): SSH를 통해서 전송되고 보안 파일 전송 프로토콜이 되기 때문에 22번 포트를 사용함
  - 80번 포트 => HTTP: 보안이 되지 않은 사이트에 액세스하기 위함
  - 443번 포트 => HTTPS: 보안이 된 사이트에 엑세스하기 위함
  - 3389 포트 => RDP (Remote Desktop Protocol): 윈도우 인스턴스에 로그인할 때 사용



###   SSH 개요

- Secure Shell(SSH): 터미널이나 명령줄을 이용해서 원격 머신이나 서버를 제어할 수 있게 해줌
- SSH: Linux, Windows 10+
- PuTTY: Windows
- EC2 Instance Connect: Linux, Windows



### EC2 Instance Connect

- AWS EC2에서 실행
- 브라우저 기반으로  EC2 인스턴스에 대한  SSH 세션을 실행할 수 있음
- 임시 SSH키를 대신 업로드하고 접속을 하기 때문에 SSH 키를 따로 관리할 필요가 없음
- Amazone Linux AMI는 AWS CLI를 포함하고 있음 



### EC2 인스턴스 시작

- EC2 인스턴스에 엑세스 키  ID와 비밀 엑세스키를 입력하면 절대 안됨 => EC2 인스턴스 역할에서 IAM 역할을 사용하기

- EC2 인스턴스 구매 옵션

  - 온-디멘드 인스턴스 (On-Demand Instances)
    - 단기적 워크로드
    - 비용 예측 가능
    - 초 단위의 요금 지불
  - 예약 (Reserved) (1 & 3 년)
    - 예약 인스턴스: 장기적 워크로드
    - 전환형 예약 인스턴스: 유연한 인스턴스 타입
  - 절약 플랜 (Saving Plans) (1 & 3년)
    - 특정한 인스턴스 유형을 약정하는 게 아니라 달러 단위로 특정한 사용량을 약정
    - 장기적 워크로드

  - 스폿 인스턴스 (Spot Instances)
    - 단기적 워크로드
    - 매우 저렴
    - 언제라도 인스턴스들이 손실될 수 있어서 낮은 신뢰성을 가짐
  - 전용 호스트 (Dedicated Hosts)
    - 물리적 서버 전체를 예약해서 인스턴스 배치를 제어할 수 있음
  - 전용 인스턴스 (Dedicated Instances)
    - 다른 고객들이 자신의 하드웨어를 공유하지 않음
  - 용량 예약 (Capacity Reservations)
    - 원하는 기간 동안에 특정한  AZ(Availabilty Zone: 가용성 영역)에 용량을 예약할 수 있음

- EC2 On Demand

  - Linux나  Window 사용시: 1분 이후에 초 단위로 청구
  - 다른 모든 운영체계: 1시간 단위로 청구
  - 비용이 가장 많이 들지만 바로 지불한 금액은 없음
  - 장기적인 약정도 필요 없음
  - 단기적이고 중단 없는 워크로드가 필요할 때, 또는 애플리케이션의 거동을 예측할 수 없을 사용

- EC2 Reserved Instances (예약 인스턴스)

  - 예약 인스턴스는 온디맨드에 비해 최대 72%까지 할인을 제공
  - 특정한 인스턴스 속성을 예약 (인스턴스 타입, 리전, 테넌시, OS)
  - 예약 기간을 1년(+discount) 이나 3년(+++discount) 으로 지정해서 할인을 더 받을 수 있음
  - 결제 옵션: 모두 선결제(+++discount)  / 부분 선결제(++discount) / 선결제 없음(+discount)
  - 범위를 특정한 리전이나 존으로 할 수 있음 (특정한 AZ에 있는 예약된 용량)
  - 사용량이 일정한 애플리케이션에 예약 인스턴스를 사용하는게 좋음 (ex - database)
  - 예약 인스턴스를 마켓플레이스에서 살 수 있고, 더 이상 필요가 없어지면 팔 수도 있음
  - 전환형 예약 인스턴스 (Convertible Reserved Instance)
    - 인스턴스 타입, 인스터스 패밀리, 운영체계, 범위, 테넌시를 변경할 수 있음
    - 최대 66%까지 할인을 제공

- EC2 Saving Plans

  - 장기간 사용하면 할인을 받을 수 있음 (최대 72% - RI와 같음)
  - 다음 1년 내지 3년 동안 시간당 10달러로 약정을 하게 됨
  - 사용량이 한도를 넘어서면 절약 플랜은 온디맨드 가격으로 청구를 하게 됨
  - 특정한 인스턴스와 패밀리, 리전으로 고정됨
  - 유연한 속성
    - 인스턴스 사이즈
    - OS
    - 테넌시 (호스트, 전용, 기본)

- EC2 Spot Instances

  - 최대 90프로까지 할인
  - 스폿 인스턴스에 대해 지불하려는 최대 가격을 정의하고 만일 스폿 가격이 그 가격을 넘게 되면 인스턴스가 손실됨
  - AWS에서 가장 비용효율적인 인스턴스

  - 고장에 대한 회복력이 있는 워크로드에 유용
    - 배치 작업
    - 데이터 분석
    - 이미지 처리
    - 모든 종류의 분산형 워크로드
    - 시작 시간과 종료 시간이 유연한 워크로드
  - **아주 중요한 작업이나 데이터베이스에는 적절하지 않음**

- EC2 Dedicated Hosts

  - 활용 사례에 전용으로 사용되는 EC2 인스턴스 용량이 있는 실제 물리적 서버를 받게 됨
  - 물리적 서버 자체에 대한 접근권을 갖고 낮은 수준의 하드웨어에 대한 가시성을 제공해 줌
  - 기존의 서버에 연결된 소프트웨어 라이선스가 있는 경우 (법규 준수 요건이 있는 활용 사례나 소켓, 코어, VM 소프트웨어 라이센스)

  - 구매 옵션
    - 온-디멘드: 초당 비용 지불
    - 예약: 1 or 3년 (선결제, 부분결제, 후결제)
  - 가장 비싼 옵션 => 실제로 물리적 서버를 예약하기 때문
  - 활용 사례
    - 라이선싱 모델과 함께 사용되는 소프트웨어 (BYOL - Bring Your Own License)
    - 규정이나 법규를 반드시 준수해야 하는 회사

- EC2 Dedicated Instances

  - 전용 하드웨어에서 실행되는 인스턴스
  - 자신만의 인스턴스를 자신만의 하드웨어에 가짐
  - 같은 계정에서 다른 인스턴스와 함께 하드웨어를 공유할 수 있음
  - 인스턴스 배치에 대한 통제권이 없음

- EC2 Capacity Reservations

  - 원하는 기간 동안 특정한  AZ에서 온디맨드 인스턴스를 예약할 수 있음
  - 필요할 때마다 예약한 용량에 접근 가능
  - 기간 약정은 없음 (언제든 예약, 취소 가능)
  - 청구 할인도 없음
  - 지역별 예약 인스턴스와 결합하거나 절약 플랜과 결합해서 요금 할인 가능
  - 인스턴스를 실행하는지에 무관하게 온디맨드 요금이 부과됨
  - 특정한 AZ에 있어야 하는 단기적이고 중단 없는 워크로드에 아주 적합



### 스팟 인스턴스 및 스팟 집합

- 최대 스팟 가격을 정의하고, 인스턴스의 현재 스팟 가격이 정의한 최대 스팟 가격을 넘지 않으면 실행됨
  - 시간당 스팟 가격은 오퍼와 용량에 따라 달라짐
  - 현재 스팟 가격이 최대 스팟 가격을 초과하면 2가지 옵션이 있으며 2분의 유예 기간을 줌
    - 인스턴스 중지: 어느 날 스팟 가격이 최대 가격 아래로 내려가면 인스턴스를 다시 시작하고 중단했던 곳부터 재개
    - 인스턴스 종료: 인스턴스 상태가 필요하지 않다면 종료 후 작업을 다시 시작할 때 새로운 EC2 인스턴스로 시작
- 스팟 블록 (Spot Block)
  - 지정된 기간 동안 스팟 인스턴스를 차단
  - 1~6시간까지 가능하며, 그동안 중단 없이 해당 블록을 사용할 수 있음
  - 하지만 아주 드물게 인스턴스가 회수되는 경우가 있음
  - 현재 AWS에서 지원을 하지 않으나 가끔 시험에 나옴
- 스팟 인스턴스 종료법
  - 스팟 요청 유형은 일회성 인스턴스 요청과 영구 인스턴스 요청으로 나뉨
    - 일회성 인스턴스 요청은 한 번의 스팟 요청으로 끝남
    - 영구 인스턴스 요청은 인스턴스가 어떤 이유로든 중지되는 경우 스팟 요청이 다시 실행되고, 유효성이 확인되면, 스팟 인스턴스가 다시 시작됨
  - 따라서 영구 인스턴스 요청 유형의 스팟 요청을 가지는 스팟 인스턴스를 종료하려면 스팟 요청을 먼저 취소해야함
- 스팟 플릿 (Spot Fleets)
  - 스팟 플릿 = 스팟 인스턴스 세트 + (optional) 온디맨드 인스턴스 세트
  - 사용자가 정의한 가격 제한으로 목표 용량을 충족하기 위해 최선을 다함
    - 가능한 런치 풀에서 시작: 다양한 인스턴스 유형, 다양한  OS 및 다양한 가용성 영역을 가질 수 있음
    - 다양한 런치 풀을 정의하게 되고, 플릿이 가장 적합한 런치 풀을 선택함
    - 스팟 플릿이 예산에 도달하거나 원하는 용량에 도달하면 인스턴스 시작을 중지함
  - **스팟 플릿에 스팟 인스턴스를 할당하는 전략**
    - 최저 가격 (lowestPrice): 가장 낮은 가격인 풀에서 인스턴스를 시작 (비용이 최적화, 매우 짧은 워크로드)
    - 다양한 방법 (diversified): 사용자가 정의한 모든 풀에 분산됨 (가용성에 좋음 => 한 풀이 사라져도 다른 풀은 여전히 활성화 돼 있으므로, 긴 워크로드)
    - 용량 최적화 (capacityOptimized): 원하는 인스턴스 수에 맞는 최적의 용량을 가진 풀을 가짐
    - 가격 용량 최적화 (priceCapacityOptimized): 먼저 사용 가능한 용량이 가장 큰 풀을 선택하고 그 중 가격이 가장 낮은 풀을 선택하는 전략 (recommended, 대부분의 워크로드에 가장 적합)
  - 스팟 플릿을 사용하면 여러 개의 런치 풀과 여러 인스턴스 유형을 정의할 수 있고 가장 낮은 가격으로 자동으로 스팟 인스턴스를 요청함



## Section 06. EC2 - 솔루션스 아키텍트 어소시에이트 레벨

### 프라이빗 vs 퍼블릭 vs 탄력적 IP

- private vs public IP (IPv4)
  - IPv4 vs IPv6
    - IPv4: 1.160.10.240
    - IPv6: 3ffe:1900:4545:3:200:f8ff:fe21:67cf
  - 강의에선 IPv4만 사용할 것이지만 AWS는 IPv6도 지원함
  - IPv4는 현재 온라인에서 가장 널리 사용되는 형식
  - IPv6는 많은 문제를 해결해주며, IoT(사물 인터넷)에 더 많이 쓰임
  - IPv4는 공용 공간에서 37억 개의 서로 다른 주소를 허용 => 이제  IP 주소가 거의 고갈되어 가고 있음
  - IPv4: [0-255].[0-255].[0-255].[0-255].
  - Private vs Public IP
    - 공용  IP
      - 인터넷 전역에 액세스할 수 있음
      - 기기가 인터넷상에서 식별될 수 있음
      - 각 공용 IP는 전체 웹에서 유일함
      - IP의 지리적 위치를 쉽게 찾을 수 있음
    - 사설  IP
      - 사설 네트워크 내에서만 액세스할 수 있음
      - 기기가 오직 사설 네트워크 안에서만 식별될 수 있음
      - IP가 사설 네트워크 안에서만 유일하면 됨
      - 두 개의 다른 사설 네트워크는 같은 사설 IP를 가질 수 있음
      - 기기가 사설 네트워크에 있을 때 NAT 장치와 프록시 역할을 할 인터넷 게이트웨이를 통해 인터넷에 연결됨
      - 지정된 범위의 IP만 사설 IP로 사용될 수 있음
- Elastic IPs (탄력적 IP)
  - EC2 인스턴스를 시작하고 중지할 때 공용 IP를 바꿀 수 있음
  - 인스턴스에 고정된 공용 IP를 사용하면 탄력적 IP가 필요하게 됨
  - 탄력적 IP는 공용 IPv4인데 삭제하지 않는 한 계속 가지고 있게 됨
  - 한 번에 한 인스턴스에만 첨부할 수 있음
  - IP 주소가 탄력적이면 한 인스턴스에서 다른 인스턴스로 빠르게 이동함으로써 인스턴스 또는 소프트웨어의 오류를 마스킹할 때 사용할 수 있음 (드문 경우)
  - 계정당 탄력적 IP를 5개만 쓸 수 있음 (AWS에 개수 증가를 요청할 수 있음)
  - 결론적으로, 탄력적 IP는 사용하지 않는 것이 좋음
    - 매우 좋지 않은 구조적 결정
    - 대신, 임의의 공용 IP를 써서 DNS 이름을 할당하는 것이 좋음
- AWS EC2
  - 기본값으로 EC2 기기는 내부 AWS 네트워크엔 사설 IP, www(world wide web)엔 공용 IP를 사용
  - EC2 머신에 SSH를 사용할 때
    - 사설 IP를 사용할 수 없음 => 같은 네트워크에 있지 않으므로
    - 공용 IP만 사용할 수 있음
  - **기기가 멈췄다가 다시 시작하면 공용 IP가 바뀔 수 있음**



### EC2 배치 그룹 (Placement Groups)

- EC2 인스턴스가  AWS 인프라에 배치되는 방식을 제어하고자 할 때 사용
- 배치 그룹을 사용하여 전략을 정의 가능
- 배치 그룹을 만들 때 세 가지 전략을 사용할 수 있음
  - 클러스터 (Cluster): 단일 가용 영역 내에서 지연 시간이 짧은 하드웨어 설정으로 인스턴스를 그룹화
  - 분산 (Spread): 인스턴스가 다른 하드웨어에 분산 (가용 영역별로 분산된 배치 그룹당 최대 7개의 인스턴스를 가질 수 있음) => 크리티컬 애플리케이션이 있는 경우
  - 분할 (Partition): 여러 파티션에 인스턴스가 분할되어 있고, 이 파티션은 가용 영역 내의 다양한 하드웨어 랙 세트에 의존. 그룹당 수백 개의 EC2 인스턴스를 통해 확장할 수 있고 이를 통해 Hadoop, Cassandra, Kafka 같은 애플리케이션을 실행할 수 있음
- Placement Groups Cluster
  - 모든 EC2 인스턴스가 동일한 랙(=동일한 하드웨어 및 가용 영역)에 있음
  - 장점: 매우 빠른 네트워크
  - 단점: 랙에 실패가 발생하면 모든 EC2 인스턴스가 동시에 실패함
  - 사용 사례
    - 빅데이터 작업
    - 극히 짧은 지연 시간과 높은 네트워크 처리량을 필요로 하는 애플리케이션이 있는 요청
- Placement Groups Spreds
  - 실패 위험을 최소화
  - 모든 EC2 인스턴스가 다른 하드웨어에 위치
  - 장점: 여러 가용 영역에 걸쳐 있을 수 있으며, 동시 실패의 위험이 감소
  - 단점: **배치 그룹의 가용 영역당 7개의 인스턴스로 제한이 됨**
  - 사용 사례
    - 가용성을 극대화하고 위험을 줄여야 하는 애플리케이션
    - 인스턴스 오류를 서로 격리해야하는 크리티컬 애플리케이션
- Placement Groups Partition
  - 가용 영역당 최대 7개의 파티션이 있을 수 있음
  - 이러한 파티션은 동일한 리전의 여러 가용 영역에 걸쳐 있을 수 있음
  - 설정으로 최대 수백 개 EC2 인스턴스를 얻을 수 있음
  - 인스턴스와 파티션은 다른 파티션의 인스턴스와 동일한 하드웨어 물리적 랙을 공유하지 않으므로 각 파티션은 실패로부터 격리됨
  - EC2 인스턴스가 어떤 파티션에 있는지 알기 위해 메타데이터 서비스를 사용하여 이 정보에 액세스하는 옵션이 있음
  -  사용 사례
    - 대규모의 분산 및 복제된 워크 로드
    - HDFS, HBase, Cassandra, Kafka



### ENI (탄력적 네트워크 인터페이스)

- Elastic Network Interfaces (ENI)
  - VPC의 논리적 구성 요소이며 가상 네트워크 카드를 나타냄
  - ENI는 EC2 인스턴스가 네트워크에 액세스할 수 있게 해줌
  - ENI는 EC2 인스턴스 외부에서도 사용됨
  - 속성
    - 주요 사설 IPv4와 하나 이상의 보조 IPv4를 가질 수 있음
    - 각 ENI는 사설 IPv4당 탄력적 IPv4를 갖거나 혹은 하나의 공용 IPv4를 가질 수 있음
    - ENI에 하나 이상의 보안 그룹을 연결할 수 있음
    - MAC 주소 및 기타 항목을 연결할 수 있음
  - EC2 인스턴스와 독립적으로 ENI를 생성하고 즉시 연결하거나 장애 조치를 위해  EC2 인스턴스에서 이동시킬 수 있음
  - 특정 가용 영역, 즉  AZ에 바인딩 됨



### EC2 절전(Hibernate) 모드

- 인스턴스 중지 방법
  - 중지 (Stop): 디스크 데이터(EBS)는 다시 시작할 때까지 그대로 유지
  - 종료 (Terminate)
    - 루트 볼륨이 삭제되게 했다면 인스턴스도 삭제
    - 그렇게 설정하지 않은 다른 볼륨은 인스턴스가 종료되더라도 그대로 남음
- 인스턴스 다시 시작시 발생하는 일
  - 첫 시작: OS가 먼저 부팅되기 시작하고 EC2 사용자 데이터 스크립트도 실행
  - 시작 후: 운영 체제가 부팅이 완료
  - 애플리케이션이 실행되고 캐시도 구성되므로 과정이 끝날 때까지 시간이 다소 걸림
- EC2 절전 모드
  - EC2 절전 모드 소개
    - 인 메모리(RAM) 상태는 그대로 보존
    - 인스턴스 부팅이 더 빨라짐 (OS를 완전히 중지하거나 재시작하지 않았으므로)
    - 백그라운드: RAM에 기록되었던 인 메모리 상태는 루트 경로의 EBS 볼륨에 기록됨
    - 루트 EBS 볼륨을 암호화해야 하고 볼륨 용량도 RAM을 저장하기에 충분해야 함
  - 사용 사례
    - 오래 실행되는 프로세스를 갖고 있고 중지하지 않을 때
    - RAM 상태를 저장하고 싶을 때
    - 빠르게 재부팅을 하고 싶을 때





## Section 07. EC2 인스턴스 스토리지

### EBS 개요

- EBS Volume?
  - EBS (Elastic Block Store) Volume: 인스턴스가 실행 중인 동안 연결 가능한 네트워크 드라이브
  - EBS 볼륨을 사용하면 인스턴스가 종료된 후에도 데이터를 지속할 수 있음
  - CCP 레벨: 하나의 EBS는 하나의 EC2 인스턴스에만 마운트 가능(단, 여러개의 EBS가 하나의 EC2 인스턴스에도 마운트가 가능함)
  - 어소시에이트 레벨: 일부 EBS 다중 연결
  - EBS 볼륨을 생성할 때는 특정 가용 영역에서만 가능
  - 네트워크 USB 스틱과 같은 역할
  - Free tier: 매달 30GB의 EBS 스토리지를 범용 SSD 혹은 마그네틱 유형으로 제공
- 특징
  - 네트워크 드라이브 => 물리적 드라이브가 아님
    - 인스턴스와 EBS 볼륨이 서로 통신을 하기 위해서는 네트워크를 필요로 함 => 따라서 컴퓨터가 다른 서버에 도달할 때 지연이 발생할 수 있음
    - EC2 인스턴스에서 분리될 수 있고 매우 빠르게 다른 인스턴스로 연결될 수 있음
  - 특정한 가용 역역(AZ)에 고정되어 있음
    - 하지만 스냅샷을 이용하면 다른 가용 역역으로도 볼륨을 옮길 수 있음
  - 볼륨이기 때문에 용량을 미리 결정해야 함
    - 원하는 양의  GB 및 IOPS(단위 초당 전송 수)
    - 해당 프로비전 용량에 따라 요금이 청구됨
    - 더좋은 성능이나 큰 사이즈가 필요하면 이후에 용량을 늘릴 수도 있음 
- **EBS - 종료 시 삭제 속성**(Delete on Termination attribute)
  - 이 옵션을 통해 EC2 인스턴스 종료 시 EBS 행동을 제어할 수 있음
    - 루트 EBS 볼륨은 디폴트 값으로 인스턴스 종료와 함께 삭제되도록 설정이 되어 있음 (활성 상태)
    - 다른 EBS 볼륨은 디폴트 값으로 삭제되지 않도록 설정이 되어 있음 (비활성 상태)
  - 종료 시 삭제 활성화 여부는 원하는 대로 조작이 가능
  - 종료 시 삭제 속성 비활성 상태 사용 예시
    - 인스턴스가 종료될 때 루트 볼륨을 유지하고자 하는 경우
    - 데이터를 저장하고자 하는 경우



### EBS 스냅샷 개요

- EBS 스냅샷
  - EBS 볼륨의 특정 시점에 대한 백업
  - EC2 인스턴스에서 EBS 볼륨을 분리할 필요는 없지만 권장 사항임
  - EBS 스냅샷은 다른 가용 역역이나 다른 리전에도 복사할 수도 있음
- 기능
  - EBS 스냅샷 아카이브(EBS Snapshot Archive)
    - 최대 75%까지 저렴한 아카이브 티어로 스냅샷을 옮길 수 있는 기능
    - 스냅샷을 아카이브 티어로 옮기면 아카이브를 복원하는데 24시간에서 최대 72시간이 걸림
  - EBS 스냅샷 휴지통(Recycle Bin for EBS Snapshots)
    - EBS 스냅샷을 삭제하는 경우 영구 삭제하는 대신에 휴지통에 넣을 수 있음 (복원 가능)
    - 휴지통에 보관되는 기간은 1일에서 1년 사이로 설정할 수 있음
  - 빠른 스냅샷 복원(FSR - Fast Snapshot Restore) 
    - 스냅샷을 완전 초기화해 첫 사용에서의 지연 시간을 없애는 기능
    - 스냅샷이 아주 크고 EBS 볼륨 또는 EC2 인스턴스를 빠르게 초기화해야 할 때 특히 유용
    - 비용이 많이 드니 사용에 유의



### AMI 개요

- AMI
  - AMI(Amazon Machine Image): EC2 인스턴스를 통해 만든 이미지를 통칭
  - AMI로 EC2 인스턴스를 원하는 대로 변경 가능
    - 원하는 소프트웨어 또는 설정 파일, 별도의 운영 체제, 모니터링 툴을 추가 가능
    - AMI를 따로 구성하면 부팅 및 설정에 드는 시간을 줄일 수 있음 => 우리가  EC2 인스턴스에 설치하고자 하는 모든 소프트웨어를 AMI가 미리 패키징해주기 떄문
  - AMI는 특정 지역에 구축 (다른 지역으로 복사도 가능)
  - EC2 인스턴스를 여러 종류의  AMI에서 실행 가능
    - A Public AMI(전체 공개 AMI): AWS에서 제공
    - Your own AMI(자체적으로 구성한 AMI): 직접 만들고 유지, 관리도 직접 해야 함
    - An AWS Marketplace AMI: 다른 사람이 구축한 AMI (보통은 구매한 이미지)
- AMI Process (from an EC2 instance)
  - 먼저 EC2 인스턴스를 원하는 대로 설정
  - 인스턴스를 중지해 데이터 무결성을 확보
  - 이 인스턴스를 바탕으로 AMI를 구축 (이 과정에서 EBS 스냅샷이 생성됨)
  - 다른 AMI에서 인스턴스를 실행할 수 있음



### EC2 인스턴스 스토어

- EC2 인스턴스 스토어
  - EBS 볼륨은 네트워크 드라이브이기 때문에 뛰어나지만 제한된 성능을 가짐
  - 고성능의 하드웨어 디스크 성능이 필요하다면, EC2 인스턴스 스토어를 사용해야 함
  - I/O 성능 향상을 위해 활용할 수 있음
  - EC2 인스턴스 스토어를 중지 또는 종료하면 해당 스토리지 또한 손실됨 => 단기 스토리지 기능
  - 사용 예시: 버퍼 / 캐시 / 스크래치 데이터 / 임시 콘텐츠
  - EC2 인스턴스의 기본 서버에 장애가 발생할 시에는 해당 EC2 인스턴스가 연결된 하드웨어에도 장애가 발생하므로 데이터 손실에 대한 위험이 존재
  - 필요에 따라 데이터를 백업해 두거나 복제해 둬야 함



### EBS 볼륨 유형

- EBS 볼륨 유형 (6 types)

  - gp2 / gp3 (SSD)
    - 범용 SSD 볼륨 
    - 다양한 워크로드에 대해 가격과 성능의 절충안이 됨
  - io1 / io2 (SSD)
    - 최고 성능을 자랑하는 SSD 볼륨
    - 미션 크리티컬이자 지연 시간이 낮고 대용량의 워크로드에 쓰임
  - st1 (HDD)
    - 저비용의 HDD 볼륨
    - 잦은 접근과 처리량이 많은 워크로드에 쓰임
  - sc1 (HDD)
    - 가장 비용이 적게 드는 HDD 볼륨
    - 접근 빈도가 낮은 워크로드를 위해 설계됨

  - 크기, 처리량, IOPS 에 따라 EBS 볼륨 유형이 나뉨
  - gp2 / gp3와  io1 / io2 만이 부팅 볼륨으로 사용될 수 있음

- General Purpose SSD (gp2 / gp3)

  - 짧은 지연 시간, 효율적인 비용의 스토리지
  - 시스템 부팅 볼륨 및 가상 데스크톱, 개발, 테스크 환경에서 사용할 수 있음
  - 크기: 1GB ~ 16TB
  - gp3
    - 최신 세대의 볼륨
    - 기본 성능으로 3,000 IOPS와 125MB/s의 처리량을 제공
    - IOPS는 최대 16,000, 처리량은 최대 1,000MB/s까지 증가시킬 수 있음
  - gp2
    - 최대 3,000 IOPS
    - 볼륨과 IOPS가 연결되어 있으며,  최대  IOPS는 16,000
    - 1GB 당 3IOPS

- Provisioned IOPS (PIOPS) SSD (io1 / io2)

  - IOPS 성능을 유지할 필요가 있는 주요 비즈니스 애플리케이션
  - 16,000 IOPS 이상을 필요로 하는 애플리케이션
  - 일반적으로 데이터베이스 워크로드에 알맞음 (스토리지 성능과 일관성에 민감)
  - io1 / io2 (4GB ~ 16TB)
    - 최대 POIPS: **Nitro EC2 인스턴스에서 64,000 IOPS**  / 나머지는 32,000  IOPS
    - 프로비저닝된  IOPS의 스토리지 크기를 독자적으로 증가시킬 수 있음
    - io2는 io1과 동일한 비용으로 내구성과 기기 당  IOPS의 수가 더 높음 (2가 더 합리적)
  - io2 Block Express (4GB ~ 64TB)
    - 고성능 유형의 볼륨
    - 지연 시간이 밀리초 미만
    - IOPS 대 GB 비율이 1,000 : 1  일 때 최대 256,000 IOPS
  - EBS 다중 연결을 지원

- Hard Disk Drives (HDD) (st1 / sc1)

  - 부팅 볼륨이 될 수 없음
  - 125MB ~ 16TB
  - 처리량 최적화(Throuhput Optimized) HDD (st1)
    - 처리량 최적화 HDD
    - 빅 데이터나 데이터 웨어하우징 로그 처리에 적합
    - 최대 처리량은 초당 500MB, 최대 IOPS는 500
  - 콜드(Cold) HDD (sc1)
    - 아카이브 데이터용
    - 접근 빈도가 낮은 데이터에 적합
    - 최저 비용으로 데이터를 저장할 때 사용
    - 최대 처리량은 초당 250MB, 최대 IOPS는 250



### EBS 다중 연결

- EBS 다중 연결 - io1 / io2 제품군
  - 하나의 EBS 볼륨을 같은 가용 영역에 있는 여러 EC2 인스턴스에 연결할 수 있게 해 줌
  - 각 인스턴스는 고성능 볼륨에 대한 읽기 및 쓰기 권한을 전부 가짐 => 동시에 읽고 쓸 수 있음
  - 사용 사례
    - 애플리케이션 가용성을 높이기 위해 클러스터링된 Linux 애플리케이션 (ex: Teradata)
    - 애플리케이션이 동시 쓰기 작업을 관리해야 할 때
  - **한 번에 16개**의  EC2 인스턴스만 같은 볼륨에 연결 가능
  - 반드시 클러스터 인식 파일 시스템을 사용해야 함 (not XFS, EX4, etc)



### EBS 암호화

- EBS 암호화(Encryption)
  - EBS 볼륨을 생성하면 즉시 다음과 같은 일이 동시다발적으로 일어남
    - 저장 데이터가 볼륨 내부에 암호화
    - 인스턴스와 볼륨 간의 전송 데이터가 암호화
    - 모든 스냅샷이 암호화
    - 스냅샷으로 생성한 볼륨도 암호화
  - 암호화 및 복호화 메커니즘은 보이지 않게 처리 됨 (아무것도 할 필요가 없음)
  - 암호화는 지연 시간에는 영향이 거의 없음
  - KMS에서 암호화 키를 생성해 AES-256 암호화 표준을 가짐
  - 스냅샷을 복사해 함호화를 푼 걸 다시 암호화 활성화를 함
- EBS 볼륨 암호화 및 암호화 풀기
  - 볼륨의 EBS 스냅샷을 생성
  - 복사 기능을 통해 EBS 스냅샷을 암호화함
  - 스냅샷을 이용해 새 EBS 볼륨을 생성 (해당 볼륨 또한 암호화 됨)
  - 암호화된 볼륨을 인스턴스 원본에 연결



### Amazon EFS

- Amazon EFS - Elastic File System

  - 네트워크 파일 시스템: 많은  EC2 인스턴스에 마운트될 수 있음
  - EC2 인스턴스는 서로 다른 가용성 영역에 있을 수 있음
  - 가용성이 높고 확장성이 뛰어나며 비쌈 (gp2 EBS 볼륨의 약 3배)
  - 사용량에 따라 비용 지불
  - 사용사례: 콘텐츠 관리, 웹 서빙, 데이터 공유, Wordpress
  - 내부적으로 NFSv4.I protocol 을 사용
  - EFS에 대한 엑세스를 제어하려면 보안 그룹을 설정해야 함
  - **Linux 기반 AMI와만 호환됨 (윈도우 X)**
  - KMS를 사용해서 EFS 드라이브에서 미사용 암호화를 활성화 가능
  - POSIX 파일 시스템 (Linux 전용) 사용 => 표준 파일  API를 가짐
  - 파일 시스템은 자동으로 확장되며 EFS에서 사용하는 데이터 GB 사용량에 따라 비용을 지불

- EFS - 성능 클래스

  - EFS Scale
    - 수천 개의 동시 NFS 클라이언트, 10GB/s 이상의 처리량
    - PB(Petabyte) 규모의 네트워크 파일 시스템으로 자동 확장 가능

  - 성능 모드(Perfomance Mode) (EFS 생성 시에 설정 가능)
    - 범용 (기본값): 지연시간에 민감한 사용 사례에 사용 (웹 서버, CMS)
    - 최대 I/O: 지연시간이 길지만, 처리량이 높고 병렬성이 높음 (빅 데이터 애플리케이션, 미디어 처리)
  - 처리량 모드(Throughput Mode)
    - 버스팅(Bursting): 1TB = 50Mb/s + 100Mb/s 버스트
    - 프로비저닝(Provisioned): 스토리지 크기에 관계없이 처리량을 설정하고 싶은 경우 (ex: 1Gb/s for 1Tb 용량)
    - 엘라스틱(Elastic): 워크로드에 따라 처리량을 자동으로 조절
      - 읽기 최대  3Gb/s, 쓰기 최대 1Gb/s
      - 워크로드를 예측하기 어려울 때 유용

- EFS - 스토리지 클래스

  - 스토리지 티어(Storage Tiers): 며칠 후 파일을 다른 계층으로 옮길 수 있는 기능

    - Standard: 자주 액세스하는 파일
    - Infrequent access(EFS-IA)
      - 자주 엑세스 하지 않는 파일
      - 낮은 비용
      - 이 계층에서 파일을 검색할 경우 비용이 발생
      - 사용하려면 수명 주기 정책을 사용해야 함

  - 가용성과 내구성(Availability and durability)

    - Standard: 다중 AZ, 프로덕션 사용 사례에 적합 => 가용성 영역 하나가 다운되더라도 EFS 파일 시스템에 영향을 미치지 않으므로
    - One Zone(EFS One Zone-IA): 하나의 AZ, 개발용으로 적합, 백업이 기본적으로 활성화, 엑세스 빈도가 낮은 스토리지 계층과 호환되지 않음

  - 최대 90% 비용할인 가능

    

### EBS 대 EFS

- EBS(Elastic Block Storage)
  - EBS volumes
    - 하나의 인스턴스에만 첨부 (io1/io2의 다중 첨부 기능 제외)
    - AZ 수준에서 잠김
    - gp2: 디스크 크기가 증가하면 IO가 증가
    - Io1: 독립적으로 IO를 늘릴 수 있음
  - AZ 간에 EBS 볼륨 마이그레이션 방법
    - 스냅샷을 찍어야 함
    - 스냅샷을 다른 AZ로 복원
    - EBS 볼륨 백업은 IO를 사용하므로, 애플리케이션이 많은 트래픽을 처리하는 경우엔 실행하지 않아야 함 => EC2 성능에 영향을 미칠 수 있음
  - EBS 인스턴스의 루트 EBS 볼륨은 EC2 인스턴스가 종료되면 기본적으로 종료됨 (비활성화 가능)
- EFS(Elastic FIle System)
  - 여러 가용성 영역에 걸친 수백 개의 인스턴스에 첨부
  - 여러 인스턴스가 하나의 파일 시스템을 공유
  - WordPress와 같은 웹사이트 파일을 공유
  - Linux 전용 (POSIX 시스템)
  - EBS보다 가격대가 높음 
  - EFS-IA 기능을 활용하여 비용 절감 가능



## Section 08. 고가용성 및 스케일링성: ELB 및 ASG

### 고가용성 및 스케일링성

- 확장성 및 고가용성 (Scalability & High Availability)
  - 확장성: 애플리케이션 시스템이 조정을 통해 더 많은 양을 처리할 수 있음
  - 종류
    - 수직 확장성 (Verical Scalability)
    - 수평 확장성 = 탄력성 (Horizontal Scalability = elasticity)
  - 확장성은 고가용성과 연관된 개념이지만 다름
- 수직 확장성
  - 인스턴스의 크기를 확장하는 것을 의미
  - ex: t2.micro => t2.large
  - 데이터베이스와 같이 분산되지 않은 시스템에서 흔히 사용됨
  - RDS, ElastiCache 등의 데이터베이스에서 찾아볼 수 있음
  - 일반적으로 확장할 수 있는 정도에는 한계가 있음 (하드웨어 제한에 의해)
- 수평 확장성
  - 애플리케이션에서 인스턴스나 시스템의 수를 늘리는 방법
  - 수평 확장은 분배 시스템이 있다는 걸 의미
  - 웹이나 현대적 애플리케이션은 대부분 분배 시스템으로 이루어져 있음
  - 요즘은 Amazon EC2와 같은 클라우드 제공 업체 덕분에 수평적인 확장이 수월해짐
- 고가용성
  - 수평 확장성과 함께 사용되는 개념이지만 같진 않음
  - 애플리케이션 또는 시스템을 적어도 둘 이상의 AWS의 AZ나 데이터 센터에서 가동 중이라는 걸 의미
  - 데이터 센터에서의 손실에서 살아남는 것이 목표 => 센터 하나가 멈춰도 계속 작동 가능
  - 고가용성은 수동적일 수 있음 (ex: RDS 다중 AZ를 갖추고 있는 경우)
  - 고가용성은 활성형일 수 있음 (ex: 수평 확장)
- EC2의 고가용성 & 확장성
  - 수직 확장: 인스턴스의 크기를 늘리는 것 (= 스케일 업 / 다운)
  - 수평 확장: 인스턴스의 수를 늘리는 것 (= 스케일 아웃 / 인)
  - 고가용성
    - 동일 애플리케이션의 동일 인스턴스를 다수의 AZ에 걸쳐 실행하는 경우
    - 다수 AZ의 오토 스케일링 그룹
    - 다수 AZ의 로드 밸런서



### Elastic Load Balancing (ELB)

- 로드 밸런싱?

  - 서버 혹은 서버셋으로 트래픽을 백엔드나 다운스트림 EC2 인스턴스 또는 서버들로 전달하는 역할을 함

- 사용 이유

  - 부하를 다수의 다운스트림 인스턴스로 분산하기 위해
  - 애플리케이션에 단일 액세스 지점(DNS)을 노출
  - 다운스트림 인스턴스의 장애를 원활히 처리할 수 있음
  - 인스턴스의 상태를 확인할 수 있음 (상태 확인 매커니즘으로 어떤 인스턴스로 트래픽을 보낼 수 없는지 확인해 줌)
  - 웹 사이트에 암호화된 HTTPS 트래픽을 가질 수 있음
  - 쿠키로 고정도를 강화할 수 있음
  - 영역에 걸친 고가용성을 가짐
  - 클라우드 내에서 개인 트래픽과 공공 트래픽을 분리할 수 있음
  - 관리형 로드 밸런서(managed load balancer)
    - AWS가 관리하며, 어떤 경우에도 작동할 것을 보장
    - AWS가 업그레이드와 유지 관리 및 고가용성을 책임짐
    - 로드 밸런서의 작동 방식을 수정할 수 있게끔 일부 구성 놉도 제공

  - 자체 로드 밸런서를 마련하는 것보다 저렴하고 자체 로드 밸런서를 직접 관리하려면 확장성 측면에서 굉장히 번거로움 
  - 다수의 AWS 서비스들과 통합되어 있음
    - EC2, EC2 오토 스케일링 그룹, Amazon ECS
    - AWS Certificate Manager (ACM), CloudWatch
    - Route 53, AWS WAF, AWS Global Accelerator

- 상태 확인(Health Checks)

  - ELB가 EC2 인스턴스의 작동이 올바르게 되고 있는지의 여부를 확인하기 위해 사용
  - ELB에겐 상태확인이 아주 중요 
  - 상태확인은 포트와 라우트에서 이루어짐
  - 만약 200응답을 받지 못하면, 인스턴스 상태가 좋지 않다고 기록됨 => 그쪽으로 트래픽을 보내지 않음

- AWS의 로드 밸런서 타입

  - 클래식 로드 밸런서  (v1 - old generation) (2009,  CLB)
    - HTTP, HTTPS, TCP, SSL (secure TCP) 지원
    - 콘솔에서는 더 이상 사용할 수 없음 => 시험에도 안나옴
  - 어플리케이션 로드 밸런서 (v2 - new generation) (2016, ALB)
    - HTTP, HTTPS, WebSocket
  - 네트워크 로드 밸런서 (v2 - new generation) (2017, NLB)
    - TCP, TLS, secure TCP, UDP
  - 게이트웨이 로드 밸런서 (2020, GWLB)
    - 네트워크층(3계층)에서 작동 - IP 프로토콜
  - 더 많은 기능을 가지고 있는 신형 로드 밸런서 사용을 권장
  - 네트워크에 개인적 접근이 가능한 내부 프라이빗 로드 밸런서가 있음
  - 웹사이트와 공공 애플리케이션 모두에 사용 가능한 외부 공공 로드 밸런서가 있음

- 로드 밸런서 보안 그룹 (Load Balancer Security Groups)

  - 유저는  HTTPS / HTTP를 사용해 어디서든 로드 밸런서의 접근이 가능
  - EC2 인스턴스는 로드 밸런서를 통해 곧장 들어오는 트래픽만을 허용해야 하기 때문에 소스는 로드 밸런서의 보안 그룹이 됨

  

### Application Load Balancer (ALB) 

- 애플리케이션 로드 밸런서
  - 7계층, 즉 HTTP 전용 로드 밸런서
  - 머신 간 다수 HTTP 애플리케이션의 라우팅에 사용 됨 (target groups)
  - 동일 EC2 인스턴스 상의 여러 애플리케이션에 부하를 분산함
  - HTTP/2 와  WebSocket을 지원
  - 리다이렉트도 지원 (ex: http -> https)
  - 다른 대상 그룹에 따른 라우팅
    - URL 대상 경로에 기반한 라우팅 (example.com/users & example.com/posts)
    - URL의 호스트 이름에 기반한 라우팅 (one.example.com & other.example.com)
    - 쿼리 문자열과 헤더에 기반한 라우팅 (example.com/users?id=123&order=false)
  - ALB는 마이크로 서비스나 컨테이너 기반 애플리케이션에 가장 좋은 로드 밸런서 (ex: Docker & Amazon ECS)
  - 포트 매핑 기능이 있어 ECS 인스턴스의 동적 포트로의 리다이렉션을 가능하게 해줌
  - 하나의 ALB로 다수의 애플리케이션을 처리할 수 있음
- ALB 대상 그룹 (Target Groups)
  - 종류
    - EC2 인스턴스 (오토 스케일링 그룹에 의해 관리될 수 있는) - HTTP
    - ECS 작업(Tasks) - HTTP
    - 람다 함수 - JSON 이벤트로 변환되는 HTTP 요청
    - IP 주소 - 사설 IP 주소만 가능
  - ALB는 여러 대상 그룹으로 라우팅할 수 있음
  - 상태 확인은 대상 그룹 레벨에서 이뤄짐
- 알아두면 좋은 내용
  - 고정 호스트 이름이 부여됨 (XXX.region.elb.amazonaws.com)
  - 애플리케이션 서버는 클라이언트의  IP를 직접 보지 못함
    - 클라이언트의 실제 IP는 X-Forwarded-For라고 불리는 헤더에 삽입
    - X-Forwarded-Port를 사용하는 포트와 X-Forwarded-Proto에 의해 사용되는 프로토콜도 얻게 됨



### Network Load Balancer (NLB) 

- 네트워크 로드 밸런서

  - 4계층(네트워크) 로드 밸런서이므로 TCP & UDP 트래픽을 다룰 수 있음
  - 초당 수백만 건의 요청을 처리할 수 있음
  - ~100ms로 짧은 지연시간을 가짐 (vs 400ms for ALB)
  - **가용 영역별로 하나의 고정 IP를 가짐**
    - 탄력적 IP 주소를 각 AZ에 할당할 수 있음
    - 여러 개의 고정 IP를 가진 애플리케이션을 노출할 때 유용
  - 고성능, TCP, UDP, 정적 IP 에 사용됨
  - AWS 프리티어에 포함 X

- 대상 그룹

  - EC2 인스턴스: TCP 또는 UDP 트래픽을 EC2 인스턴스로 리다이렉트 할 수 있음
  - IP 주소: 사설 IP 주소만 가능
  - 어플리케이션 로드 밸런서: 고정 IP 주소를 얻을 수 있고 HTTP 유형의 트래픽을 처리하는 규칙을 얻을 수 있음
  - 상태 확인 지원: TCP, HTTP, HTTPS 

  

### Gateway Load Balancer (GWLB)

- 게이트웨이 로드밸런서
  - 배포 및 확장과 AWS의 타사 네트워크 가상 어플라이언스의 플릿 관리에 사용
  - 예시: 방화벽, 침입 탐지 및 방지 시스템(IDPS), 심층 패킷 분석 시스템
  - 3계층(네트워크 계층) - IP Packets
  - 기능
    - 투명 네트워크 게이트웨이(Transparent Network Gateway): VCP의 모든 트래픽이 GWLB가 되는 단일 엔트리와 출구를 통과
    - 로드 밸런서: 대상 그룹의 가상 어플라이언스 집합에 전반적으로 트래픽을 분산
  - **6081번 포트의 GENEVE 프로토콜을 사용**
- 대상 그룹
  - EC2 인스턴스
  - IP 주소: 사설 주소만 가능



### Elastic Load Balancer - 고정 세션(Sticky Session)

- 고정 세션 (세션 밀접성 -  Session Affinity)
  - 고정성 혹은 고정 세션을 실행하는 것으로 로드 밸런서에 2가지 요청을 수행하는 클라이언트가 요청에 응답하기 위해 백엔드에 동일한 인스턴스를 갖는 것
  - 이 동작은 ALB에서도 설정할 수 있음
  - 고정성을 위해 사용되는 쿠키는 사용자가 컨트롤 가능한 만료 기간을 가지고 있음
  - 사용자의 로그인과 같은 중요한 정보를 취하는 세션 데이터를 잃지 않기 위해 사용
  - 고정성을 활성화하면 백엔드 EC2 인스턴스 부하에 불균형을 초래할 수 있음
- 쿠키
  - 애플리케이션 기반 쿠키 (Application-based Cookies) => 기간 설정 가능
    - 사용자 정의 쿠키
      - 대상(target)에 의해 생성
      - 애플리케이션에 필요한 모든 사용자 정의 속성을 포함할 수 있음
      - 쿠키 이름은 각 대상 그룹별로 개별적으로 지정해야 함
      - 쿠키 이름으로 AWSALB, AWSALBAPP, AWSALBTG는 사용하면 안됨 (ELB에서 사용하기 때문)
    - 애플리케이션 쿠키
      - 로드 밸런서에 의해 생성
      - 쿠키 이름은 AWSALBAPP
  - 기간 기반 쿠키 (Duration-based Cookies) => 기간 설정 불가
    - 로드 밸런서에서 생성되는 쿠키
    - ALB에서는 이름이 AWSALB이며 CLB에서는 AWSELB



### Elastic Load Balancer - 크로스존 로드밸런싱 (Cross Zone Load Balancing)

- 크로스존 로드 밸런싱
  - 각 로드 밸런서 인스턴서는 모든 가용영역에 등록된 모든 인스턴스에 전반적으로 동일하게 트래픽을 분산해줌
- 애플리케이션 로드 밸런서
  - 교차 영역 로드 밸런싱이 기본적으로 활성화 (대상 그룹 설정에서 비활성화 가능)
  - 데이터를 다른 가용 영역으로 옮기는데 비용이 들지 않음
- 네트워크 & 게이트웨이 로드 밸런서
  - 교차 영역 로드 밸런싱이 기본적으로 비활성화
  - 활성화하려면 비용을 지불해야 함 => 가용 영역 사이에서 데이터를 옮기면 비용이 듬



### Elastic Load Balancer - SSL 인증서

- SSL / TLS 기초
  - SSL
    - SSL 인증서는 클라이언트와 로드밸런서 사이에서 트래픽이 이동하는 동안 데이터를 암호화 해줌 
    - 이를 전송 중(in -flight) 암호화라고 함
    - 데이터는 네트워크를 이동하는 동안에는 암호화되고, 송신자와 수신자 측에서만 이를 복호화할 수 있음
    - SSL은 보안 소켓 계층(Secure Sockets Layer)을 의미하고 연결을 암호화하는 데 사용
  - TLS
    - 새로운 버전의 SSL로 전송 계층 보안(Transport Layer Security)을 의미
    - 최근에는 TLS 인증서가 주로 사용되는데 사람들은 여전히 이를  SSL이라고 부르고 있음
  - 퍼블릭 SSL 인증서는 인증기관(CA - Certificate Authorities)에서 발급
    - 인증기관: Comodo, Symantec, GoDaddy, GlobalSign, Digicert, Letsencrypt, etc...
    - 퍼블릭 SSL 인증서를 로드 밸런서에 추가하면, 클라이언트와 로드 밸런서 사이의 연결을 암호화할 수 있음
  - SSL 인증서에는 만료 날짜가 있어서 주기적으로 갱신해 인증 상태를 유지해줘야 함
- 로드 밸런서 - SSL 인증서
  - 사용자가 HTTPS를 통해 로드밸런서에 접속
  - 로드 밸런서에서는 내부적으로 SSL 종료(SSL Termination)를 수행
  - 백엔드에서는 HTTP로 EC2 인스턴스와 통신 (암호화 되지 않은 상태) -> VPC로 이동하는 트래픽은 프라이빗 네트워크를 쓰기 때문에 안전하게 보호
  - 로드 밸런서는 X.509 인증서를 사용 (SSL/TLS 서버 인증서로 불림)
  - AWS에는 이 인증서들을 관리할 수 있는 ACM(AWS Certificate Manager)이 있음
  - 본인의 인증서를 ACM에 업로드할 수도 있음
  - HTTP listener를 구성할 때 반드시 HTTPS listener 로 해야함
    - 기본 인증서를 지정해줘야 함
    - 다중 도메인을 지원하기 위해 다른 인증서를 추가할 수도 있음
    - 클라이언트는 SNI(Server Name Indication - 서버 이름 지정)라는 걸 써서 접속할 호스트의 이름을 알릴 수 있음
    - 원하는 대로 보안 정책을 지정할 수 있음 => 구 버전의  SSL과 TLS(레거시 클라이언트)를 지원
- SSL - Server Name Indication(SNI)
  - 여러 개의 SSL 인증서를 하나의 웹서버에 로드해 하나의 웹 서버가 여러 개의 웹 사이트를 지원할 수 있게 해줌
  - 확장된 프로토콜로, 최초 SLL 핸드셰이크 단계에서 클라이언트가 대상 서버의 호스트 이름을 지정하도록 함
  - 클라이언트가 접속할 웹사이트를 말했을 때, 서버는 어떤 인증서를 로드해야 하는지 알 수 있음
  - **ALB 와 NLB, CloudFront에 한해서만 동작함**
- SSL 인증서 지원 항목
  - 클래식 로드 밸런서 (v1)
    - 하나의  SSL 인증서만 둘 수 있음
    - 여러 개의 인증서로 여러 호스트 이름을 지원하려면 클래식 로드 밸런서를 여러 개 둬야 함
  - 애플리케이션 노드 밸런서 / 네트워크 로드 밸런서 (v2)
    - 여러 개의 SSL 인증서를 두고 리스너를 여러 개 지원할 수 있음
    - 멀티 지원을 위해 SNI를 사용



### Elastic Load Balancer (ELB) - 연결 드레이닝(Connection Draining)

- 연결 드레이닝
  - 명명법
    - CLB: 연결 드레이닝(Connection Draining)
    - ALB & NLB: 등록 취소 지연(Deregistration Delay)
  - 인스턴스가 등록 취소, 혹은 비정상인 상태에 있을 때 인스턴스에 어느 정도의 시간을 주어 인-플라이트 요청(활성 요철)을 완료할 수 있도록 하는 기능
  - EBL는 등록 취소 중인 EC2 인스턴스로 새로운 요청을 보내지 않음
  - 연결 드레이닝 파라미터: 1~3600s (default: 300s)
  - 파라미터를 0으로 설정하면 드레이닝이 비활성화 됨
  - 짧은 요청의 경우에는 낮은 값으로 설정하면 좋음



### Auto Scaling Group(ASG) 개요

- 오토 스케일링 그룹

  - 웹사이트나 애플리케이션 배포시에, 웹사이트 방문자가 갈수록 많아지면서 로드가 바뀔 수 있음

  - 클라우드에서 서버를 빠르게 생성하고 종료할 수 있음
    - ASG의 목표
      - 증가한 로드에 맞춰 스케일 아웃 (EC2 인스턴스 추가)
      - 감소한 로드에 맞춰 스케일 인 (EC2 인스턴스 제거)
      - ASG에서 실행되는 EC2 인스턴스의 최소 및 최대 개수를 정의 가능
      - 로드 밸런서와 페어링 하는 경우 ASG에 속한 모든 EC2 인스턴스가 로드 밸런서에 연결
      - 한 인스턴스가 비정상이면 종료하고 이를 대체할 새 EC2 인스턴스를 생성

  - ASG는 무료 (EC2 인스턴스와 같은 생성된 하위 리소스에 대한 비용만 내면 됨)

- 오토 스케일링 그룹 속성
  - 시작 템플릿(Launch Template) 생성
    - AMI 및 인스턴스 유형
    - EC2 사용자 데이터
    - EBS 볼륨
    - 보안 그룹
    - SSH 키 페어
    - EC2 인스턴스의 IAM 역할
    - 네트워크 및 서브넷 정보
    - 로드 밸런서 정보
  - 최소 크기 / 최대 크기 / 초기 용량 정의
  - 스케일링 정책 정의
- 오토 스케일링 - CloudWatch Alarms & Scaling
  - CloudWatch 알람을 기반으로 ASG를 스케일 인 및 스케일 아웃할 수 있음
  - 알람은 지표(metric)을 모니터링 함(평균 CPU, 원하는 사용자 지표)
  - 알람을 기반으로
    - 스케일 아웃 정책을 만들 수 있음 (인스턴스 수 증가)
    - 스케일 인 정책을 만들 수 있음 (인스턴스 수 감소)



### Auto Scaling Group(ASG) - 스케일링 정책(Scaling Polices)

- 동적 스케일링 정책 (Dynamic Scaling Polices)

  - 대상 추적 스케일링 (Target Tracking Scaling)
    - 가장 단순하고 설정하기 쉬움
    - Ex: 모든 EC2 인스턴스에서 오토 스케일링 그룹의 평균 CPU 사용률을 추적하여 이 수치가 40%대에 머무를 수 있도록 할 때 사용
  - 단순 / 단계 스케일링 (Simple / Step Scaling)
    - CloudWatch 경보를 설정(ex: CPU 70% 초과)하고 경보가 트리거 되면 용량을 두 유닛 추가하도록 설정 가능
    - CloudWatch 경보를 설정(ex: CPU 30% 미만)하고 경보가 트리거 되면 용량을 한 유닛 제거하도록 설정 추가 가능

- 예약된 작업 (Scheduled Actions)

  - 나와 있는 사용 패턴을 바탕으로 스케일링을 예상

  - Ex: 금요일 오후 5시에 큰 이벤트가 예정되어 있으니 매주 금요일 오후 5시마다 자동으로 ASG 최소 용량을 10까지 증가

- 예측 스케일링 (Predictive Scaling)

  - 로드를 보고서 다음 스케일링을 예측

- 스케일링을 예측하기 좋은 지표

  - CPU 사용률 (CPU Utilization): 모든 인스턴스의 평균 CPU 사용률
  - 대상별 요청의 수 (Request Count Per Target): 각 EC2 인스턴스에 인스턴스가 안정적일 수 있는 최대 요청수를 정함
  - 평균 네트워크 I / O (Average Network In / Out): 애플리케이션이 네트워크와 연결된 경우
  - 커스텀 지표: CloudWatch에서 애플리케이션 별로 지표 설정하고 이를 기반으로 스케일링 정책을 바꿀 수 있음

- 스케일링 휴지 (Scaling Cooldowns)

  - 스케일링 작업이 끝날 때마다 인스턴스의 추가 또는 삭제를 막론하고 휴지 기간(default 300초)을 갖는 것
  - 휴지 기간에는 ASG가 추가 인스턴스를 실행 또는 종료할 수 없음 => 지표를 이용하여 새로운 인스턴스가 안정화 될 수 있도록 해줌
  - 즉시 사용이 가능한 AMI를 이용하여 EC2 인스턴스 구성 시간을 단축하고 이를 통해 요청을 좀 더 신속히 처리하는 것이 좋음 => 활성화 시간이 빨라지면 휴지 기간 또한 단축되기 때문에 ASG 상에서 더 많은 동적 스케일링이 가능해짐



## Section 09. AWS 기초: RDS + Aurora + ElasticCache

### Amazon RDS 개요

- RDS
  - 관계형 데이터베이스 서비스(Relational Database Service)
  - SQL을 쿼리 언어로 사용하는 데이터베이스용 관리형 데이터베이스 서비스
  - 클라우드의 RDS 서비스에 DB를 생성할 수 있고 AWS가 DB를 관리
    - Postgres
    - MySQL
    - MariaDB
    - Oracle
    - Microsoft SQL Server
    - Aurora (AWS Proprietary database)
- RDS가 주는 이점
  - 관리형 서비스
    - 데이터베이스 프로비저닝, 기본 운영체제 패치 자동화
    - 지속적으로 백업이 생성되므로 특정 타임스탬프(특정 시점)으로 복원 가능
    - 대시보드에서 모니터링 가능
    - 읽기 전용 복제본을 활용해 읽기 성능을 개선할 수 있음
    - 재해 복구 (Disaster Recovery - DR)를 위해 다중 AZ 설정 가능 
    - 유지 관리 기간에 업그레이드 가능
    - 인스턴스 유형을 늘려 수직 확장하거나 읽기 전용 복제본을 추가하여 수평 확장 가능
    - 파일 스토리지는 EBS에 구성 (gp2 or io1)
  - RDS 인스턴스에 SSH 액세스를 할 수 없음
- RDS 스토리지 오토 스케일링
  - RDS DB 인스턴스는 동적으로 스토리지를 확장해줌
  - 데이터베이스 스토리지를 수동으로 확장하는 작업을 피할 수 있게해줌
  - **최대 스토리지 임계값(Maximum Storage Threshold) 를 설정해야 함**
  -  자동 수정 조건
    - 허용된 공간에서 남은 공간이 10% 미만이 되는 경우
    - 스토리지 부족 상태가 5분 이상 지속되는 경우
    - 지난 수정으로부터 6시간이 지났을 경우
  - 워크로드를 예측할 수 없는 애플리케이션에서 굉장히 유용
  - 모든 RDS 데이터베이스 엔진에서 지원되는 기능



### RDS 읽기 전용 복제본(Read Replicas for read scalability)과 다중 AZ

- RDS 읽기 전용 복제본
  - 읽기를 스케일링
  - 최대 15개까지 생성 가능
  - 가용영역 안, 가용 영역이나 리전을 걸쳐서 생성 가능
  - 복제는 ASYNC(비동기)이므로 읽기가 항상 일관적으로 유지됨
  - 복제본은 데이터베이스로 승격시켜 이용할 수도 있음
  - 읽기 전용 복제본을 활용하려면 애플리케이션이 연결을 업데이트해야 함
- 사용 사례
  - 평균적인 로드를 감당하고 있는 프로덕션 데이터베이스
  - 데이터를 기반으로 몇 가지 보고와 분석을 하기를 원함
  - 보고 애플리케이션을 메인 RDS DB 인스턴스에 연결하면 오버로드가 발생하고 생산 애플리케이션의 속도가 느려짐
  - 새로운 워크로드에 대한 읽기 전용 복제본을 생성
  - 이 경우 생산 애플리케이션을 전혀 영향을 받지 않음
  - 읽기 전용 복제본은 SELECT 명령문에만 사용
- 네트워크 비용
  - 보통 AWS에서는 하나의 가용 영역에서 다른 가용 영역으로 데이터가 이동할 때 비용이 발생
  - RDS에서는 읽기 전용 복제본이 다른 AZ이지만 동일한 리전 내에 있을 때는 비용이 발생하지 않음 => 다른 리전인 경우는 비용 발생
- RDS 다중 AZ (Disaster Recovery)
  - 다중 AZ는 주로 재해 복구에 사용됨
  - SYNC 복제본
  - 하나의 DNS 이름을 가짐 => 마스터에 문제가 생길 때 스탠바이 데이터베이스에 자동으로 장애 조치가 수행됨
  - 가용성을 높일 수 있음
  - 전체 AZ 또는 네트워크가 손실될 때, 마스터 인스턴스 또는 스토리지에 장애가 발생할 때에 대비한 장애 조치
  - 따로 앱에 수동으로 조치를 취할 필요가 없음
  - 스케일링에 이용되지 않음 => 스탠바이 데이터베이스는 단지 대기 목적 하나만 수행
  - 읽기 전용 복제본을 다중 AZ로도 설정할 수 있음
- 단일 AZ => 다중 AZ 전환
  - 이 작업에는 다운타임이 전혀 없음 (=DB를 중지할 필요가 없음)
  - 데이터베이스 수정을 클릭하고 다중 AZ 기능을 활성화시키기만 하면 됨
  - 내부적으로 발생하는 일
    - 기본 데이터베이스의 RDS가 자동으로 스냅샷을 생성
    - 이 스냅샷은 새로운 스탠바이 데이터베이스에 복원
    - 스탠바이 데이터베이스가 복원되면 두 데이터베이스 간 동기화(SYNC)가 설정됨



### RDS Custom for Oracle과 Microsoft SQL Server

- RDS Custom
  - RDS Custom을 사용해서 Oracle 및 Microsoft SQL Server에서 OS 및 데이터베이스 사용자 지정 기능에 액세스할 수 있음
  - RDS: AWS에서의 데이터베이스 자동화 설정, 운영, 스케일링
  - Custom: 기저 데이터베이스와 운영 체제에 액세스할 수 있게 됨
    - 내부 설정 구성
    - 패치 적용
    - 네이티브 기능 활성화
    - SSH 또는 SSM 세션 관리자를 사용해서 RDS 뒤에 있는 기저 EC2 인스턴스에 액세스 가능
  - 사용자 지정 설정을 사용하려면 RDS가 수시로 자동화, 유지 관리 또는 스케일링과 같은 작업을 수행하지 않도록 **자동화를 꺼두는 것이 좋음**
  - 오류 발생 가능성이 올라가므로 데이터베이스 스냅샷을 만들어 두는 것이 좋음
  - RDS vs RDS Custom
    - RDS: 전체 데이터베이스와 OS가 AWS에 의해 관리됨
    - RDS Custom: Oracle 및 Microsoft SQL Server에서만 사용할 수 있으며 관리자 권한 전체를 갖게 됨



### Amazon Aurora 개요

- Aurora
  - AWS 고유의 기술 (오픈 소스 X)
  - Postgres 및 MySQL과 호환되도록 만들어짐
  - 클라우드에 최적화되어 있어 RDS의 MySQL보다 5배, RDS의 Postgres보다 3배 높은 성능을 가짐
  - Aurora의 스토리지는 자동으로 확장 (10GB에서 시작하여 128TB까지 확장)
  - 읽기 전용 복제본의 경우 15개의 복제본을 둘 수 있으며 복제 속도도 훨씬 빠름 (MySQL은 최대 5개)
  - Aurora의 장애조치는 즉각적임 => 클라우드 네이티브이므로 가용성이 높음
  - RDS에 비해 약 20% 비용이 높음 => 스케일링 측면에서 훨씬 더 효율적
- 높은 가용성(High Availability)과 읽기 스케일링(Read Scaling)
  - 데이터베이스에 무언가를 기록할 때마다 3AZ에 걸쳐 6개의 사본을 저장함
    - 쓰기에는 6개 사본 중 4개만 있으면 됨
    - 읽기에는 6개 사본 중 3개만 있으면 됨
    - 자가 복구 과정이 있음
    - 단일 볼륨에 의존하지 않고 수 백 개의 볼륨을 사용
  - 쓰기를 받는 인스턴스는 하나 (master)
  - 마스터가 동작하지 않으면 평균 30초 이내로 장애 조치가 시작됨
  - 복제본들은 리전 간 복제를 지원
- Aurora DB Cluster
  - 라이터(Writer) 엔드포인트
    - 라이터 엔드포인트는 DNS 이름으로 항상 마스터를 가리킴
    - 장애 조치 후에도 클라이언트는 라이터 엔드포인트와 상호작용하게 됨 => 올바른 인스턴스로 자동으로 리다이렉트 됨
  - 리더(reader) 엔드포인트
    - 라이터 엔드포인트와 같은 역할
    - 연결 로드 밸런싱에 도움을 줌
    - 모든 읽기 전용 복제본과 자동으로 연결됨
    - **로드 밸런싱은 문장 레벨이 아닌 연결 레벨에서 일어남**
  - 공유 스토리지 볼륨
    - 자동 스케일링
    - 자동 확장
- Aurora의 기능
  - 자동 장애 조치
  - 백업 및 복구
  - 격리 및 보안
  - 산업 규정 준수
  - 버튼식 스케일링
  - 제로 다운타임 자동 패치 설치
  - 고급 모니터링
  - 통상 유지 관리
  - 백트랙: 과거 어떤 시점의 데이터로도 복원할 수 있게 해줌 (백업에 의존 X)

 

### Amazon Aurora - 고급 개념

- Aurora Replicas - Auto Scaling
  - 리더 엔드포엔트에서 많은 읽기 요청이 발생
  - Aurora DB의 CPU 사용량 증가
  - 복제본 오토 스케일링으로 인한 복제본 추가
  - 리더 엔드포인트가 새 복제본을 처리하도록 확장됨
  - 새로운 복제본은 트래픽을 받기 시작하고, 읽기가 더 분산된 방식으로 발생함
  - 전체 CPU 사용량이 낮아짐
- Aurora - 사용자 지정 엔드포인트 (Custom Endpoints)
  - Aurora 인스턴스의 하위 집합을 사용자 지정 엔드포인트로 정의
  - Example: 특정 복제본에 대해 분석 쿼리를 실행할 수 있음
  - 리더 엔드포인트는 일반적으로 사용자 지정 엔드포인트를 정의한 후에는 사용되지 않음
- Aurora Serverless
  - 실제 사용량에 따라 자동화된 데이터베이스 인스턴스화 및 오토 스케일링을 제공
  - 워크로드가 드물거나 간헐적이거나 예측할 수 없는 경우에 유용
  - 용량 계획을 세울 필요가 없음
  - 각 Aurora 인스턴스에 초당 요금을 지불하게 되므로 비용 효율적임
- Aurora 멀티 마스터(Multi-Master)
  - 라이터 노드에 대해 지속적인 쓰기 가용성을 원하는 경우
  - Aurora 클러스터에서 모든 Aurora 인스턴스는 라이터 노드가 됨
- Global Aurora
  - 리전 간 읽기 복제본이 있는 경우
    - 재해 복구에 매우 유용
    - 설치가 매우 간단
  - Aurora Global Database 설정 가능 (권장 됨)
    - 기본 리전에서 읽기 및 쓰기가 모두 일어남
    - 최대 5개의 보조 읽기 전용 리전도 있음 => 복제 지연이 1초 미만
    - 보조 리전당 최대 16개의 읽기 복제본을 설정할 수 있음
    - 읽기 워크로드 지연 시간을 줄일 수 있음
    - 재해 복구를 위해 다른 리전을 활성화할 때 복구 시간 목표 (RTO)를 1분 미만으로 할 수 있음
- Aurora Machine Learning
  - Aurora 머신러닝은 애플리케이션에 머신러닝 기반 예측을 적용할 수 있음
  - Aurora와 AWS ML 서비스 간의 간단하고 최적화된 안전한 통합
  - 지원되는 서비스
    - Amazon SageMaker (모든 종류의 머신러닝 모델을 사용할 수 있게 해줌)
    - Amazon Comprehend (감성 분석 가능)
  - 머신러닝 경험이 없어도 됨
  - 사용 사례: 사기 탐지, 광고 타겟팅, 감정 분석, 제품 추천 등



### RDS & Aurora - 백업과 모니터링

- RDS Backups
  - 자동화된 백업
    - 자동으로 매일 데이터베이스의 전체 백업을 수행 (데이터베이스 백업 기간 동안)
    - 5분마다 트랜잭션 로그가 백업 => 가장 빠른 백업은 5분 전의 백업
    - 자동 백업 보존 기간은 1~35일 사이로 설정 가능
    - 백업 보존 기간을 0으로 설정 시 자동 백업을 사용하지 않게 됨
  - 수동 DB 스냅샷 (Manual DB Snapshots)
    - 사용자가 수동으로 트리거
    - 수동으로 한 백업을 원하는 기간 동안 유지할 수 있음 (자동 백업은 만료 됨)
  - 스냅샷은 RDS 데이터베이스의 실제 스토리지 비용보다 훨씬 저렴하므로 DB를 지속적으로 사용하는게 아니라면 스냅샷을 뜬 뒤에 RDS 데이터베이스를 삭제하고 DB를 사용시에 스냅샷을 사용해 복원하면 비용을 절감할 수 있음

- Aurora Backups
  - 자동화된 백업
    - 1~35일 사이로 설정 가능 => 비활성화 불가
    - 시점 복구 기능 => 해당 기간의 어느 시점으로든 복구 가능
  - 수동 DB 스냅샷
    - 사용자가 수동으로 트리거
    - 수동으로 한 백업을 원하는 기간 동안 유지할 수 있음 (자동 백업은 만료 됨)
- RDS & Aurora 복원 옵션 (Restore options)
  - RDS 또는 Aurora의 백업 또는 스냅샷은 새 데이터베이스로 복원이 가능
  - S3에서 MySQL 데이터베이스를 복원이 가능
    - 온프레미스 데이터베이스의 백업을 생성
    - 객체 스토리지인 Amazon S3에 백업 파일 배치
    - MySQL을 실행하는 새 RDS 인스턴스로 백업 파일을 복원
  - S3에서 MySQL Aurora 클러스터로 복원이 가능
    - 온프레미스 데이터베이스를 다시 백업 (Percona XtraBackup 소프트웨어 사용)
    - 객체 스토리지인 Amazon S3에 백업 파일 배치
    - MySQL을 실행하는 새 Aurora 클러스터로 백업 파일을 복원
- Aurora Database Cloning
  - 기존 데이터베이스 클러스터에서 새로운 Aurora 데이터베이스 클러스터를 생성할 수 있음
  - 스냅샷을 찍고 복원하는 것보다 훨씬 빠름
  - copy-on-write 프로토콜을 사용
    - 처음 데이터베이스 복제본을 만들 때는, 원래 데이터베이스 클러스터와 동일한 데이터 볼륨을 사용하게 됨 (빠르고 효율적 => 데이터 복사 X)
    - 새로운 DB 클러스터 데이터에 업데이트가 이루어지면 새로운 추가 스토리지가 할당되고, 데이터가 복사 및 분리됨
  - 매우 빠르고 비용 효율적
  - 프로덕션 데이터베이스에 영향을 주지 않으면서 데이터베이스를 복제하는 데 매우 유용



### RDS Security

- RED & Aurora Security
  - 저장된 데이터 암호화 (At-rest encryption)
    - KMS를 사용해 마스터와 모든 복제본의 암호화가 이루어짐 (DB를 처음 실행할 때 정의됨)
    - 마스터 DB를 암호화하지 않았다면 읽기 전용 복제본을 암호화할 수 없음
    - 암호화 되어있지 않은 기존 DB를 암호화 하려면 암호화 되지 않은 DB의 DB 스냅샷을 가지고 와서 암호화된 DB 형태로 DB 스냅샷을 복원해야 함
  - 전송 중 데이터 암호화 (In-flight encryption)
    - RDS 및 Aurora의 각 DB는 기본적으로 전송 중 데이터 암호화 기능을 갖추고 있음
    - 클라이언트는 AWS 웹사이트에서 제공하는 AWS의 TLS 루트 인증서를 사용해야 함
  - IAM 인증 (IAM Authentication)
    - IAM 역할을 사용해서 데이터베이스에 접속이 가능 (username/pw 방식 대신)
  - 보안 그룹 (Security Groups)
    - 보안 그룹을 사용하여 DB에 대한 네트워크 액세스를 통제할 수 있음
    - 특정 포트, IP, 보안 그룹을 허용하거나 차단 가능
  - RDS와 Aurora에는 SSH 액세스가 없음 (RDS 커스텀 서비스는 예외)
  - DB 확인을 위해 감사 로그 작성(Audit Logs)을 활성화 할 수 있으며 로그를 장기간 보관하고 싶으면 CloudWatch Logs 전용 서비스로 전송해야 함



### RDS Proxy

- Amazon RDS Proxy
  - 완전 관리형 RDS 데이터베이스 프록시 (Fully managed database proxy for RDS)
  - Amazon RDS 프록시를 사용하면 애플리케이션이 데이터베이스 내에서 DB 연결 풀을 형성하고 공유할 수 있음
  - RDS 데이터베이스 인스턴스에 직접 연결을 줄여 CPU와 RAM 등 데이터베이스 리소스의 부담을 줄여 데이터베이스 효율성을 향상시킬 수 있고 데이터베이스에 개방된 연결과 시간초과를 최소화할 수 있음
  - 서버리스, 오토 스케일링 (용량 관리 X), 높은 가용성 (다중 AZ)
  - RDS & Aurora 장애조치 시간이 66%까지 감소
  - RDS (MySQL, PostgreSQL, MariaDB) 및 Aurora (MySQL, PostgreSQL) 지원
  - 애플리케이션 코드를 변경하지 않아도 됨
  - 데이터베이스에 IAM 인증을 강제함으로써 IAM 인증을 통해서만 RDS 데이터베이스 인스턴스에 연결하도록 할 수 있음 
    - 자격 증명은 AWS Secrets Manager 서비스에 안전하게 저장됨
  - RDS는 퍼블릭 엑세스가 절대로 불가능 (VPC 내에서만 액세스 가능) => 보안 훌륭



### ElastiCache 개요

- Amazone ElastiCache

  - RDS가 관계형 데이터베이스를 관리하는 것과 같은 방식
  - ElastiCache는 캐싱 기술인 Rdis 또는 Memcached를 관리할 수 있도록 도와줌
  - 캐시는 매우 높은 성능과 짧은 지연 시간을 가진 인메모리 데이터베이스
  - 읽기 집약적인 워크로드에서 데이터베이스의 로드를 줄여줌 => 일반적인 쿼리는 캐시에 저장되므로, 매번 데이터베이스를 쿼리하지 않아도 됨
  - 애플리케이션을 상태 비저장형(application stateless)으로 할 수 있게 도와줌
  - AWS는 데이터베이스의 운영 체제를 유지 관리할 수 있음
    - 패치, 최적화, 설정, 구성, 모니터링, 장애 복구, 백업
  - ElastiCache를 사용하는 경우, 애플리케이션의 코드를 많이 바꿔야함

-  ElastiCache Solution Architecture - DB Cache

  - 애플리케이션은 쿼리를 ElastiCache에 작성 => 쿼리가 이미 발생했는지 확인을 위함
  - 캐시 히트(ElastiCache에 해당 쿼리가 저장): 쿼리를 수행하기 위해 DB로 이동하는 시간이 절약
  - 캐시 미스: DB에서 데이터를 가지고 옴
  - RDS의 로드를 줄이는데 도움을 줌
  - 캐시 무효화 전략이 필요 => 가장 최신 데이터만 사용되어야하므로

- ElastiCache Solution Architecture - User Session Store

  - 사용자가 어떤 애플리케이션에 로그인
  - 애플리케이션이 세션 데이터를 Amzone ElastiCache에 작성
  - 사용자가 애플리케이션의 다른 인스턴스로 리디렉션되면 애플리케이션은 그 세션의 세션 캐시를  ElastiCache에서 직접 검색이 가능 => 사용자는 여전히 로그인 상태가 됨
  - 애플리케이션을 상태 비저장형으로 만듬

- ElastiCache - Redis vs Memcached

  - Redis

    - **다중 AZ**: 자동 장애 조치 기능
    - **읽기 복제본**: 읽기를 확장하고 **고가용성**을 가짐
    - AOF 지속성을 이용한 **데이터 내구성**
    - **백업 및 복원 기능**
    - 세트 및 정렬된 세트를 제공

  - Memcached

    - 데이터 분할을 위해 멀티 노드 사용 (샤딩<sup>sharding</sup>이라고 함)
    - **고가용성 없음** **(= 복제가 일어나지 않음)**
    - **영구적이지 않음**
    - **백업 및 복원 없음**

    - 멀티스레드 아키텍처



### 솔루션 설계자를 위한 한 ElastiCache

- Cache Security
  - Redis에서만 IAM 인증을 지원
  - ElastiCache에서 IAM 정책을 정의하면 AWS API 수준 보안에만 사용됨
  - Redis AUTH
    - Redis 클러스트를 만들 때, Redis 내 보안을 통해 비밀번호와 토큰을 설정할 수 있음
    - 캐시에 추가 보안 수준을 제공하는 것 (보안 그룹에 추가로)
    - SSL 전송 중 암호화 지원
  - Memcached
    - SASL 기반 승인을 제공
- ElasticCache을 로드하는 패턴
  - 지연 로딩 (Lazy Loading)
    - 모든 데이터가 캐시되고 데이터가 캐시에서 지체될 수 있음
  - Write Through
    - DB에 데이터가 기록될 때마다 캐시에 데이터를 추가하거나 업데이트
    - 데이터가 지체되지 않음
  - 세션 스토어 (Session Store)
    - 캐시에 임시 세션 데이터를 저장
    - 유지 시간 기능(TTL features)을 사용해 세션을 만료할 수 있음
  - 컴퓨터 과학에서 가장 어려운 것 두 가지는 캐싱 무효화와 이름 붙이기
- Redis 사용 사례
  - 게이밍 리더보드 만들기
  - Redis Sorted Sets는 고유성과 요소 순서를 모두 보장함
  - 요소가 추가될 때마다, 실시간으로 순위를 매긴 다음 올바른 순서로 추가됨





## Section 09. Route 53

### DNS

- DNS란?

  - DNS (Domain Name System):  사람에게 친숙한 호스트 이름을 대상 서버 IP 주소로 번역해 줌
  - ex: www.google.com => 172.217.18.36
  - DNS는 인터넷의 중추로 URL과 호스트 이름을 IP로 변환
  - DNS는 계층적 이름 구조가 있음

- DNS 관련 용어 (Terminologies)

  - 도메인 레지스트라 (Domain Registrar): 도메인 이름을 등록하는 곳 - Route 53, GoDaddy, ...
  - DNS 레코드 (DNS Records): A, AAAA, CNAME, NS, ...
  - 존 파일 (Zone File): 모든 DNS 레코드를 포함
  - 이름 서버 (Name Server): DNS 쿼리를 실제로 해결하는 서버
  - 최상위 도메인 (Top Level Domain - TLD): .com, .us, .in, .gov, .org, ...
  - 2단계 도메인 (Second Level Domain - SLD): amazon.com, google.com, ...
  - FQDN: 전체 주소 도메인 이름 (Fully Qualified Domain Name) 의 약자 => 프로토콜까지 포함된 이름

- DNS 동작 방법

  ![KakaoTalk_Photo_2023-10-15-19-40-28](/Users/iseongheon/Downloads/KakaoTalk_Photo_2023-10-15-19-40-28.jpeg)



### Route 53 개요

- Amazon Route 53

  - 고가용성, 확장성을 갖춘 완전히 관리되며 권한있는 DNS
  - 권한있는 = 고객이 DNS 레코드를 업데이트 할 수 있음 (DNS에 대한 완전한 제어가 가능)
  - 도메인 이름 레지스트라 (Domain Registrar)
  - Route 53 리소스 관련 상태 확인이 가능
  - 100% SLA 가용성을 제공하는 유일한 AWS 서비스
  - 53: 전통적인 DNS 포트

- 레코드 (Records)

  - 레코드를 통해 특정 도메인으로 라우팅하는 방법 정의
  -  레코드의 포함 요소
    - 도메인 / 서브도메인 이름 (ex - example.com)
    - 레코드 종류 (ex - A or AAAA)
    - 값 (ex - 123.456.789.123)
    - 라우팅 정책 - Route 53이 쿼리에 응답하는 방식
    - TTL (Time To Live) - DNS 리졸버(resolver)에서 레코드가 캐싱 되는 시간
  - Route53에서 제공하는 DNS 레코드 종류
    - (반드시 알아야하는 것) A / AAAA / CNAME / NS 
    - (고급 사항) CAA / DS / MX / NAPTR / PTR / SOA / TXT / SPF /SRV

- 레코드 타입 (Record Types)

  - A: 호스트 이름과 IPv4 주소를 매핑
  - AAAA: 호스트 이름과 IPv6 주소를 매핑
  - CNAME: 호스트 이름을 다른 호스트 이름과 매핑
    - 대상 호스트 이름은 A나 AAAA 레코드가 될 수도 있음
    - DNS 이름 공간 또는 Zone Apex의 상위 노드에 대한 CNAMES를 생성할 수 없음
    - Ex - example.com에 CNAME을 만들 수는 없지만, www.example.com에 대한 CNAME 레코드는 만들 수 있음
  - NS: 호스팅 존의 이름 서버
    - 트래픽이 도메인으로 라우팅 되는 방식을 제어함

- 호스팅 존 (Hosted Zones)

  - 레코드의 컨테이너: 도메인과 서브도메인으로 가는 트래픽의 라우팅 방식을 정의
  - 퍼블릭 호스팅 존 (Public Hosted Zones)
    - 인터넷에서 트래픽을 라우팅하는 방법을 지정하는 레코드가 포함 (공개 도메인 이름)
  - 프라이빗 호스팅 존 (Private Hosted Zones)
    - 공개되지 않는 도메인 이름을 지원
    - 가상 프라이빗 클라우드(VPC)만이 URL을 리졸브 할 수 있음 (비공개 도메인 이름)
  - 호스팅 존 하나당 월에 50센트를 지불해야 함

  

### Route 53 - TTL (Time To Live)

- Records TTL
  - 높은 TTL
    - Route 53에 발생하는 트래픽이 감소
    - 클라이언트가 오래된 레코드를 받을 가능성이 커짐
  - 낮은  TTL
    - Route 53에 트래픽 증가 (높은 비용)
    - 레코드 변경이 빨라짐
  - 별칭 레코드(Alias records)를 제외하고 TTL은 모든 DNS 레코드에서 필수적임



### Route 53 - CNAME vs Alias

- CNAME vs Alias
  - AWS 리소스(로드 밸런서, 클라우드 프론트 등)는 호스트 이름이 노출됨
    - 보유한 도메인에 호스트 이름을 매핑하기를 원함
  - CNAME
    - 호스트 이름이 다른 호스트 이름으로 향하도록 할 수 있음
    - **루트 도메인 이름이 아닌 경우에만 가능** (mydomain.com 에선 안됨)
  - Alias
    - 호스트 이름이 특정 AWS 리소스로 향하도록 할 수 있음
    - **별칭 레코드는 루트 및 비루트 도메인 모두에 작동**
    - 무료
    - 자체적으로 상태 확인 가능
- 별칭 레코드 (Alias Records)
  - AWS 리소스에만 매핑이 되어 있음
  - DNS의 확장 기능 (시중의 모든 DNS에서 가능)
  - 기반 ALB에서 IP가 바뀌면 별칭 레코드는 자동으로 인식
  - CNAME과 달리, 별칭 레코드는 Zone Apex라는 DNS 네임스페이스의 상위 노드로 사용될 수 있음 (ex - example.com)
  - AWS 리소스를 위한 별칭 레코드의 타입은 항상 A 또는 AAAA (IPv4 / IPv6)
  - **TTL을 설정할 수 없음 (Route 53에 의해 자동으로 설정)**
- 별칭 레코드 대상
  - Elastic Load Balancer
  - CloudFront Distributions
  - API Gateway
  - Elastic Beanstalk environments
  - S3 Websites
  - VPC Interface Endpoints
  - Global Accelerator accelerator
  - Route 53 Record (동일 호스트 존)
  - **EC2의 DNS 이름에 대해서는 별칭 레코드를 설정할 수 없음**



### 라우팅 정책 - 단순

- 라우팅 정책
  - Route 53이 DNS 쿼리에 응답하는 것을 도움
  -  라우팅이라는 단어를 혼동하면 안됨
    - 로드밸런서가 트래픽을 백엔드 EC2 인스턴스로 라우팅하는 것과는 다름
    - 여기서 라우팅은 트래픽이 아닌 DNS 관점 (트래픽은 DNS를 통과하지 않음)
  - Route 53가 지원하는 라우팅 정책
    - 단순 (Simple)
    - 가중치 기반 (Weighted)
    - 장애 조치 (Failover)
    - 지연 시간 기반 (Latency based)
    - 지리적 (Geolocation)
    - 다중 값 응답 (Multi-Value Answer)
    - 지리 근접 라우팅 (Geoproximity)
- 단순 라우팅 정책
  - 트래픽을 단일 리소스로 보내는 방식
  - 동일한 레코드에 여러 개의 값을 지정하는 것도 가능
  - DNS에 의해 다중 값을 받은 경우에는 클라이언트 쪽에서 그 중 하나를 무작위로 고르게 됨
  - 별칭 레코드를 함께 사용하면 하나의 AWS 리소스만을 대상으로 지정할 수 있음
  - 상태 확인은 할 수 없음



### 라우팅 정책 - 가중치

- 가중치 라우팅 정책
  - 가중치를 활용해 요청의 일부 비율을 특정 리소스로 보내는 식의 제어가 가능
  - 각 레코드로 보내지는 트래픽의 양(%) 
    - 해당 레코드의 가중치 / 전체 가중치
    - 전체 가중치의 합은 100이 아니어도 됨
  - DNS 레코드들은 동일한 이름과 유형을 가져야 함
  - 상태 확인과도 관련될 수 있음
  - 사용 케이스
    - 서로 다른 지역들에 걸쳐 로드 밸런싱
    - 새 애플리케이션 테스트
  - 가중치 0의 값을 보내게 되면 특정 리소스에 트래픽 보내기를 중단해 가중치를 바꿀 수 있음
  - 모든 리소스 레코드 가중치의 값이 0인 경우에는 모든 레코드가 다시 동일한 가중치를 갖게 됨



### 라우팅 정책 - 대기 시간

- 지연 시간 기반 라우팅 정책
  - 지연 시간이 가장 짧은(=가장 가까운) 리소스로 리다이렉팅을 하는 정책
  - 지연 시간에 민감한 웹사이트나 애플리케이션이 있는 경우 아주 유용
  - 지연 시간은 유저가 레코드로 가장 가까운 식별된 AWS 리전에 연결하기까지 걸리는 시간을 기반으로 측정됨
  - ex - 독일 유저는 미국에 있는 리소스의 지연시간이 가장 짧다면, 해당 유저는 미국 리전으로 리다이렉팅 됨
  - 상태 확인과 연결이 가능



### Route 53 - 상태 확인

- 상태 확인
  - 공용 리소스에 대한 상태를 확인하는 방법
  - DNS의 장애 조치를 자동화하기 위한 작업
  - 세 가지의 상태 확인이 가능
    - 공용 엔드 포인트를 모니터링 (애플리케이션, 서버, 다른 AWS 리소스)
    - 다른 상태 확인을 모니터링하는 상태 확인 (계산된 상태 확인이라 불림)
    - CloudWatch 경보의 상태를 모니터링하는 상태 확인 (제어가 쉽고 개인 리소스들에 아주 유용)
  - 상태 확인들은 각자의 매트릭을 사용하며 CloudWatch의 지표에서도 확인이 가능
- 특정 엔드 포인트에서 작동 방식
  - 전 세계에서 온 15개의 상태 확인이 엔드 포인트의 상태를 확인
    - 정상 / 비정상 임계값: 3번 (default)
    - 간격: 30초 / 10초
    - 지원 프로토콜: HTTP, HTTPS, TCP 등
    - 18% 이상의 상태 확인이 엔드 포인트를 정상이라고 판단하면 Route 53도 이를 정상이라고 간주함
    - 상태 확인에서 사용될 위치도 선택할 수 있음
  - 상태 확인은 로드 밸런서로부터 2xx나 3xx의 코드를 받아야만 통과가 됨
  - 텍스트 기반 응답일 경우 응답은 처음 5120 바이트를 확인 => 응답 자체에 해당 텍스트가 있는지 보기 위함
  - 상태 확인의 작동이 가능하려면 Route 53 상태 확인이 애플리케이션 밸런서나 엔드 포인트에 접근이 가능해야 함
    - Route 53의 상태 확인 IP 주소 범위에서 들어오는 모든 요청을 허용해야 함
- 계산된 상태 확인 (Calculated Health Checks)
  - 여러 개의 상태 확인 결과를 하나로 합쳐주는 기능
  - 상태 확인들을 모두 합치기 위한 조건으로 OR, AND, NOT을 사용할 수 있음
  - 하위 상태 확인을 256개까지 모니터링 가능
  - 상위 상태 확인이 통과하기 위해 몇 개의 상태 확인을 통과해야 하는지도 지정할 수 있음
  - 사용 케이스: 상태 확인이 실패하는 일 없이 상위 상태 확인이 웹사이트를 관리 유지하도록 하는 경우
- 개인 리소스 (Private Hosted Zones) 상태 확인
  - Route 53 health checkers는 VPC 외부에 있음
  - 개인 엔드포엔트에 접근할 수가 없음 (개인 VPC or 온프레미스 리소스)
  - CloudWatch 지표를 만들어 CloudWatch 알람을 할당하는 식으로 이 문제를 해결할 수 있음



### 라우팅 정책 - 장애 조치

- 장애 조치 라우팅 정책

  - Primary / Secondary - Disaster Recovery => 각각 하나씩

  - 상태 확인과 기본 레코드를 연결
  - 상태 확인이 비정상적이면 자동으로 2번째의 레코드로 장애 조치를 함



### 라우팅 정책 - 지리적 위치

- 지리 위치 라우팅 정책
  - 사용자의 실제 위치를 기반으로 함
  - Ex - 사용자가 미국인 경우에 특정 레코드로 가도록 지정 
  - 기본 레코드를 생성해야 함 (일치하는 위치가 없는 경우를 위해)
  - 사용 사례: 콘텐츠 분산을 제한하고 로드 밸런식 등을 실행하는 웹사이트 현지화
  - 상태 확인과 연결할 수 있음



### 라우팅 정책 - 지리적 근접성

- 지리 근접 라우팅 정책
  - 사용자와 리소스의 지리적 위치를 기반으로 트래픽을 리소스로 라우팅하도록 함
  - 이 정책으로 편향값을 사용해 특정 위치를 기반으로 리소스를 더 많은 트래픽으로 이동하는 것
  - 지리적 위치를 변경하려면 편향값을 지정해야 함
    - 확장 (To Expand) (1 to 99): 더 많은 트래픽을 보내려면 편향값을 증가
    - 감소 (To shrink) (-1 to -99): 더 적은 트래픽을 보내려면 편향값을 음수로 설정
  - 리소스
    - AWS 리소스 (특정 AWS 리전 지정)
    - Non-AWS 리소스 (특정 위도 경도 지정)
  - 편향 활용을 위해 고급 Route 53 트래픽 플로우를 사용해야만 함



### 라우팅 정책 - IP-based

- IP 기반 근접 라우팅 정책
  - 클라이언트 IP 주소를 기반으로 라우팅을 정의
  - Route 53에서 CIDR 목록(클라이언트의 IP 범위)을 정의하고 CIDR에 따라 트래픽을 어느 로케이션으로 보내야 하는지 정함
  - 사용 케이스: 성능 최적화, 네트워크 비용 절감
  - Ex: 특정 인터넷 제공업체가 특정 IP 주소 셋을 사용하는 걸 안다면 특정 엔드포인트로 라우팅 가능



### 라우팅 정책 - 다중 값

- 다중 값 라우팅 정책
  - 트래픽을 다중 리소스로 라우팅할 때 사용
  - Route 53은 다중 값과 리소스를 반환
  - 상태 확인과 연결하면 다중값 정책에서 반환하는 유일한 리소스는 정상 상태 확인과 관련이 있음
  - 각각의 다중 값 쿼리에 최대 8개의 정상 레코드가 반환됨
  - **ELB와 유사해 보이지만 ELB를 대체할 수는 없음** (클라이드 측면의 로드 밸런싱 느낌)



### 타사 도메인 및 Route 53

- Domain Registar vs DNS Service
  - 도메인 이름 레지스트라를 통해 원하는 도메인 이름을 구매할 수 있음 (매년 비용 지불)
  - 레지스트라를 통해 도메인을 등록하면 DNS 레코드 관리를 위한 DNS 서비스를 제공
  - 하지만 DNS 레코드로 AWS Route 53 등을 사용하지 않고 다른 DNS 서비스를 사용할 수 있음
- GoDaddy as Registrar & Route 53 as DNS Service
  - GoDaddy에서 도메인 등록을 하면 이름 서버 옵션이 생겨서 사용자 정의 이름 서버를 지정할 수 있음
  - Amazone Route 53에서 원하는 도메인의 공용 호스팅 영역을 생성하고 호스팅 영역 상세의 오른쪽 부분에서 이름 서버를 찾음
  - GoDaddy의 이름서버를 해당 이름 서버로 변경

- Domain Registrar != DNS Service



## Section 11.  클래식 솔루션 아키텍처 토론

### WhatsTheTime.com

- Stateless Web App: WhatIsTheTime.com
  - WhatIsTheTime.com 은 사람들에게 시간을 알려줌
  - 데이터베이스가 필요 없음
  - 우리는 작은 것부터 시작하고 다운타임을 수용할 수 있기를 원함
  - 우리는 다운타임이 없이 수직 및 수평적으로 확장하기를 원함
  - 이 앱에 대한 솔루션 아키텍트 여정을 배우게 될 것임
- Stateless Web App:
  - Route 53(별칭 레코드) + ELB + 헬스체크 + 다중 AZ + 오토 스케일링 그룹 + EC2 + 보안 그룹 규칙
  - 예약 인스턴스을 통한 비용 절감
- 기억 할 것
  - 공용 vs 사설 IP 와 EC2 인스턴스
  - 탄력적 IP vs Route 53 vs 로드 밸런서
  - Route 53 TTL, A 레코드와 별칭 레코드
  - EC2 인스턴스 수동으로 관리  vs 오토 스케일링 그룹
  - 다중 AZ
  - ELB 헬스 체크
  - 보안 그룹 규칙
  - 예약 인스턴스
  - 비용, 성능, 신뢰성, 보안, 탁월한 운영을 고려해서 아키텍처를 설계하자 



### MyClothes.com

- Stateful Web App: MyClothes.com
  - 사람들이 온라인으로 옷을 살 수 있음
  - 장바구니 기능
  - 동시간에 수백 명의 사용자가 웹사이트를 둘러보고 있음
  - 확장을 할 수 있어야 하고 수평 확장성을 유지하며 애플리케이션의 웹 티어를 최대한 무상태로 유지하고 싶음
  - 사용자가 웹사이트를 둘러볼 때 장바구니의 상태는 유지되어야 함
  - 주소 등의 사용자 정보를 데이터베이스에 효과적으로 보관해야 함
- Stateful Web App
  - ElasticCache, DynamoDB (단기적 저장) / RDS (장기적 저장) And Multi AZ
  - RDS => 읽기 복제본,  ElasticCache
  - ELB 보안 그룹 설정(HTTPS)
- 기억 할 것
  - ELB 고정 세션 (Sticky session)
  - 쿠키 저장을 위한 웹 클라이언트 웹 앱을 무상태로 만드는 법
  - ElasticCache
    - 세션 ID와 세션 캐시 저장을 위해 사용 (대안: DynamoDB)
    - RDS로부터 데이터 캐시
    - 다중 AZ
  - RDS
    - 사용자 데이터 저장
    - 읽기 확장을 위한 읽기 전용 복제본
    - 다중 AZ
  - 서로 참조하는 보안 그룹을 만들기 위해 타이트하게 보안을 추가



### MyWordPress.com

- Stateful Web App: MyWordPress.com
  - 완전히 확장 가능한 웹사이트
  - 웹사이트에 접근하기 쉬우며, 업로드한 그림이 바르게 나타나길 원함
  - 사용자 데이터와 블로그 내용 등 모든게 MySQL 데이터베이스에 저장되야 함
- Stateful Web App
  - Aurora MySQL
    - 다중 AZ
    - 읽기 전용 복제본
    - 글로벌 데이터베이스
  - ENI, EFS
- 기억 할 것 
  - Aurora Database (다중 AZ, 읽기 전용 복제본)
  - EBS 데이터 저장 (하나의 인스턴스 애플리케이션)
  - EFS 데이터 저장 (분산 애플리케이션)



### 애플리케이션을 빠르게 인스턴스화 하기

- 풀 스택 실행법
  - 애플리케이션 설치
  - 데이터 삽입 및 복구
  - 모든 내용을 구성
  - 애플리케이션 실행
- 빠르게 인스턴스화 하는 법
  - EC2 인스턴스
    - Golden AMI 사용
      - 애플리케이션과 OS 종속성 등 모든 것을 사전에 설치하고 그것으로부터 AMI를 생성
      - 이후로는 EC2 인스턴스들을 Golden AMI로부터 직접 실행
    - EC2 사용자 데이터 사용한 부트스트랩
      - 부트스트래핑은 기본적으로 인스턴스가 처음 시작될 때 구성하는 것을 의미
      - 애플리케이션, OS 종속성 등을 설치하기 위해 부트스트래핑 사용 (But 느림)
      - 동적 구성에서 사용자 데이터를 사용하여 부트스프래핑을 활용
    - 하이브리드
      - Golden AMI + User Data (Elastic Beanstalk)
  -  RDS 데이터베이스
    - 스냅샷으로부터 복구: 데이터베이스에서 스키마와 데이터가 준비
  - EBS 볼륨
    - 스냅샷으로부터 복구: 필요한 데이터를 가지고 있는 적절히 포맷되어 있는 디스크가 준비



### Beanstalk 개요

- AWS에서 개발자의 어려움
  - 인프라 관리
  - 코드 배포
  - 데이터 베이스, 로드 밸런서 등을 설정
  - 스케일링

- Elastic Beanstalk - 개요
  - Elastic Beanstalk은 개발자 입장에서 애플리케이션을 AWS에 배포
  - 하나의 인터페이스에 우리가 살펴본 모든 컴포넌트들 (EC2, ASG, ELB, RDS, ...) 을 재사용한다는 개념
  - 관리되는 서비스
    - 용량 프로비저닝, 로드밸런서 설정, 스케일링, 애플리케이션 상태 모니터링, 인스턴스 설정
    - 개발자는 코드 자체만 담당하면 됨
  - 하지만 개발자는 모든 컴포넌트의 설정에 대한 완벽한 통제력을 갖게 됨
  - Beanstalk은 무료이지만 활용하는 인스턴스나 ASG, ELB 등에 대해서는 비용을 지불
- Elastic Beanstalk - 컴포넌트
  - 애플리케이션: Elastic Beanstalk 컴포넌트 컬렉션 (환경, 버전, 설정 등)
  - 애플리케이션 버전: 애플리케이션 코드 버전
  - 환경 (Environment)
    - 특정한 애플리케이션 버전을 실행하는 리소스들의 컬렉션 (어떤 환경에서 하나의 애플리케이션 버전만 가질 수 있음)
    - 티어 (Tiers)
      - 웹 서버 환경 티어
      - 워커 환경 티어
    - 다양한 환경을 생성할 수 있음 (dev, test, prod, ...)
- Elatic Beeanstalk - 지원 플랫폼
  - Go
  - Java SE
  - Java with Tomcat
  - .NET Core on Linux
  - .NET on Windows Server
  - Node.js
  - PHP
  - Python
  - Ruby
  - Packer Builder
  - Single Container Docker
  - Multi-container Dokcer
  - Preconfigured Docker
  - Custom platform
-  Web Server Tier vs Wokrer Tier	![KakaoTalk_Photo_2023-10-28-22-55-38](/Users/iseongheon/Downloads/KakaoTalk_Photo_2023-10-28-22-55-38.jpeg)

- Elastic Beanstalk Deployment Modes
  - Single Instance Great for dev : 하나의 EC2 인스턴스, 탄력적 IP, RDB Master => 개발용에 적합
  - High Availability with Load Balancer Greate for prod : 다수의 EC2 인스턴스, 오토 스케일링, 멀티  AZ 등 => 운영용에 적합







## Section 12.  Amazon S3 소개

### S3 개요

- Amazon S3

  - S3는 AWS의 주요 구성 요소
  - 무한하게 확장할 수 있는 스토리지
  - 많은 웹사이트들이 S3를 사용
  - 많은 AWS 서비스들이 S3를 통합을 위해 사용

- Amazon S3 - Use cases

  - 백업과 스토리지
  - 재해 복구
  - 아카이브
  - 하이브리드 클라우드 스토리지
  - 애플리케이션 호스팅
  - 미디어(동영상 파일이나 이미지 등) 호스팅
  - 데이터 레이크 & 빅데이터 분석
  - 소프트웨어 딜리버리
  - 정적 웹사이트

- Amazon S3 - Buckets

  - S3는 버킷(디렉토리)에 객체(파일)를 저장함
  - 버킷은 반드시 전역적으로 고유한 이름이 있어야 함 (모든 리전과 AWS에 존재하는 모든 계정에서)
  - 버킷은 리전 수준에서 정의됨
  - S3는 전역 서비스처럼 보이지만 버킷은 사실상 리전에서 생성됨
  - 명명 규칙 (기억할 필욘 없음)
    - 대문자나 밑줄이 없어야함
    - 3 ~ 63자 사이
    - IP X
    - 소문자나 숫자로 시작해야 함
    - 문자, 숫자, 하이픈만 됨
    - 몇 가지 접두사, 접미사 제한이 있음

- Amazon S3 - Objects

  - 객체 (파일)는 키를 가짐
  - 키는 파일의 전체 경로
    - s3://my-bucket/**my_file.txt**
  - 키는 접두사와 객체 이름으로 구성되어 있음
    - s3://my-bucket/**my_folder/another_folder/my_file.txt**
  - Amazone S3 그 자체로는 디렉토리의 개념은 없음
  - 키는 길이가 굉장히 긴 이름으로 슬래시를 포함하며, 키는 접두사와 객체 이름으로 만들어짐

  

- Amazon S3 - Objects 구성요소

  - 값은 본문의 내용
    - 최대 객체 크기는 5TB
    - 업로드하는 파일이 5GB보다 크다면 멀티파트 업로드를 사용해서 해당 파일을 여러 부분으로 나눠 업로드해야 함
  - 메타데이터 (객체의 키-값 쌍 리스트 => 시스템이나 사용자에 의해 설정됨)
  - 태그 (유니코드 키-값 쌍 => 최대 10개)
    - 보안과 수명 주기에 유용
  - 버전 ID (버전 관리를 활성화 한 경우)



### S3 보안 및 버킷 정책

- Amazon S3 - 보안
  - 사용자 기반
    - IAM 정책 - 어떤 API 호출이 특정 IAM 사용자를 위해 허용되어야 하는지를 승인
  - 리소스 기반
    - 버킷 정책 - S3 콘솔에서직접 할당할 수 있는 전체 버켓 정책
    - 객체 엑세스 제어 목록 (ACL - Object Access Control List) - 세밀한 보안 (비활성화 가능)
    - 버킷 엑세스 제어 목록 (ACL - Bucket Access Control List) - 덜 일반적 (비활성화 가능)
  - IAM 원칙이 S3 객체에 엑세스하는 상황
    - IAM 권한이 이를 허용하거나 리소스 정책이 이를 허용하는 경우
    - 명백한 거부느 없음
  - 암호화 (Encryption): 암호키를 사용하여 객체를 암호화

- S3 Bucket Policies

  - JSON 기반의 정책

    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Sid": "PublicRead",
          "Effect": "Allow",
          "Principal": "*",
          "Action": [
            "s3:GetObject"
          ],
          "Resource": [
            "arn:aws:s3:::examplebucket/*"
          ]
        }
      ]
    }
    ```

    - 리소스 (Resource) : 정책이 적용되는 버킷과 객체
    - 결과 (Effect) : 액션을 허용 또는 거부
    - 액션 (Action) : API 집합을 허용하거나 거부
    - 원칙 (Principal) : 정책을 적용할 계정 또는 사용자를 제시

  - 버킷 정책 사용

    - 버킷에 대한 공개 액세스를 허용
    - 업로드 시 객체를 강제로 암호화
    - 또 다른 계정으로의 액세스를 허용

- 블록 공개 액세스 (Block Public Access)에 대한 보안 설정 

  - 기업 데이터 유출을 방지하기 위한 추가 보안 계층으로서 AWS가 개발
  - 버킷을 공개하면 안 되는 경우, 이 설정을 그대로 두면 잘못된 S3 버킷 정책을 설정한 사람들에 대해 이러한 수준의 보안을 갖출 수 있음
  - 계정 레벨에서 설정이 가능



### S3 웹사이트

- Amazon S3 - 정적 웹사이트 호스팅
  - S3는 웹 사이트를 호스팅하고 인터넷에서 액세스할 수 있게 만들 수 있음
  - 웹 사이트 URL은 이것을 생성하는 AWS 리전에 따라 달라짐 (2가지 경우)
    - http://bucket-name.s3-website-aws-region.amazonaws.com
    - http://bucket-name.s3-website.aws-region.amazonaws.com
  - 읽기를 위해 버킷을 활성화한 후 403 Forbidden 오류가 발생한다면, 버킷을 공개로 해야함



### S3 버전 관리

- Amazon S3 - Versioning
  - S3에서는 파일을 버전 관리할 수 있음
  - 버킷 수준에서 활성화해야 하는 설정
  - 동일한 키를 업로드하고 해당 파일을 덮어쓰는 경우 버전2, 버전3 등을 생성하게 됨
  - 버킷을 버전 관리하는 것이 좋음
    - 의도하지 않게 삭제하지 않도록 보호 (이전 버전 복구 가능)
    - 이전 버전으로 쉽게 롤백할 수 있음
  -  주의 사항
    - 버전 관리를 활성화하기 전에 버전 관리가 적용되지 않은 모든 파일은 널(null) 버전을 갖게 됨
    - 버전 관리를 중단해도 이전 버전을 삭제하지는 않음



### S3 복제

- Amazon S3 - Replication (CRR - 교차 리전 복제 & SRR - 같은 리전 복제)
  - 소스 버킷과 복제 대상 버킷 둘 모두 버전 관리 기능이 활성화되어야 함
  - Cross-Region Replication (CRR)
  - Same-Region Replication (SRR)
  - 버킷은 서로 다른 AWS 계정간에도 사용할 수 있음
  - 복제는 비동기식으로 이루어짐
  - S3에 적절한 IAM 권한(읽기, 쓰기)이 필요
  - 사용 사례
    - CRR - 컴플라이언스, 법규나 내부 체제 관리, 지연 시간을 줄일 경우, 계정간 복제
    - 다수의 S3 버킷간의 로그 통합, 운영 환경과 개발 환경간의 실시간 복제를 필요로 할 때

- Amazon S3 - Replication Notes
  - 복제를 활성화한 후에는 새로운 객체만 복제 대상이 됨
  - 기존의 객체를 복제하려면 S3 배치 복제 기능을 사용해야 함
    - 기존 객체부터 복제에 실패한 객체까지 복제할 수 있는 기능
  - 작업을 삭제하는 법
    - 소스 버킷에서 대상 버킷으로 삭제 마커를 복제 (설정에서 선택 가능)
    - 버전 ID로 삭제하는 경우 버전 ID는 복제되지 않음 (악의적인 삭제를 피하기 위해)
  - 체이닝 복제는 불가
    - 1번 버킷이 2번에 복제되어 있고 2번 버킷이 3번 버킷에 복제돼 있다고 해서 1번 버킷의 객체가 3번 버킷으로 복제되지 않음



### S3 스토리지 클래스

- S3 Stroage Classes
  - Amazon S3 Standard-General Purpose
  - Amazon S3 Standard-Infrequent Access (IA)
  - Amazon S3 One Zone-Infrequent Access 
  - Amazon S3 Glacier Instant Retrival
  - Amazon S3 Clacier Deep Archive
  - Amazon S3 Intelligent Tiering
  - 스토리지 클래스를 수동으로 또는 Amazon S3 수명 주기 구성을 사용해서 수정할 수 있음
- S3 내구성(Durability)과 가용성(Availability)
  - 내구성
    - 아마존 S3에 의해 객체가 손실되는 횟수
    - 높은 내구성을 가짐 (99.999999999%의 내구성 보장)
    - S3에 천만 개의 객체를 저장했을 때 평균적으로 10,000년에 한 번 객체 손실이 예상됨
    - 모든 스토리지 클래스의 내구성은 동일
  - 가용성
    - 서비스가 얼마나 용이하게 제공되는지를 나타냄
    - 스토리지 클래스에 따라 다름
    - Example: S3 standard의 가용성은 99.99% => 1년에 약 53분 동안은 서비스를 사용할 수 없음
- S3 Stroage Classes - General Purpose
  - 99.99% 가용성
  - 자주 액세스하는 데이터에 사용됨
  - 지연 시간이 짧고 처리량이 높음
  - AWS에서 2개의 기능 장애를 동시에 버틸 수 있음
  - 사용 사례: 빅 데이터 분석, 모바일과 게임 애플리케이션, 콘텐츠 배포
- S3 Stroage Classes - Infrequent Access
  - 자주 액세스하지는 않지만 필요한 경우 빠르게 액세스해야  하는 데이터에 유용
  - S3 standard보다 낮은 비용 (but, 검색 비용 발생)
  - Amazon S3 Standard-Infrequent Access
    - 99.9% 가용성
    - 사용 사례: 재해 복구, 백업
  - Amazon S3 One Zone-Infrequent Access 
    - 단일 AZ에서 높은 내구성 (99.999999999%) => AZ가 파괴되면 데이터를 잃게 됨
    - 99.5% 가용성
    - 사용 사례: 온프레미스 데이터를 2차 백업, 재생성 가능한 데이터를 저장
-  S3 Stroage Classes - Glacier Storage Classes
  - 아카이빙과 백업을 위한 저비용 객체 스토리지
  - 스토리지 비용 + 검색 비용
  - Amazon S3 Glacier Instant Retrival
    - 밀리초 단위로 검색 가능, 분기에 한 번 액세스하는 데이터에 아주 적합
    - 최소 보관 기간 90일
    - 백업이지만 밀리초 이내에 액세스 해야할 때 적합
  - Amazon S3 Glacier Flexible Retrival
    - Expedited (1 ~ 5분 이내), Standard (3 ~ 5시간 이내), Bulk (5 ~ 12시간) => 무료
    - 최소 보관 기간 90일
  - Amazon S3 Glacier Deep Archive - 장기 보관
    - Standard (12시간),  Bulk (48시간)
    - 최소 보관 기간 180일
- S3 Stroage Classes - S3 Intelligent Tiering
  - 사용 패턴에 따라 액세스된 티어 간에 객체를 이동할 수 있게 해줌
  - 소액의 월별 모니터링 비용과 티어링 비용이 발생
  - 검색 비용이 없음
  - Frequent Access Tier (자동): 기본 티어
  - Infrequent Access Tier (자동): 30일 동안 액세스하지 않는 객체 전용 티어
  - Archive Instant Access tier (자동): 90일 동안 액세스하지 않는 객체 전용 티어
  - Archive Access tier (선택): 90일에서 700일 이상까지 액세스하지 않는 객체에 구성 가능
  - Deep Archive Access tier (선택): 180일에서 700일 이상까지 액세스하지 않는 객체에 구성 가능





## Section 13. 고급 Amazon S3

### S3 수명 주기 규칙

- Amazon S3 - 스토리지 클래스 간 객채 옮기기
  - 객체에 액세스를 자주 하지 않는다면 Standard IA로 이전 가능
  - 객체를 아카이브화 하려는 걸 알고 있다면 Glacier 티어나  Deep Archive 티어로 이전 가능
  - 객체들은 라이프사이클 규칙을 이용해서 자동으로 옮길 수도 있음
- Amazon S3 - Lifecycle Rules
  - Transition Actions - 다른 스토리지 클래스로 이전하기 위해 객체를 설정
    - 생성된지 60일 후에 Standard IA 클래스로 이전
    - 6개월 후에 Glacier 티어로 이동시켜 아카이브화
  - Expiration actions - 일정한 시간 뒤에 만료되어서 객체를 삭제하도록 객체를 설정
    - 액세스 로그 파일들을 365일 후에 삭제할 수 있음
    - 버저닝을 사용중이라면 오래된 버전의 파일들을 삭제할 수 있음
    - 불완전한 멀티파트 업로드를 삭제할 수 있음
  - 규칙은 버킷 정체에 적용하거나 버킷 안의 특정한 경로에 적용할 수 있음
  - 규칙은 특정한 객체 태그에 대해 지정할 수도 있음
- Amazon S3 Analytics - Storage Class Analysis
  - 올바른 스토리지 클래스로 객체를 전환할 수 있도록 도와줌
  - Standard 나 Standard IA 에 관한 추천사항을 제시
    - One-Zone IA나 Glacier와는 호환되지 않음
  - 보고서는 매일 업데이트 됨
  - 데이터 분석 결과가 나오는 게 보일때까지는 24 ~ 48시간이 걸림
  - 합리적인 라이프사이클 규칙들을 조합하거나 개선하기 위한 좋은 첫걸음임



### S3 요청자 지불

- S3 - 요청자 지불
  - 일반적으로는 버킷 소유자가 버킷과 관련된 모든 Amazon S3 스토리지 및 데이터 전송 비용을 지불
  - 요청자 지불 버킷은 버킷 소유자가 아니라 요청자가 객체 데이터 다운로드 비용을 지불
  - 대량의 데이터 셋을 다른 계정과 공유하려고 할 때 매우 유용
  - 요청자가 AWS에서 인증을 받아야 함( = 익명이어서는 안됨)



### S3 이벤트 알림

- S3 Event Notifications
  - 이벤트
    - S3:ObjectCreated, S3: ObjectRemoved, S3:ObjectRestore, S3:Replication...
  - 오브젝트 이름 필터링이 가능 (*.jpg)
  - 사용 사례: S3에 업로드된 모든 이미지의 섬네일을 생성
  - 원하는 만큼 S3 이벤트를 만들 수 있고, 어떤 타깃에도 전송할 수 있음
  - S3 이벤트들은 통상적으로 몇 초 안에 대상으로 전달되지만 간혹 몇 분 정도 걸릴 수도 있음
- S3 Event Notifications - IAM Permissions
  - SNS 리소스 정책: SNS 토픽에 첨부하는 IAM 정책으로 S3 버킷이 SNS 토픽에 직접 메시지를 전송하도록 허용해줌
  - SQS 리소스 정책: S3 서비스가 SQS Queue에 데이터를 전송하도록 허가해줌
  - 람다 리소스 정책: S3 서비스가 람다 함수를 호출할 권한을 제공해줌
- S3 Event Notifications with Amazon EventBridge
  - 이벤트 -> S3 -> Amazone EventBridge
  - 모든 이벤트는 결국 Amazon EventBridge로 가게 됨
  - EventBridge에서 규칙을 설정할 수 있으며, 그 규칙들 덕분에 이벤트들을 18가지 AWS 서비스에 전송할 수 있음
  - EventBridge를 JSON 룰과 함께 사용하면 훨씬 많은 고급 필터링 옵션을 사용할 수 있음 (메타데이터, 객체 사이즈, 이름 등)
  - 다수의 전송 가능 - ex) Step Functions, Kinesis Streams, Firehose
  - EventBridge 기능 - 아카이빙, 이벤트 중계, 안정적 전달



### S3 퍼포먼스

- S3 - 기준 성능
  - Amazon S3는 요청이 아주 많을 때 자동으로 확장됨
  - 지연 시간 100~200ms
  - S3는 버킷 내에서 접두사당 초당 3,500개의 PUT/COPY/POST/DELETE 요청과 5,500개의 GET/HEAD 요청을 지원
  - 버킷 내에서 접두사 수에 제한이 없음
  - 접두사가 네 개이고 각각의 접두사에 읽기 요청을 균등하게 분산하면 초당 22,000개의 GET/HEAD 요청을 처리할 수 있음
- S3 - 성능
  - 멀티파트 업로드 (Multi-Part upload)
    - 100MB가 넘는 파일에 추천
    - 5GB가 넘는 파일은 반드시 사용해야 함
    - 업로드를 병렬화하므로 전송 속도를 높여 대역폭을 최대화할 수 있음
  - S3 전송 가속화 (Transfer Acceleration)
    - 파일을 AWS 엣지 로케이션으로 전송해서 전송 속도를 높이고 데이터를 대상 리전에 있는 S3 버킷으로 전달
    - 엣지 로케이션은 리전보다 수가 많음 
    - 멀티파트 업로드와 같이 사용할 수 있음
- S3 성능 - S3 바이트 범위 가져오기 (Byte-Range Fetches)
  - 파일에서 특정 바이트 범위를 가져와서 GET 요청을 병렬화함
  - 특정 바이트 범위를 가져오는 데 실패한 경우에 더 작은 바이트 범위에서 재시도 => 복원력이 높음
  - 다운로드 속도를 높일 때 사용
  - 파일의 일부만 검색해야할 때 사용



### S3 셀렉트 & Glacier 셀렉트

- S3 Select & Glacier Select
  - SQL 문을 사용해 서버측 필터링을 수행함으로 인해 더 적은 양의 데이터를 검색
  - 행과 열을 사용해 필터링 가능 (간단한 SQL문)
  - 클라이언트 측에서 네트워크 전송이 줄어들고, CPU 비용도 줄어듬
  - 속도는 400% 빨라지고 비용은 80% 줄어듬



### S3 Batch Operations

- S3 Batch Operation
  - 단일 요청으로 기존 S3 객체에서 대량 작업을 수행하는 서비스
    - 한 번에 많은 S3 객체의 메타데이터와 프로퍼티를 수정할 수 있음
    - 배치 작업으로 S3 버킷 간에 객체를 복사할 수 있음
    - **S3 버킷 내에 암호화 되지 않은 모든 객체를 암호화 할 수 있음**
    - ACL, 태그 수정 가능
    - S3 Glacier에서 한 번에 많은 객체를 복원할 수 있음
    - Lambda 함수를 호출해 S3 Batch Operations의 모든 객체에서 사용자 지정 작업을 수행할 수도 있음
  - 작업은 객체의 목록, 수행할 작업 옵션 매개 변수로 구성됨
  - S3 Batch Operation을 사용하면 재시도를 관리할 수 있고 진행 상황을 추적하고 작업 완료 알림을 보내고 보고서 생성 등을 할 수 있음
  - S3 Inventory라는 기능을 사용해 객체 목록을 가져오고 S3 Select를 사용해 객체를 필터링



## Section 14. Amazon S3 보안

### S3 암호화

- Amazon S3 - Object Encryption
  - S3 버킷에 있는 객체들을 암호화하는 방법은 네가지가 있음
  - Server-Side Encryption (SSE)
    - SSE-S3: Amazon S3에서 관리하는 키를 이용한 서버 측 암호화 (기본으로 활성화)
    - SSE-KMS: KMS 키를 이용해서 암호화 키를 관리
    - SSE-C: 고객이 제공한 키를 사용
  - Client-Side Encryption
- Amazon S3 Encryption - SSE-S3
  - AWS가 처리하고 관리하고 소유한 키를 이용해서 암호화
  - 객체는 서버 측에서 암호화가 됨
  - 보안 유형은 AES-256
  - 헤더를 "x-amz-server-side-encryption": "AES256" 으로 설정해야 함
  - SSE-S3는 새로운 버킷과 새로운 객체에 대해 기본값으로 활성화되어 있음
- Amazone S3 Encryption - SSE-KMS
  - AWS KMS, 즉 키 관리 서비스를 이용해서 직접 자신의 키를 관리
  - KMS 장점: 사용자가 키를 통제 + 키를 사용할 때마다 CloudTrail에 로깅됨
  - 객체는 서버 측에서 암호화가 됨
  - 헤더를 "x-amz-server-side-encryption": "aws:kms" 으로 설정해야 함
- SSE-KMS Limitation
  - 업로드를 할 때, GenerateDataKey KMS 자체 API를 사용해서 암호화를 해야함
  - 다운로드를 할 때 Decrypt API를 사용해서 복호화를 해야함
  - 모든 API 사용은 KMS의 초당 API 호출 쿼터에 합산 됨 (리전마다 초당 5500 / 10000 / 30000 요청이 가능)
  - S3 버킷의 처리량이 아주 많고 모든 게 KMS 키로 암호화되어 있다면 일종의 스로틀링 활용 사례가 될 수 있음
-  Amazon S3 Encryption - SSE-C
  - 키가 AWS 외부에서 관리되지만 여전히 서버 측 암호화임
  - Amazon S3는 우리가 제공한 암호화 키를 절대 저장하지 않음
  - HTTPS가 반드시 사용됨
  - 모든 요청에 HTTP 헤더의 일부로서 키를 전달해야 함
- Amazon S3 Encryption - Client-Side Enctytion
  - 클라이언트 라이브러리를 활용
  - 클라리언트 측 암호화는 클라이언트가 직접 데이터를 암호화한 다음에 Amazon S3에 전송
  - 데이터의 복호화는 Amazon S3 외부의 클라이언트 측에서 이루어짐
  - 클라이언트가 키와 암호화 사이클을 완전하게 관리
- Amazon S3 - Encryption in transit (SSL / TLS)
  - 전송 중 암호화 또는 통신 중 암호화는 SSL 또는 TLS 라고 부름
  - Amazon S3는 2개의 엔드포인트가 있음
    - HTTP Endpoint - 암호화 X
    - HTTPS Endpoint - 전송 중 암호화 O
  - HTTPS  사용을 권고
  - SSE-C 타입의 매커니즘을 이용한다면 HTTPS 프로토콜이 필수
- 전송 중 암호화 강제하기
  - S3 버킷 정책 - Statement - Condition - Bool - was:SecureTransport 를 false 로 설정



### S3 기본 암호화

- S3 기본 암호화

  - 모든 버킷은 기본값으로 SSE-S3 암호화가 되어 있음

  - 버킷 정책을 이용해서 암호화를 강제하고 올바른 암호화 헤더가 없는 경우에는 S3 객체를 PUT하는 API 호출을 거절할 수 있음

  - 버킷 정책은 기본값보다 선제적으로 평가되기 때문에 원하는 암호화를 강제할 수 있음



### S3 CORS 

- CORS?
  - Cross-Origin Resource Sharing (CORS)
  - Origin = scheme (protocol) + host (domain) + port
  - CORS는 웹 브라우저 기반 보안 메커니즘으로 메인 오리진을 방문하는 동안 다르 오리진에 대한 요청을 허용하거나 거부함
  - Same origin: 같은 scheme + host + port
  - 요청 체계의 일부로 다른 웹사이트에 요청을 보내야 할 때 다른 오리진이 CORS 헤더를 사용해서 요청을 허용하지 않는 한 해당 요청은 이행되지 않음 => 액세스 제어 허용 오리진 헤더
- Amazon S3 - CORS
  - 클라이언트가 S3 버킷에서 교차 오리진 요청을 하면 정확한 CORS 헤더를 활성화해야 함
  - 이 작업을 빠르게 수행하려면 특정 오리진을 허용하거나 *를 붙여 모든 오리진을 허용



### S3 MFA Delete

- Amazon S3 - MFA Delete
  - MFA (Multi-Factor Authentication) - 사용자가 장치에서 코드를 생성하도록 강제함
  - MFA가 필요한 경우
    - 객체 버전을 영구적으로 삭제할 때
    -  버킷에서 버저닝을 중단할 때
  - MFA가 필요하지 않은 경우
    - 버저닝을 활성화할 때
    - 삭제된 버전을 나열할 때
  - MFA Delete를 사용하려면 먼저 버킷에서 버저닝을 활성화해야 함
  - 버킷 소유자, 즉 루트 계정만이 MFA Delete를 활성화하거나 비활성화할 수 있음



### S3 액세스 로그

- S3 Access Logs
  - 감사 목적으로 S3 버킷에 대한 모든 액세스를 기록할 수 있음
  - 어떤 계정에서든 S3로 보낸 모든 요청은 승인 또는 거부 여부와 상관없이 다른 S3 버킷에 파일로 기록됨
  - 해당 데이터는 Amazon Athena 같은 데이터 분석 도구로 분석할 수 있음
  - 대상 로깅 버킷은 같은 AWS 리전에 있어야 함
- 주의할 점
  - 로깅 버킷을 모니터링하는 버킷과 동일하게 설정하면 안됨
  - 동일하게 설정하면 로깅 루프가 생성되고 무한 반복되어 버킷의 크기가 기하급수적으로 증가하게 됨



### S3 사전 서명된 URL

- Amazon S3 - Pre-Signed URLs
  - S3 콘솔, CLI, SDK를 사용하여 생성할 수 있는 URL
  - URL 만료 기한
    - S3 콘솔 : 최대 12시간
    - AWS CLI : 최대 168시간
  - 미리 서명된 URL을 생성할 때 URL을 받는 사용자는 URL을 생성한 사용자의 GET 또는 PUT에 대한 권한을 상속함
  - 예시
    - 로그인한 사용자만  S3 버킷에서 프리미엄 비디오를 다운로드할 수 있도록 허용
    - 사용자 목록이 계속 변하는 경우 URL을 동적으로 생성해서 파일을 다운로드할 수 있게 해줌
    - 일시적으로 사용자가 S3 버킷의 특정한 위치에 파일을 업로드하도록 허용



### S3 잠금 정책 및 Glacier 볼트 잠금

- S3 Glacier Vault Lock
  - WORM (Write Once Read Many = 한 번 쓰고 여러 번 읽는다) 모델을 채택
  - 볼트 잠금 정책을 생성 
  - 향후 편집을 위해 정책을 잠금 (누구도 변경하거나 삭제할 수 없음)
  - 규정 준수와 데이터 보존에 아주 유용
- S3 Object Lock (버저닝 활성화 필수)
  - WORM 모델을 채택
  - 객체 잠금은 전체 S3 버킷 수준의 잠금 정책이 아니라 버킷 내의 모든 객체에 각각 적용할 수 있는 잠금
  - 특정 객체 버전이 특정 시간 동안 삭제되는 걸 차단할 수 있음
  - 보존 모드 (Retention mode) - 규정 준수 (Compliance)
    - 사용자를 포함한 그 누구도 객체 버전을 덮어쓰거나 삭제할 수 없음
    - 보존 모드 자체도 변경할 수 없으며, 보존 기간도 단축할 수 없음
  - 보존 모드 (Retention mode) - 거버넌스 (Governance)
    - 대부분의 사용자는 객체 버전을 덮어쓰거나 삭제하거나 로그 설정을 변경할 수 없음
    - 관리자 같은 일부 사용자는 IAM을 통해 부여받은 특별 권한으로 보존 기간을 변경하거나 객체를 바로 삭제할 수 있음
  - 보존 기간 (Retention Period): 고정된 기간 동안 객체를 보호할 수 있고, 원하는 만큼 기간을 연장할 수 있음
  - 법적 보존 (Legal Hold)
    - 법적 보존을 설정하면 S3 버킷 내 모든 객체를 무기한으로 보호함
    - S3:PutObjectLegalHold IAM 권한을 가진 사용자는 어떤 객체에든 법적 보존을 설정하거나 제거할 수 있음



### S3 액세스 포인트

- S3 - Access Points
  - 엑세스 포인트는 S3 버킷의 보안 관리를 간소화해줌
  - 각각의 엑세스 포인트
    - 각자의 DNS 이름을 가짐 (인터넷 오리진 or VPC 오리진)
    - 엑세스 포인트 정책 (버킷 정책과 비슷) 첨부 - 보안 관리를 스케일링 가능

- S3 - Access Points - VPC Origin
  - S3 액세스 포인트의 VPC 오리진을 프라이빗 액세스가 가능하도록 정의할 수 있음
  - 액세스 포인트에 접근하기 위해 VPC 엔드포인트를 만들어야 함
  - VPC 엔드포인트에는 정책이 있고 그 정책은 타깃 버킷과 액세스 포인트에 대한 액세스를 허용해 줘야 함



### S3 오브젝트 람다

- S3 Object Lambda
  - 호출자 애플리케이션이 객체를 받기 직전에 그 객체를 수정하려는 경우에 사용
  - S3 액세스 포인트와 S3 오브젝트 람다 액세스 포인트가 필요
  - 사용 사례
    - 분석기나 비프로덕션 환경을 위해 PII 데이터, 즉 개인식별정보를 삭제하는 경우
    - 데이터 형식을 XML에서 JSON으로 변환하는 경우
    - 즉석에서 이미지 크기를 조정하거나 워터마크를 추가



## Section 15. CloudFront 및 AWS 글로벌 액셀러레이터

### CloudFront 개요

- AWS CloudFront

  - Content Delevery Nextwork (CDN)
  - 서로 다른 엣지 로케이션에 미리 캐싱하여 읽기 성능을 높임 => 사용자 경험을 높임
  - 216개의 엣지 로케이션을 통해 구성
  - 컨텐츠가 전체적으로 분산되어 있으므로 DDoS 공격에서 보호를 받을 수 있음 (Shield, 어플리케이션 방화벽)

- CloudFront - Origins

  -  S3 bucket
     - CloudFront를 통해 파일을 분산하고 캐싱할 수 있게 함
     - 원본 접근 제어 (OAC, Origin Access Control) 를 통해 버킷에서는 CloudFront만 접근할 수 있게 보장
     - OAC 는 기존의 OAI (Origin Access Identity) 를 대체
     - Ingress를 사용할 수 있음 (S3에 파일을 업로드)
  -  Custom Origin (HTTP)
     - 애플리케이션 로드 밸런서
     - EC2 인스턴스
     - S3 웹사이트 (버킷을 활성화해서 정적 웹사이트로 설정해야 함)

- CloudFront vs S3 Cross Region Replication (교차 리전 복제: CRR)

  - CloudFront

    - 글로벌 엣지 네트워크
    - TTL에 의해 파일이 캐싱됨
    - 전세계를 대상으로 한 정적 컨텐츠를 사용하고자 할 때 용이

  - S3 Cross Region Replication

    - 복제를 원하는 각 리전에 이 설정이 되어 있어야 함 (전세계 대상이 아님)
    - 파일은 거의 실시간으로 갱신됨 => 캐싱 X
    - 읽기 전용으로만 설정이 가능
    - 일부 리전을 대상으로 동적 컨텐츠를 낮은 지연 시간으로 제공하고자 할 때 용이

    

### CloudFront - 어플리케이션 로드 밸런서를 원본으로 쓸 경우

- CloudFront - ALB or EC2 as an origin
  - EC2를 원본으로 사용하는 경우: EC2인스턴스를 public으로 열어주고 엣지 로케이션을 public으로 설정
  - ALB를 원본으로 사용해서 EC2에 접근하는 경우: ALB를 public으로 열어주고 엣지 로케이션을 public으로 설정 => EC2 인스턴스는 로드밸런서의 보안 그룹에 의해 private가 가능



### CloudFront - 지리적 제한 설정

- CloudFront Geo Restriction
  - 사용자들의 지역에 따라 배포 객체 접근을 제한할 수 있음
    - 접근리스트 (Allowlist): 접근이 가능한 국가 목록을 만들 수 있음
    - 블락리스트 (Blocklist): 접근이 불가능한 국가 목록을 만들 수 있음
  - 국가는 서드 파티 지역 DB에서 설정한 것으로, 사용자의 IP가 어떤 국가에 해당하는지를 확인할 수 있음
  - 사용 사례: 컨텐츠 저작권법으로 인한 제한



### CloudFront - Price Classes

- CloudFront - Pricing
  - CloudFront 엣지 로케이션은 전 세계에 고루 분포
  - 엣지 로케이션마다 데이터 전송 비용이 다름
- CloudFront - Price Classes
  - 비용 절감을 위해 CloudFront를 분산할 전 세계 엣지 로케이션 수를 줄일 수 있음
  - 세가지 가격 등급이 있음
    - Price Class All: 모든 리전 - 최상의 성능
    - Price Class 200: 가장 비싼 리전들을 제외한 대부분의 리전
    - Price Class 100: 가장 저렴한 리전



### CloudFront - Cache Invalidation

- CloudFront - Cache Invalidations
  - CloudFront에는 항상 백엔드 오리진이 있음
  - CloudFront 엣지 로케이션은 백엔드 오리진이 업데이트 될 때 업데이트 사항을 모름 => 캐시의 TTL 이 만료되면 백엔드 오리진으로부터 업데이트된 콘텐츠를 받음
  - 캐시 무효화를 통해 전체 또는 일부의 캐시를 강제로 새로고침해서 캐시에 있는 TTL을 모두 제거할 수 있음
  - 전체 파일 또는 특정 파일 경로를 무효화할 수 있음 (* or /images/*)



### AWS Global Accelerator

- Unicast IP vs Anycast IP
  - Unicast IP
    - 하나의 서버가 하나의 IP 주소를 가짐
  - Anycast IP
    - 모든 서버가 동일한 IP 주소를 가짐
    - 클라이언트는 가장 가까운 서버로 라우팅됨
- AWS Global Accelerator
  - 애플리케이션을 라우팅하기 위해 AWS 내부 글로벌 네트워크를 활용
  - 하나의 애플리케이션에서 2개의 Anycast IP가 생성됨
  - 애니캐스트 IP는 사용자와 가장 가까운 엣지 로케이션으로 트래픽을 직접 전송
  - 엣지 로케이션은 사설 AWS 네트워크를 거쳐 애플리케이션 로드 밸런서로 트래픽을 전송
  - 특징
    - 탄력적 IP, EC2 인스턴스, ALB, NLB, public or private
    - 안정적인 성능
      - 뭔가 잘못될 경우에는 신속한 리전 장애 조치가 이루어짐
      - 아무것도 캐시하지 않기에 클라이언트 캐시와도 문제가 없음 (IP는 변하지 않음)
      - 내부 AWS 네트워크
    - 상태 확인 (Health Checks)
      - Global Accelerator가 애플리케이션에 대해 상태 확인을 실행
      - 애플리케이션이 글로벌한지 확인 (장애발생 시 1분 안에 정상 엔드 포인트로 실행)
      - 재해 복구에 뛰어남
    - 보안
      - 2개의 외부 IP만 화이트리스트에 있으면 됨
      - AWS Shield에 의해 DDoS 보호
- AWS Global Accelerator vs CloudFront
  - 공통점
    - 동일한 글로벌 네트워크를 사용하고 전 세계의 엣지 로케이션을 사용함
    - DDoS 보호를 위해 AWS Shield와 통합
  - 차이점
    - CloudFront
      - 이미지나 비디오처럼 캐시 가능한 내용과 API나 동적 사이트 서빙처럼 동적 내용 모두에 대해 성능을 향상
      - 콘텐츠는 엣지 로케이션으로부터 제공됨
    - Global Accelerator
      - TCP나 UDP상의 다양한 애플리케이션 성능을 향상시킴
      - 패킷은 엣지 로케이션으로부터 하나 이상의 AWS 리전에서 실행되는 애플리케이션으로 프록시됨 => 캐싱  X
      - 게임이나 IoT 또는 Voice over IP 같은 비 HTTP를 사용할 경우에 매우 적합
      - 글로벌하게 고정 IP를 요구하는 HTTP를 사용할 때도 매우 유용
      - 결정적이고 신속한 리전 장애 조치가 필요할 때도 좋음





## Section 16. AWS 스토리지 추가 기능

### AWS Snow Family

- AWS Snow Family
  - 아주 안전한 휴대기기를 말하며, 이것을 활용하여 엣지에서 데이터를 수집하고 처리하거나 데이터를 AWS 안팎으로 마이그레이션
  - 데이터 마이그레이션 (Data migration)
    - Snowcone
    - Snowball Edge
    - Snowmobile
  - 엣지 컴퓨팅 (Edge computing)
    - Snowcone
    - Snowball Edge
- Data Migrations with AWS Snow Family
  - 네트워크를 통해 데이터를 전송하면 많은 시간이 걸림
  - 빠르게 전송하기 위한 챌린지
    - 연결 제한
    - 대역폭 제한
    - 데이터 전송 비용
    - 공유되는 대역폭
    - 불안정한 연결
  - Snow Family
    - 데이터 마이그레이션을 할 수 있게 해주는 오프라인 기기
    - AWS는 우편을 통해 실제로 물리적인 기기를 배송해 줌
    - 데이터를 해당 기기에 로딩하고 다시 AWS에 송부
    - AWS는 해당 기기를 받아 자체 인프라에 삽입 후 해당 서비스로 가져오기나 내보내기를 함
- Snowball Edge 
  - 테라바이트나 페타바이트 용량의 데이터를 AWS와 교환하기 위해 사용
  - 네트워크를 통해 데이터를 옮기는 대신에 사용
  - 데이터 전송 작업당 비용을 지불
  - 블록 스토리지나 Amazon S3 호환 객체 스토리지를 제공
  - 스토리지가 최적화된 스노우볼 엣지
    - 80TB 용량의 하드디스크 용량이 제공
    - 블록 볼륨이나 S3 호환 객체 스토리지로 사용
  - 컴퓨팅이 최적화된 스노우볼 엣지
    - 용량은 42TB 또는 28TB
  - 사용 사례
    - 대규모 데이터의 클라우드 마이그레이션
    - 데이터센터 폐지
    - 재난복구
- Snowcone
  - 아주 작은 휴대 기기(2.1kg)이고, 견고하며 안전
  - 데이터의 양이 적은 환경에 사용
  - 에지 컴퓨팅, 스토리지, 데이터 전송에 사용됨
  - 8TB의 HDD 스토리지 혹은 14TB SSD가 장착
  - 공간제약이 있는 환경
  - 배터리와 케이블은 직접 준비해야 함
  - 오프라인으로 데이터를 발송하는 방법과 기기에 데이터를 담은 다음에 인터넷 연결이 가능할 때 그걸 데이터 센터에 연결하는 방법이 있음
    - 후자의 방법은 AWS DataSync 서비스를 사용해서 데이터를 다시 AWS에 전송
- AWS Snowmobile
  - 데이터를 옮기는 실제 트럭
  - 엑사바이트급 데이터를 옮길 수 있음 (1EB = 1000 PB = 1000000 TB)
  - 한 대의 용량은 100PB
  - 매우 안전하고, 온도 조절이 가능, GPS 추적과 24시간 감시가 가능
  - 10PB 이상의 데이터를 옮긴 경우 Snowball 보다 더 좋음
- What is Edge Computing?
  - 엣지 컴퓨팅은 엣지 위치에서 데이터를 생성하는 중에 그 데이터를 처리하는 것을 의미
  - 엣지 위치
    - 인터넷이 없거나 클라우드에서 멀리 떨어져 있는 모든 것
    - 도로에 있는 트럭이나 바다에 있는 배, 지하에 있는 광산 등
    - 연결이 제한되거나 인터넷에 접속할 수 없거나 컴퓨팅 능력에 액세스 할 수 없는 경우
  - 엣지 컴퓨팅을 위해 Snowball Edge / Snowcone 을 주문하고 세팅할 수 있음
  - 활용 사례
    - 데이터 전처리
    - 엣지에서 이루어지는 머신러닝
    - 미디어 스트림의 사전 트랜스코딩
  - 데이터를 다시 AWS로 보내야한다면 기기를 반송할 수 있음
- Snow Family - Edge Computing
  - Snowcone & Snowcone SSD (경량)
    - 2CPUs, 4GB 메모리, 유선 또는 무선 액세스
    - 전원으로 USB-C나 배터리 옵션이 제공
  - Snowball Edge - 컴퓨팅 최적화
    - 104 vCPUs, 416 GB 메모리
    - GPU 옵션 제공 (머신 러닝 또는 비디오 처리에 유용)
    - 28TB의 NVMe나 42TB의 HDD 스토리지가 제공
    - 스토리지 클러스터링 이용가능 (최대 16개 노드)
  - Snowball Edge - 용량 최적화
    - 40 vCpus, 80 GB 메모리, 80TB 스토리지
  - 모든 기기들은 EC2 인스턴스와 람다 함수를 실행할 수 있음 (AWS IoT Greengrass 서비스 사용)
  - 장기 배포 옵션: 1년 또는 3년 할인 가격
- AWS OpsHub
  - 과거에는 우리가 이런 기기를 사용할 때 CLI를 사용해야 했음
  - 컴퓨터나 노트북에 설치하는 GUI 소프트웨어 => 클라우드에서 사용하는게 아니라 개인의 컴퓨터에 다운
    - 싱글 또는 클러스터 기기를 열어서 설정 가능
    - 파일을 전송
    - Snow Family 기기에서 실행되는 인스턴스를 시작하고 관리할 수 있음
    - 기기와 매트릭을 모니터링
    - 호환되는 AWS 서비스들을 본인의 기기에서 시작할 수 있음



### 아키텍처: Snowball 에서 Clacier 까지

- Solution Architecture: Snowball into Glacier
  - Snowball을 Glacier에 데이터를 직접 끌어올 순 없음
  - Amazon S3를 사용해서 수명 주기 정책을 생성하여 Amazon Glacier로 객체를 전환할 수 있음



### Amazon FSx

- Amazon FSx - Overview
  - AWS에서 완전 관리형 서비스로 타사 고성능 파일 시스템을 실행시킴
- FSx for Windows (File Server)
  -  완전 관리형 Windows 파일 서버 공유 드라이브
  - SMB 프로토콜 & Windows NTFS 지원
  - Microsoft Active Directory 통합을 지원 => 사용자 보안, ACLs, 사용자 할당량
  - **Linux EC2 인스턴스에도 마운트할 수 있음**
  - Microsoft's Distributed File System (DFS) Namespaces 지원 (파일 시스템을 그룹화 할 수 있음)
  - 초당 수십 GB, 수백만 IOPS, 수백 PB의 데이터까지 확장 가능
  - 스토리지 옵션
    - SSD - 지연시간이 짧아야 하는 워크로드 (데이터베이스, 미디어 처리 데이터 분석)
    - HDD - 넓은 스펙트럼의 워크로드 (홈 디렉터리, CMS)
  - 프라이빗 연결로 온프레미스 인프라에서 액세스 가능
  - 고가용성 다중 AZ에 대해 FSx for Windows File Server를 구성할 수 있음
  - 데이터는 매일 S3에 백업됨
- FSx for Lustre
  - 원래 분산 파일 시스템으로 대형 연산에 쓰임
  - Lustre = Linux + Cluster 를 합친 단어
  - 머신 러닝과 HPX(고성능 연산)에 쓰임
  - 동영상 처리나 금융 모델링, 전자 설계 자동화에 쓰임
  - 초당 수백 GB 데이터 / 수백만 IOPS / 밀리초보다 짧은 지연 시간
  - 스토리지 옵션
    - SSD
    - HDD
  - S3와 무결절성 통합이 가능
    - FSx로 S3를 파일 시스템처럼 읽어들일 수 있음
    - FSx의 연산 출력값을 다시 S3로 쓸 수 있음
  - VPN과 직접 연결을 통해 온프레미스 서버에서 사용 가능
- FSx File System Deployment Options
  - 스크래치 파일 시스템 (Scratch File System)
    - 임시 스토리지
    - 데이터가 복제되지 않음 (서버가 오작동하면 파일이 모두 유실)
    - 초과 버스트 가능 (성능 6배 / TiB 처리량당 초당 200MB 속도)
    - 단기 처리 데이터에 쓰이며 데이터 복제가 없어 비용을 최적화할 수 있음
  - 영구 파일 시스템 (Persistent File System)
    - 장기 스토리지
    - 동일한 가용 영역에 데이터가 복제됨
    - 서버가 오작동했을 때 몇분 내에 해당 파일이 대체됨
    - 장기처리 및 민감한 데이터에 쓰임 
- FSx for NetApp ONTAP
  - AWS의 관리형 NetApp ONTAP 파일 시스템
  - NFS, SMB, iSCSI 프로토콜과 호환 가능
  - 온프레미스 시스템의 ONTAP이나 NAS에서 실행 중인 워크로드를 AWS로 옮길 수 있음
  - 다양한 운영 체제에서 사용 가능
    - Linux
    - Windows
    - MacOS
    - VMware Cloud on AWS
    - Amazon Workspaces & AppStream 2.0
    - Amazon EC2, ECS and EKS
  - 스토리지는 자동으로 확장, 축소 됨
  - 복제와 스냅샷 기능 지원, 저비용, 데이터 중복 제거 기능
  - **지정 시간 복제 기능 지원 (새 워크로드 등을 테스트할 때 유용)**
- FSx for OpenZFS
  - AWS의 관리형 OpenZFS 파일 시스템
  - 여러 버전에서 NFS 프로토콜과 호환이 가능
  - ZFS에서 실행되는 워크로드를 내부적으로 AWS에 옮길 때 사용
  - 다양한 운영 체제에서 사용 가능 (NetApp ONTAP 과 동일)
  - 백만 IOPS까지 확장 가능하고 지연 시간은 0.5 밀리초 이하
  - 스냅샷, 얍축을 지원하고 비용은 적지만 데이터 중복제거 기능이 없음
  - **지정 시간 복제 기능 지원 (새 워크로드 등을 테스트할 때 유용)**



### 스토리지 Gateway

- Hybrid Cloud for Stroage
  - AWS는 하이브리드 클라우드를 권장함
    - 일부는 AWS 클라우드에 있고
    - 나머지는 그대로 온프레미스에 두는 방식
  - 권장 이유
    - 오래 걸리는 클라우드 마이그레이션을 해야하는 경우
    - 보안 또는 규정 준수 요건이 있는 경우
  - AWS Storage Gateway가 S3 데이터를 온프레미스에 두는데 가교 역할을 함
- AWS Stroage Cloud Native Options
  - 블록: Amazon EBS, EC2 인스턴스
  - 파일: Amazon EFS, FSx
  - 객체: Amazon S3, Glacier
- AWS Storage Gateway
  - 온프레미스 데이터와 클라우드 데이터 간의 가교 역할
  - 사용 사례
    - 재해 복구
    - 백업 & 복구
    - 스토리지 확장
    - 온프레미스 캐시 & 낮은 지연시간의 파일 액세스
  - Stroage Gateway 타입
    - S3 File Gateway
    - FSx File Gateway
    - Volume Gateway
    - Tape Gateway
- Amazon S3 File Gateway
  - S3 파일 게이트웨이로 구성한 모든 버킷은 NFS 및 SMB 프로토콜을 이용해서 액세스 가능
  - **전체 S3 버킷이 아닌 최근에 사용한 파일만 파일 게이트웨이에 있음**
  - Glacier을 제외한 여러 스토리지 클래스를 지원
  - 수명 주기 정책을 사용하면 S3 Glacier로도 옮길 수 있음
  - 버킷에 액세스하려면 각 파일 게이트웨이마다 IAM 역할을 생성해야 함
  - Windows 파일 시스템 네이티브인 SMB 프로토콜을 사용하는 경우 사용자 인증을 위해 Active Directory와 통합해야 함
- Amazon FSx File Gateway
  - Amazon FSx for Windows File Server에 네이티브 액세스를 제공
  - 자주 액세스하는 데이터의 로컬 캐시를 확보할 수 있음
  - 윈도우 네이티브와 호환 가능 (SMB, NTFS, Active Directory, ...)
  - 그룹 파일 공유나 온프레미스를 연결할 홈 디렉터리로 사용할 수 있음
- Volume Gateway
  - 블록 스토리지로 Amazon S3가 백업하는 iSCSI 프로토콜을 사용
  - 볼륨이 EBS 스냅샷으로 저장되어 필요에 따라 온프레미스 볼륨을 복구할 수 있음
  - Cached volume: 최근 데이터 액세스 시 지연 시간이 낮음
  - Stored volume: 전체 데이터 세트가 온프레미스에 있으며 주기적으로 Amazon S3 백업이 따름
- Tape Gateway
  - 물리적으로 테이프를 사용하는 백업 시스템이 있는 회사가 백업에 테이프 대신에 클라우드를 활용해 데이터를 백업할 수 있게 해줌
  - 가상 테이프 라이브러리(Virtual Tape Library - VTL)는 Amazon S3와 Glacier를 이용
  - 테이프 기반 프로세스의 기존 백업 데이터를 iSCSI 인터페이스를 사용하여 백업
  - 업계를 선도하는 백업 소프트웨어 벤더가 사용하는 서비스
- Storage Gateway - Hardware appliance
  - 온프레미스에 서버가 없는 경우 사용
  - amazon.com 에서 구매 가능
  - 파일 게이트웨이, 볼륨 게이트웨이 혹은 테이프 게이트웨이로 설정 가능
  - 제대로 작동하려면 충분한 CPU, 메모리, 네트워크, SSD 캐시 리소스가 필요 
  - 소규모 데이터 센터의 NFS 백업처럼 가상화가 없는 경우 유용



### AWS 전송 제품군

- AWS Transfer Family
  - Amazon S3 또는 EFS의 안팎으로 데이터를 전송하려고 하고 싶은데 S3 APIs, EFS 네트워크 파일 시스템는 사용하고 싶지 않고 FTP 프로토콜만 사용하려는 경우에 사용
  - 지원하는 프로토콜
    - AWS Transfer for FTP (File Transfer Protocol )
    - AWS Transfer for FTPs (File Transfere Protocol over SSL)
    - AWS Transfer for SFTP (Secure File Transfer Protocol)
  - 전송 제품군은 완전 관리형 인프라이며 확장성, 안정성이 높고 높은 가용성을 가짐
  - 시간당 프로비저닝된 엔드 포인트 비용 + 전송 제품군 안팎으로 전송된 데이터당 GB 요금
  - 서비스 내에서 사용자 자격 증명을 저장 및 관리 가능
  - 기존의 인증 시스템과 통합할 수 있음 (Microsoft Active Directory, LDAP, Okta, Amazon Cognito, custom)
  - 사용 사례
    - S3나 EFS의 FTP 인터페이스를 갖기 위해
    - 파일 공유
    - 공개 데이터셋 공유
    - CRM
    - ERP



### DataSync

- AWS DataSync
  - 데이터를 동기화하며 이를 통해 대용량의 데이터를 한 곳에서 다른 곳으로 옮길 수 있음
    - 온프레미스나 AWS의 다른 클라우드 (NFS, SMB, HDFS, S3 API, ...)로 데이터를 옮길 수 있음
    - 옮길 위치인 온프레미스나 연결한 다른 클라우드에 에이전트가 있어야 함
    - 한 AWS 서비스에서 다른 AWS로 데이터를 옮길 수도 있음
  - 동기화 가능한 서비스 
    - Amazon S3 (모든 스토리지 클래스)
    - Amazon EFS
    - Amazon FSx (모든 운영채제)
  - 복제 작업은 매번 실행하지 않고 매 시간, 매일, 혹은 매주 실행되도록 할 수 있음
  - 파일 권한과 메타데이터 보존 기능 (NFS POSIX, SMB 권한 준수)
  - 에이전트 하나의 태스크가 초당  10Gb까지 사용할 수 있으며 대역폭에 제한을 걸 수 있음



### 모든 AWS 스토리지 옵션 비교

- Storage Comparison
  - S3: 객체 스토리지
  - S3 Glacier: 객체 아카이브
  - EBS volumes: 한 번에 한 개의 EC2 인스턴스에만 스토리지를 연결하는 경우
  - Instance Stroage: 고성능 물리 스토리지를 필요로 하는 경우
  - EFS: 다중 가용 영역 간 마운트를 해야 하면서 POSIX 파일 시스템을 쓰는 경우
  - FSx for Windows: Windows 서버 파일 시스템을 필요로 하는 경우
  - FSx for Lustre: 고성능 연산 Linux 파일 시스템이며 Lustre 클라이언트와 호환 가능해야 하는 경우
  - FSx for NetApp: 높은 운영 체제 호환성과 네트워크 파일 시스템이 필요할 때
  - FSx for OpenZFS: 관리형 ZFS 파일 시스템이 필요할 때
  - Storage Gateway: S3 & FSx 파일 게이트웨이, 볼륨 게이트웨이 (캐시 & 저장), 테이프 게이트웨이
  - Transfer Family: FTP, FTPS, SFTP 인터페이스를 필요로 하는 경우
  - DataSync: 온프레미스에서 AWS, AWS에서 AWS로 일정에 따라 데이터를 동기화할 때
  - Snowcone / Snowball / Snowmobile: 데이터를 옮기는 데 쓸 네트워크 용량이 없거나 물리적으로 대용량의 데이터를 옮겨야할 때





## Section 17. 디커플링 애플리케이션: SQS, SNS, Kinesis, Active MQ

### 메시징 소개

- Section 소개

  - 애플리케이션을 여러 개 배포하려고 할 때 커뮤니케이션이 필요
  - 애플리케이션 커뮤니케이션은 두 가지 패턴으로 나뉨
    - 동기 커뮤니케이션 (애플리케이션 + 애플리케이션이 직접적으로 연결)
    - 비동기 / 이벤트 기반 (애플리케이션 + 대기열 - queue + 애플리케이션)

  - 애플리케이션 간의 동기화는 때때로 문제가 될 수 있음
    - 트래픽이 갑자기 급증하거나 아무것도 예측할 수 없는 경우
    - 이런 경우, 일반적으로 애플리케이션을 분리하고 분리 계층을 확장하는 것이 좋음
      - SQS: queue model
      - SNS: pub/sub model
      - Kinesis: real-time streaming model



### Amazon SQS - 표준 Queues

- Amazone SQS - 표준 Queue
  - 가장 오래된 서비스 (10년 이상)
  - 완전 관리형 서비스이며 **애플리케이션을 분리**하는 데 사용
  - 특징
    - 처리량 및 메시지 수에 제한이 없음
    - 메시지는 기본값으로 4일동안 대기열에 남아 있음 (최대 시간은 14일)
    - 지연 시간이 짧음 (송신 및 수신 시 10ms 이내에 응답)
    - 전송된 메시지당 256KB 미만이어야 함
  - 중복 메시지가 있을 수 있음
  - 품절메시지를 보낼 수 있음 (최선의 오더)
- SQS - Producing Messages
  - 생산자는 SDK 소프트웨어 개발 키트를 사용하여 SQS에 메시지를 보냄 (SendMessage API)
  - 메시지가 작성되면 소비자가 해당 메시지를 읽고 삭제할 때까지 SQS 대기열에 유지됨
- SQS - Consuming Messages
  - 소비자 (EC2 인스턴스, 서버, AWS 람다에서 실행)
  - 대기열에는 소비자가 있고 소비자는 SQS 메시지를 폴링 (한 번에 최대 10개의 메세지를 받음)
  - 메시지를 처리 (ex - 메시지를 RDS DB에 insert 함)
  - 메시지를 삭제 (DeleteMessage API)
- SQS - Multiple EC2 Instance Consumers
  - SQS는 병렬적으로 메시지를 동시에 수신하고 처리할 소비자를 여러개 가질 수 있음
  - 적어도 한번은 전송이 됨
  - 최선의 노력으로 메시지 순서 지정을 함
  - 소비자는 메시지를 처리 후 삭제 
  - 소비자를 추가하고 수평확장을 통해 처리량을 개선할 수 있음
- SQS - Sequrity
  - 암호화
    - HTTPS API를 사용하여 전송 중 암호화
    - KMS 키를 사용하여 미사용 암호화
    - 원한다면 클라이언트 측 암호화도 가능 => 클라이언트가 자체적으로 암호화 및 암호 해독을 수행해야 함
  - 엑세스 컨트롤
    - IAM 정책을 사용해 SQS API에 대한 액세스를 규제할 수 있음
  - SQS 액세스 정책 (S3 버킷 정책과 유사)
    - SQS 대기열에 대한 교차 계정 액세스를 수행하려는 경우
    - SNS 혹은 Amazon S3 같은 다른 서비스가 SQS 대기열에 S3 이벤트 같은 것을 쓸 수 있도록 허용하려는 경우



### SQS - 메시지 가시성 시간 초과

- SQS - 메시지 가시성 시간 초과
  - 소비자가 메시지를 폴링하면 그 메시지는 다른 소비자들에게 보이지 않게 됨
  - 메시지 가시성 시간 초과의 기본값은 30초
  - 30초 안에 메시지가 처리되어야 한다는 의미
  - 메시지 가시성 시간이 초과된 후에 메시지는 SQS에 다시 보이게 됨
  - 메시지 가시성 시간 내에 메시지가 처리되지 않으면 메시지가 두 번 처리될 수도 있음
  - 소비자는 ChangeMessageVisibility API를 호출할 수 있음 => 메시지 처리 시간이 가시성 시간 초과보다 길어질 것 같을 때
  - 가시성 시간이 너무 짦으면 중복 처리 문제가 발생할 수 있고, 너무 길면 큐에 다시 보이기까지 시간이 너무 길어짐



### SQS - 롱 폴링

- Amazone SQS - Long Polling
  - 소비자가 대기열에 메시지를 요청하는데 대기열에 아무것도 없다면 메시지 도착을 기다리면 됨 
  - 이것을 롱 폴링이라고 함
    - 지연 시간을 줄이기 위해
    - SQS로 보내는 API 호출 숫자를 줄이기 위해
  - 롱 폴링은 SQS로의 API 호출 숫자를 줄이면서 애플리케이션의 효율성과 대기 시간을 증가시킴
  - 기다리는 시간을 1 ~ 20초까지 설정이 가능 (20초가 더 좋음)
  - 숏 폴링보다는 롱 폴링을 선호
  - 대기열 레벨에서 구성하는 방법과 WaitTimeSeconds API를 사용하여 지정하는 방법



### SQS - FIFO Queues

- Amazon SQS - FIFO Queue
  - FIFO = First In First Out
  - 표준 대기열보다 순서가 더 확실히 보장됨 (중복 제거도 가능)
  - 처리량 제한: 묶음이 아닐 경우에는 초당 300개의 메시지를 처리, 묶음일 경우 초당 3000개의 메시지를 처리



### SQS + 오토 스케일링 그룹

-   SQS with Auto Scaling Group (ASG)
  - ASG 내의 EC2 인스턴스에 메시지를  SQS 대기열에서 폴링
  - 오토 스케일링 그룹을 자동으로 대기열 크기에 따라 확장시키기 위함 
  - CloudWatch 지표인 대기열 길이를 보고 결정
  - CloudWatch Alarm이 울리면 ASG에 따라 EC2가 확장되고 메시지가 훨씬 더 빨리 처리됨
- SQS as a buffer to database writes
  - SQS를 버퍼로 사용하여 모든 트랜잭션이 데이터베이스에 쓰이도록 확인할 수 있음
  - 이 패턴은 클라리언트에게 따로 데이터베이스에 쓰였다는 확인을 전송할 필요가 없을 때만 사용이 가능
- SQS to decouple between application tires
  - 애플리케이션이 요청을 전달받고 처리한 후 응답을 재전송하는 대신 이 과정을 분리
  - 모든 요청을 프론트엔드 웹 애플리케이션에서 받고 해당 요청을 SQS 대기열로 전송
  - 백엔드 처리 작업이 메시지를 전달받은 다음 준비되면 메시지를 처리하고 필요에 따라 스케일링



### Amazon Simple Notification Service

- Amazon SNS
  - 메시지 하나를 여러 수신자에게 보내기를 원할 때
  - 이벤트 생성자는 한 SNS 주제에만 메시지를 보냄
  - 이벤트 수신자 또는 구독자는 해당 주제와 관련한 SNS 알림을 받으려는 사람
  - SNS 주제 구독자는 해당 주제로 전송된 메시지를 모두 받게 됨 (필터링하는 기능을 사용하는 경우도 포함)
  - 주제별로 최대 1,250만 이상의 구독자까지 가능
- SNS Integrates with a lot of AWS services
  - SNS는 다양한 AWS 서비스에서 데이터를 수신하기도 함
  - SNS로 직접 데이터를 보냄
- SNS - How to publish
  - 주제(topic) 게시 (SDK 사용)
    - 주제를 만듬
    - 하나 또는 여러 개의 구독을 만듬
    - SNS 주제에 게시
  - 직접(Direct) 게시 (모바일 앱 SDK 전용)
    - 플랫폼 애플리케이션 생성
    - 플랫폼 엔드 포인트 만듬
    - 플랫폼 엔드 포인트에 게시
    - 수신 가능 대상: Google, GCM, Apple APNS, Amazon ADM ...
- SNS - Security
  - 암호화
    - HTTPS API를 사용하여 전송 중 암호화
    - KMS 키를 사용하여 미사용 암호화
    - 원한다면 클라이언트 측 암호화도 가능 => 클라이언트가 자체적으로 암호화 및 암호 해독을 수행해야 함
  - 엑세스 컨트롤
    - IAM 정책을 사용해 SNS API에 대한 액세스를 규제할 수 있음
  - SNS 액세스 정책 (S3 버킷 정책과 유사)
    - SNS 주제에 대한 교차 계정 액세스를 수행하려는 경우
    - S3 이벤트와 같은 서비스가 SNS 주제에 작성할 수 있도록 하는 경우



### SNS 및 SQS - 팬아웃 패턴

- SNS + SQS: Fan Out
  - 메시지를 여러 SQS 대기열로 보내고 싶은데 모든 SQS 대기열에 개별적으로 메시지를 보내면 문제가 발생할 수 있음
    - 애플리케이션이 중간에 비정상적으로 종료될 수도 있고 전달에 실패할 수도 있고 SQS 대기열에 더 추가될 수도 있음
    - 이런 경우에 팬아웃 패턴을 사용
  - SNS 주제에 메시지를 전송한 후 원하는 수의 SQS 대기열이 이 SNS 주제를 구독
  - 완전히 분리된 모델이며, 데이터도 손실되지 않음
  - SQS로 작업을 다시 시도할 수 있으며, 데이터 지속성, 지연 처리도 수행 가능
  - 이런 방식으로 SNS 주제를 구독하도록 더 많은 SQS 대기열을 추가할 수도 있음
  - SQS 액세스 정책에서 SNS 주제가 SQS 대기열에 쓰기 작업을 할 수 있도록 허용해야 함
  - 리전 간 전달: 한 리전의 SNS 주제에서 다른 리전의 SQS 대기열로 메시지를 보낼 수 있음
- Application: S3 Events to multiple queues
  - S3에서 객체 생성과 같은 이벤트 유형과 /images와 같은 접두사 조합이 동일하다면 S3 이벤트 규칙은 한 가지여야 함 
  - 만약 여러 대기열에 동일한 S3 이벤트 알림을 보내고 싶다면 팬아웃 패턴을 사용
- Application: SNS to Amazon S3 through Kinesis Data Firehose
  - SNS를 KDF에 직접 연결하여 구매 서비스에서 데이터를 SNS 주제로 전송할 수 있음
  - KDF에서 해당 정보를 수신하고 해당  KDF에서 Amazon S3 버킷으로 전달하거나 특정한 KDF 목적지로 어디든 전달이 가능
- Amazon SNS - FIFO Topic
  - SQS FIFO 와 유사
    - 메시지 그룹 ID에 따라 순서를 매김
    - 중복 제거 ID를 활용하거나 내용을 비교하여 중복 데이터를 제거
  - SQS FIFO 대기열을 FIFO SNS 주제의 구독자로 설정
  - 처리량은 제한적이며 SQS FIFO 대기열과 동일
- SNS FIFO + SQS FIFO: Fan Out
  - 팬아웃 + 순서 + 중복 제거가 가능
- SNS - Mesasge Filtering
  - SNS 주제를 구독할 때 전송되는 메시지를 필터링하는 데 사용되는 JSON 정책
  - 구독에 어떤 필터링 정책도 없다면 모든 메시지를 받아들이며 이것이 기본 동작



## Section 18. AWS의 컨테이너: ECS, Fargate, ECR 및 EKS

### Docker 소개

- Docker
  - 도커는 앱 배포를 위한 소프트웨어 개발 플랫폼
  - 컨테이너에 앱이 패키징되는데 컨테이너는 표준화 되어 있어서 아무 운영체제에나 실행할 수 있음
  - 앱이 컨테이너에 패키징되면 어느 운영체제에서든 같은 방식으로 실행됨
    - 모든 머신
    - 호환성 문제 X
    - 예측 가능한 행위 특성
    - 작업이 적어짐
    - 유지 및 배포가 쉬움
    - 언어, 운영체제, 기술에 상관 없이 실행 가능
  - 사용 사례: 마이크로서비스 아키텍처, 온프레미스에서 클라우드로 앱을 리프트-앤-시프트 등
- 도커 이미지가 저장되는 곳
  - 도커 이미지는 도커 레포지토리에 저장됨
  - Docker Hub
    - 퍼블릭 레포지토리
    - 많은 기술에 맞는 기본 이미지를 찾을 수 있음 (e.g. Ubuntu, MySQL, ...)
  - Amazon ECR (Amazon Elastic Container Registry)
    - 프라이빗 레포지토리
    - 퍼블릭 레포지토리 (Amazon ECR Public Gallery)
- 도커 vs 가상 머신
  - 도커도 가상화 기술의 일종이긴 하지만 순전히 가상화 기술은 아님
  - 리소스가 호스트와 공유 => 한 서버에서 다수의 컨테이너를 공유할 수 있음
- 도커 시작법
  - Dockerfile 작성
  - 베이스 도커 이미지에 몇 가지 파일을 추가해서 구축 => 도커 이미지
  - 도커 이미지는 푸시를 해서 도커 레포지토리에 저장할 수 있음
  - 도커 이미지를 실행하면 도커 컨테이너가 됨
- AWS에서 도커 컨테이너 관리
  - Amazon ECS (Elastic Container Service)
    - Amazon 전용 컨테이너 플랫폼
  - Amazon EKS (Elastic Kubernetes Service)
    - Amazon 관리형 쿠버네티스 플랫폼 (오픈 소스)
  - AWS Fargate
    - Amazon의 서버리스 컨테이너 플랫폼
    - ECS와 EKS 둘 다 함께 작동 가능
  - Amazon ECR
    - 컨테이너 이미지를 저장



### Amazon ECS

- Amazon ECS - EC2 Launch Type
  - ECS = Elastic Container Service
  - AWS에서 도커 컨테이너를 실행 = ECS 클러스터에 ECS 태스크를 실행
  - EC2 시작 유형
    - EC2 인스턴스를 사용하는 인프라를 직접 프로비저닝하고 유지해야 함
  - 각각의 EC2 인스턴스는 ECS 클러스터에 등록하기 위해 ECS 에이전트를 실행해야함
  - AWS는 컨테이너를 시작하거나 멈춤 
- Amazon ECS - Fargate Launch Type
  - AWS에 도커 컨테이너를 실행
  - 인프라를 프로비저닝하지 않음 (관리할 EC2 인스턴스가 없음)
  - 서버리스
  - ECS 태스크를 관리하는 태스크 정의만 생성하면 됨
  - 필요한 CPU나 RAM에 따라 ECS 태스크를 AWS가 대신 실행
  - 확장하려면 간단하게 태스크 수만 늘리면 됨 => EC2 인스턴스 관리 X
- Amazon ECS - IAM Roles for ECS
  - EC2 인스턴스 프로파일 (EC2 시작 유형 사용시)
    - ECS 에이전트만이 사용
    - ECS 서비스에 API를 호출
    - CloudWatch 로그에 API 호출을 해 컨테이너 로그를 보냄
    - ECR로부터 도커 이미지를 가져옴
    - Secrets Manager나 SSM Parameter Store에서 민감 데이터를 참고하기도 함
  - ECS Task Role
    - 각자의 테스크에 특정 역할을 만들 수 있음
    - 역할이 각자 다른 ECS 서비스에 연결할 수 있게 할 수 있게 해줌
    - ECS 서비스의 태스크 정의에서 태스크의 역할을 정의
- Amazon ECS - Load Balancer Integrations
  - Application Load Balancer는 대부분의 사용 사례를 지원하는 좋은 옵션
  - Network Load Balancer는 처리량이 매우 많거나 높은 성능, AWS Private Link 사용이 요구될 때만 권장
-  Amazon ECS - Data Volumes (EFS)
  - EC2 태스크에 EFS 파일 시스템을 마운트
  - EC2와 Fargate 시작 유형 모두 호환이 됨
  - 어느 AZ에 실행되는 태스크든 Amazo n EFS에 연결되어 있다면 데이터를 공유할 수 있고 원한다면 파일 시스템을 통해 다른 태스크와 연결할 수 있음
  - Fargate + EFS = Serverless
  - 사용 사례: 다중 AZ가 공유하는 컨테이너의 영구 스토리지
  - **Amazon S3는 ECS 태스크에 파일 시스템으로 마운트될 수 없음**



### Amazon ECS - 오토 스케일링

- ECS Service Auto Scaling
  - 태스크 수를 자동으로 늘리거나 줄여줌
  - AWS ECS 오토 스캐일링은 AWS Application Auto Scaling을 사용
    - ECS 서비스의 CPU 사용률
    - ECS 서비스의 메모리 사용률 - RAM
    - ALB 타겟당 요청 수
  - Target Tracking - CloudWatch metric의 특정 타겟 값을 추적하여 스케일
  - 단계(Step) Scaling - 특정 CloudWatch Alarm에 기반하여 스케일
  - Sceduled Scaling - 특정 시간 및 날짜에 ECS 서비스 스케일
  - ECS Service Auto Scaling (task level) != EC2 Auto Scaling (EC2 instance level)
  - EC2 오토 스케일링이 필요하지 않다면 Fargate를 사용하는 것이 서비스 오토 스케일링에 더 도움이 됨 (서버리스기 때문)
- EC2 Launch Type - Auto Scaling EC2 Instances
  - Auto Scaling Group Scaling
    - CPU 사용률에 따라 ASG 확장을 원한다면
    - CPU 사용률이 급등할 때 EC2 인스턴스를 추가
  - ECS Cluster 용량 공급자 (Capacity Provider)  => 추천
    - 새 테스크를 실행할 용량이 부족하면 자동으로 ASG를 확장
    - Capacity Provider는 오토 스케일링 그룹과 함께 사용됨
    - RAM이나 CPU가 모자랄 때 EC2 인스턴스를 추가



### Amazon ECR

- Amazon ECR
  - Elastic Container Registry
  - AWS에 도커 이미지를 저장하고 관리하는 데 사용
  - Private and Public repository (Amazon ECR Public Gallery)
  - ECS와 완전히 통합돼 있으며, 이미지는 백그라운드에서 Amazon S3에 저장됨
  - ECR에 대한 모든 접근은 IAM이 보호하고 있음 (권한 에러 => 정책 살펴보기)
  - 이미지의 취약점 스캐닝, 버저닝 태그 및 수명 주기 확인을 지원



### EKS

- Amazon EKS Overview

  - Amazon EKS = Amazon Elastic Kubernetes Service
  - AWS에 관리형 Kubernetes 클러스터를 실행할 수 있는 서비스
  - Kubernetes는 오픈 소스 시스템으로 Docker로 컨테이너한 애플리케이션의 자동 배포, 확장, 관리를 지원
  - 컨테이너를 실행한다는 목적은 ECS와 비슷하지만, 사용하는 API가 다름
  - EC2 시작 모드는 EC2 인스턴스에서처럼 작업자 모드를 배포할 때 사용
  - Fargate 모드는 EKS 클러스터에 서버리스 컨테이너를 배포할 때 사용
  - 사용 사례: 온프레미스나 클라우드에서 Kubernetes나 Kubernetes API를 사용중일 때 Kubernetes 클러스트를 관리하기 위해 

  - **Kubernetes는 cloud-agnostic임** (Azure, Google Cloud 등 모든 클라우드에서 지원)

- Amazon EKS - Node Types

  - 관리형 노드 그룹 (Managed Node Groups)
    - AWS로 노드 (EC2 인스턴스)를 생성하고 관리
    - 노드는 EKS 서비스로 관리되는 오토 스케일링 그룹의 일부
    - 온디맨드 인스턴스와 스팟 인스턴스를 지원
  - 자체 관리형 노드 (Self-Managed Nodes)
    - 직접 노드를 생성하고 EKS 클러스터에 등록한 다음 ASG의 일부로 관리
    - 사전 빌드된 AMI를 사용할 수 있음 - Amazon EKS Optimized AMI
    - 온디맨드 인스턴스와 스팟 인스턴스를 지원
  - AWS Fargate
    - 유지 관리도 필요 없고 노드를 관리하지 않아도 됨

- Amazon EKS - Data Volumes

  - EKS 클러스터에 스토리지 클래스 매니페스트를 지정해야 함
  - 컨테이너 스토리지 인터페이스 (CSI)라는 규격 드라이버를 활용
  - 지원 서비스
    - Amazon EBS
    - Amazon EFS (Fargate 모드가 작동하는)
    - Amazon FSx for Lustre
    - Amazon FSx for NetApp ONTAP



### AWS App Runner

- AWS App Runner
  - 완전 관리형 서비스로 규모에 따라 웹 애플리케이션, API 배포를 도움
  - 인프라나 컨테이너, 소스 코드 등을 알 필요가 없음
  - 소스 코드나 Docker 컨테이너 이미지를 가지고 원하는 구성을 설정
  - 자동으로 그 다음 작업이 이루어짐 => 웹 앱을 빌드하고 배포
  - 장점
    - 오토 스케일링 가능
    - 가용성이 높음
    - 로드 밸런싱
    - 암호화
  - 애플리케이션(컨테이너)이 VPC에 액세스 가능
  - 데이터베이스와 캐시, 메시지 대기열 서비스에 연결 가능
  - 사용 사례: 웹 앱, API, 마이크로 서비스, 신속한 프로덕션 배포



## Section 19. 솔루션 설계자 관점의 서버리스 개요

### 서버리스 소개

- Serverless?

  - 서버리스를 사용하는 개발자는 서버를 관리할 필요가 없음 (서버가 없다는 말은 아님)

  - 코드(함수)를 배치만 하면 됨

  - 원래 서버리스는 FaaS (Function as a Service)를 뜻했음

  - 서버를 프로비저닝 하지 않는 원격 관리되는 것(데이터베이스, 메시징, 스토리지 등)을 모두 포함

  - 서버리스란 서버가 없는 게 아니라 서버가 보이지 않거나 서버를 프로비저닝 하지 않는 것

- Serverless in AWS

  - AWS Lambda
  - DynamoDB
  - AWS Cognito
  - AWS API Gateway
  - Amazon S3
  - AWS SNS & SQS
  - AWS Kinesis Data Firehose 
  - Aurora Serverless
  - Step Functions
  - Fargate



### Lambda 개요

- Why AWS Lambda
  - 가상의 함수 - 관리할 서버가 없음
  - 제한 시간이 있음 - 실행시간이 짧음
  - 온디맨드 실행
  - 스케일링이 자동화
- Benefits of AWS Lambda
  - 쉽고 싼 가격 
    - 호출 횟수와 컴퓨팅 시간, 즉 Lambda가 실행된 시간만큼 청구 됨
    - 프리티어: Lambda 요청 1백만 건과 40만 GB초의 컴퓨팅 시간이 포함
  - 다양한 AWS 서비스와 통합
  - 여러가지 프로그래밍 언어를 사용 가능
  - CloudWatch와의 모니터링 통합이 쉬움
  - 함수당 더 많은 리소스를 프로비저닝하기 쉬움 (함수당 최대 10GB의 RAM)
  - 함수의 RAM을 증가시키면 CPU 및 네트워크의 품질이 향상됨
- AWS Lambda 지원 언어
  - Node.js (JavaScript)
  - Python
  - Java (Java 8 compatible)
  - C# (.NET Core)
  - Golang
  - C# / Powershell
  - Ruby
  - Custom Runtime API (커뮤니티가 지원, ex. Rust)
  - Lambda Container Image
    - 컨테이너 이미지 자체가 Lambda의 런타임 API를 구현해야 함
    - ECS와 Fargate는 계속 임의의 도커 이미지를 실행할 때 더 많이 사용됨



### Lambda 제한

- AWS Lambda Limits to Know - per region
  - 실행 한도
    - 메모리 할당량: 128MB ~ 10GB (1MB씩 증가)
    - 최대 실행 시간: 900초 (15분)
    - 환경 변수: 4KB
    - 제한적인 공간이나 Lambda 함수를 생성하는 동안 큰 파일을 가져올 때 사용할 수 있는 임시 공간(/tmp 폴더에 있음): 512MB to 10GB
    - 동시 실행: 최대 1,000개 (증가시킬 수 있음)
  - 배포 한도
    - 압축시 최대 크기: 50MB
    - 압축하지 않았을 때 최대 크기: 250MB
    - 크기가 더 큰 파일은 /tmp 디렉터리를 사용
    - 환경 변수: 4KB



### Lambda@엣지 & CloudFront Functions

- Customization At The Edge

  - 보통은 함수와 애플리케이션을 특정 리전에서 배포하지만 CloudFront를 사용할 때는 엣지 로케이션을 통해 콘텐츠를 배포
  - 모던 애플리케이션에서는 애플리케이션에 도달하기 전에 엣지에서 로직을 실행하도록 요구
  - 엣지 함수
    - CloudFront 배포에 연결하는 코드
    - 사용자 근처에서 실행하여 지연 시간을 최소화
  - CloudFront에는 두 종류의 함수가 있음
    - CloudFront 함수
    - Lambda@Edge
  - 서버를 관리할 필요가 없고, 전역으로 배포됨
  - 사용 사례: CDN 콘텐츠를 사용자 지정하는 경우
  - 사용한 만큼만 비용을 지불하며 완전 서버리스

- CloudFront Functions & Lambda@Edge Use Cases

  - 웹사이트 보안과 프라이버시
  - 엣지에서의 동적 웹 애플리케이션
  - 검색 엔진 최적화(SEO)
  - 오리진 및 데이터 센터 간 지능형 경로
  - 엣지에서의 봇 완화
  - 엣지에서의 실시간 이미지 변환
  - A / B 테스트
  - 사용자 인증 및 권한 부여
  - 사용자 우선순위 지정
  - 사용자 추적 및 분석

- CloudFront Functions

  - CloudFront 함수는 JavaScript로 작성된 경량 함수
  - 확장성이 높고 지연 시간에 민감한 CDN 사용자 지정에 사용
  - 시작 시간은 1밀리초 미만이며 초당 백만 개의 요청을 처리
  - 뷰어 요청과 응답을 수정할 때만 사용됨
    - 뷰어 요청: CloudFront가 뷰어로부터 요청을 받은 다음에 뷰어 요청을 수정할 수 있음
    - 뷰어 응답: CloudFront가 뷰어에게 응답을 보내기 전에 뷰어 응답을 수정할 수 있음
  - CloudFront의 네이티브 기능 (모든 코드가 CloudFront에서 직접 관리됨)

- Lambda@Edge

  - Node.js나 Python으로 작성
  - 초당 수천 개의 요청을 처리할 수 있음
  - 5~10초의 시작시간이 걸림
  - 모든 CloudFront 요청 및 응답을 변경할 수 있음
    - 뷰어 요청: CloudFront가 뷰어로부터 요청을 받은 다음에 수정할 수 있음
    - 오리진 요청: CloudFront가 오리진에 요청을 전송하기 전에 수정할 수 있음
    - 오리진 응답: CloudFront가 오리진에서 응답을 받은 후에 수정할 수 있음
    - 뷰어 응답: CloudFront가 뷰어에게 응답을 보내기 전에 수정할 수 있음
  - 함수는 us-ease-1 리전에서만 작성할 수 있음 (CloudFront 배포를 관리하는 리전과 같은 리전)

- CloudFront Functions vs Lambda@Edge 사용 사례

  - CloudFront Functions
    - 캐시 키 생성
      - 요청 속성을 변환하여 최적의 캐시 키 생성
    - 요청이나 응답에 HTTP 헤더를 삽입, 수정, 삭제하도록 헤더를 조작
    - URL을 다시 쓰거나 리다이렉트
    - 요청인증 & 권한부여 
      - JWT를 생성하거나 검증하는 요청 인증 및 권한 부여

  - Lambda@Edge
    - 긴 실행 시간 (몇 초)
    - CPU와 메모리가 증가하므로 여러 라이브러리 로드 가능
    - 타사 라이브러리에 코드를 의존시킬 수 있음 (e.g - SDK에서 다른 AWS 서비스에 액세스할 수 있도록)
    - 네트워크 액세스를 통해 외부 서비스에서 데이터를 처리할 수 있음
    - 파일 시스템이나 HTTP 요청 본문에도 바로 액세스 가능



### Lambda in VPC

- Lambda by default
  - 기본적으로 Lambda 함수를 시작하면 생성자의 VPC 외부에서 시작 (VPC는 AWS가 제공하는 서비스)
  - 따라서, VPC 내에서 리소스에 액세스할 권한이 없음 (RDS, ElastiCache, 내부 ELB...)
- Lambda in VPC
  - VPC ID Lambda 함수를 시작하려는 서브넷을 지정하고 Lambda 함수에 보안그룹을 추가해야 함
  - Lambda가 서브넷에 엘라스틱 네트워크 인터페이스를 생성
- Lambda with RDS Proxy
  - 람다 함수가 직접적으로 DB에 접근한다면, 람다 함수의 수가 너무 많이 생성되었다 사라지길 반복하면서 개방된 연결이 너무 많아짐 => RDS Proxy로 문제 해결 가능
  - RDS Proxy
    - 데이터베이스 연결의 풀링과 공유를 통해 확장성을 향상시킴
    - 장애가 발생할 경우 장애 조치 시간을 66%까지 줄여 가용성을 향상시키고 연결을 보존
    - RDS 프록시 수준에서 IAM 인증을 강제하여 보안을 높일 수 있고 자격 증명은 Secrets Manager에 저장됨
  - Lambda 함수가 RDS 프록시에 연결할 수 있으려면 자신의 VPC에서 Lambda 함수를 시작해야 함 => RDS 프록시는 퍼브릭 액세스가 불가능하기 때문



### RDS - 람다 호출 및 이벤트 알림

- Invoking Lambda from RDS & Aurora
  - 어떤 경우에 데이터베이스 인스턴스 안에서 람다 함수를 호출할 수도 있음
  - 그러면 데이터베이스 안에서 일어나는 데이터 이벤트를 처리할 수 있게 됨
  - RDS for PostgreSQL과 Aurora MYSQL에 해당 기능이 지원 됨
  - RDS 데이터베이스 인스턴스로부터 람다 함수로 오는 인바운드 트래픽을 반드시 허용해야 함 (Public, NAT Gateway, VPC Endpoints)
  - DB 인스턴스는 람다 함수를 호출할 필수적인 권한을 가지고 있어야 함 (Lambda Resouce-based Policy & IAM Policy)
- RDB 이벤트 알림 (Event Notifications)
  - 알림들은 AWS 안에서 이루어지며 DB 인스턴스 자체에 대한 정보를 알려줌 (생성, 정지, 시작 시각 등)
  - **데이터에 대한 정보는 전혀 없음**
  - 데이터베이스 인스턴스, 데이터베이스 스냅샷, 파라미터 그룹, 보안 그룹, 프록시 또는 커스텀 엔진 버전에 관한 이벤트를 구독할 수 있음
  - 전달 시간이 최대 5분인 근 실시간 이벤트를 받음
  - 알림을 SNS에 전송하거나 EventBridge에서 가로챌 수도 있음



### Amazon DynamoDB 개요

- Amazon DynamoDB
  - 완전 관리형 데이터베이스로 데이터가 다중 AZ간에 복제되므로 가용성이 높음
  - NoSQL 데이터베이스 - 트랜잭션 지원 기능
  - 방대한 워크로드로 확장이 가능 => 데이터베이스가 내부에서 분산됨
  - 초당 수백만 개의 요청을 처리하고, 수조 개의 행, 수백 TB의 스토리지를 갖게 됨
  - **성능은 한 자릿수 밀리초를 자랑하고 일관성 또한 높음**
  - 보안과 관련된 모든 기능(보안, 권한 부여, 관리 기능)은 IAM과 통합되어 있음
  - 비용이 적게 들고 오토 스케일링 기능이 탑재돼 있음
  - 유지 관리나 패치 없이도 항상 사용할 수 있음
  - 데이터베이스를 프로비저닝할 필요가 없음
  - 테이블 클래스: Standard 클래스 & Infrequent Access (IA) 테이블 클래스
- DynamoDB - Basics
  - 테이블로 구성됨
  - 각 테이블에 기본 키가 부여 됨 (기본 키는 생성 시 결정 됨)
  - 각 테이블은 행을 무한히 추가할 수 있음
  - 각 항목은 속성을 가지며 속성은 열에 표시됨 (속성은 나중에 추가할 수도 있고 null이 될 수도 있음)
  - 항목의 최대 크기는 400KB
  - 다양한 데이터 타입을 지원
    - 스칼라 유형 - String, Number, Binary, Boolean, Null
    - 목록 유형 - List, Map
    - 세트 유형 - String Set, Number Set, Binary Set
  - 스키마를 빠르게 전개해야할 때 선택
- DynamoDB - Read/Wirte Capacity Modes
  - DynamoDB는 테이블 용량 관리 방식을 제어해야 함
  - 프로비저닝된 모드 (Provisioned Mode) (default)
    - 초당 읽기/쓰기 요청 수를 예측해서 미리 지정
    - 미리 용량을 계획함함
    - 프로비저닝된 RCU(Read Capacity Units - 읽기 용량 단위)와 와  WCU(Wirte Capacity Units - 쓰기 용량 단위)와만큼의 비용을 지불
    - 테이블의 로드에 따라 자동으로 RCU와 WCU를 늘리거나 줄이는 오토 스케일링 기능이 있음
  - 온디맨드 모드 (On-Demand Mode)
    - 읽기/쓰기 용량이 워크로드에 따라 자동으로 확장됨
    - 미리 용량을 계획하지 않음
    - 정확히 사용한 만큼의 비용을 지불 => 더욱 비쌈
    - 워크로드를 예측할 수 없거나 급격히 증가하는 경우에 유용



### Amazon DynamoDB 심화 기능

- DynamoDB Accelerator (DAX)
  - DynamoDB를 위한 고가용성의 완전 관리형 무결절 인메모리 캐시
  - 캐싱을 통해 읽기 혼잡을 해결
  - DAX는 캐시 데이터에 **마이크로초** 수준의 지연 시간을 제공
  - 애플리케이션 로직을 변경할 필요가 없음 (DAX 클러스터는 기존 DynamoDB API와 호환되므로)
  - 캐시의 기본 TTL은 5분 (변경 가능)
- DynamoDB Accelerator (DAX) vs ElastiCache
  - DAX는 DB 앞에 있고 개별 객체 캐시와 쿼리와 스캔 캐시를 처리하는데 유용
  - ElstiCache는 집계 결과를 저장할 때 유용
- DynamoDB - Stream Processing
  - 테이블의 모든 수정 사항 (생성/업데이트/삭제)을 포함한 스트림을 생성할 수 있음
  - 사용 사례
    - 테이블의 변경 사항에 실시간 반응이 필요할 때 (유저에게 환영 이메일)
    - 실시간으로 사용 분석
    - 파생 테이블을 삽입
    - 리전 간 복제를 실행
    - DynamoDB 테이블 변경 사항에 대해 Lambda 함수를 실행
  - DynamoDB Streams
    - 24시간의 보존기간
    - 소비자 수가 제한
    - Lambda 트리거와 함께 사용하면 좋음
    - 자체적으로 읽기를 실행하려면 DynamoDB Stream Kinesis 어댑터를 사용
  - Kinesis Data Streams (newer)
    - 1년의 보존 기간
    - 더 많은 수의 소비자 수를 가짐
    - 데이터를 처리하는 방법이 훨씬 많음 (AWS Lambda, Kinesis Data Analytics, Keneis Data FireHose, AWS Glue Streaming ETL....)
- DynamoDB Global Tables
  - 여러 리전 간에 복제가 가능한 테이블
  - DynamoDB 글로벌 테이블은 복수의 리전에서 짧은 지연 시간으로 액세스할 수 있게 해 줌
  - 다중 활성 복제가 가능
  - 애플리케이션이 모든 리전에서 테이블을 읽고 쓸 수 있음
  - 글로벌 테이블을 활성화하려면 DynamoDB 스트림을 활성화해야 함
- DynamoDB - Time To Live (TTL)
  - 만료 타임스탬프가 지나면 자동으로 항목을 삭제하는 기능
  - 사용 사례
    - 최근 항목만 보관하도록 하는 경우
    - 2년 후 데이터를 삭제하야 하는 규정을 따라하 하는 경우
    - **웹 세션 핸들링을 해야 하는 경우**

- DynamoDB - Backups for disaster recovery
  - 지정 시간 복구 (PITR - point-in-time revovery) 을 사용한 지속적 백업
    - 활성화를 선택할 수 있고 35일 동안 지속
    - 활성화하면 백업 기간 내에는 언제든 지정 시간 복구를 실행할 수 있음
    - 복구를 진행할 겨우 새로운 테이블을 생성
  - 온디맨드 백업 (On-demand backups)
    - 직접 삭제할 때까지 보존됨
    - DB의 성능이나 지연 시간에 영향을 주지 않음
    - 백업을 좀 더 제대로 관리할 수 있는 방법 중 하나로 AWS Backup 서비스가 있음 (리전간 백업이 가능)
    - 백업으로 복구를 진행하면 새로운 테이블이 생성됨
- DynamoDB - Integration with Amazon S3
  - Export to S3 (지정 시간 복구 기능 활성화 필요)
    - 최근 35일 이내 어떤 시점으로든 테이블을 내보낼 수 있음
    - 테이블을 내보내도 테이블의 읽기 용량이나 성능에 영향을 주지 않음
    - 테이블을 내보내기 하여 데이터 분석을 수행할 수 있음
    - 감사 목적으로 스냅샷을 확보할 수 있음
    - 데이터를 DynamoDB로 다시 가져오기 전에 데이터 ETL 등 대규모 변경을 실행할 수 있음
    - 내보낼 때는 DynamoDB JSON이나 ION 형식을 이용
  - Import to S3
    - S3에서 CSV, JSON 그리고 ION 형식으로 내보낸 다음 새로운 DynamoDB 테이블을 생성하는 방식
    - 쓰기 용량을 소비하지 않고 새로운 테이블을 생성
    - 가져올 때 발생한 오류는 모두 CloudWatch Logs에 기록됨



### API Gateway 개요

- AWS API Gateway
  - AWS Lambda + API Gateway: 서버리스 애플리케이션 구축 => 인프라 관리가 필요없어짐 
  - WebSocket 프로토콜을 지원
  - API 버저닝을 핸들링 (v1, v2...)
  - 여러 환경을 핸들링 (dev, test, prod...)
  - 보안 핸들링 (인증, 권한 부여 등)
  - API 키를 생성하여 요청을 스로틀링할 수 있음
  - Swagger / Open API 같은 공통 표준을 사용하여 신속히 API를 정의하여 가져올 수 있음
  - API Gateway 수준에서 요청과 응답을 변형하거나 유효성을 검사해 올바른 호출이 실행되게 할 수 있음
  - SDK나 API 스펙을 생성
  - API 응답을 캐시
- API Gateway - Integrations High Level
  - Lambda Function
    - 람다 함수를 지연 호출
    - 람다 함수를 사용하는 REST API를 완전 서버리스 애플리케이션에 노출시키는 가장 쉬운 방법
  - HTTP
    - 백엔드의 HTTP의 엔드포인트를 노출시킬 수 있음
    - 예시: 온프레미스에 HTTP API가 있거나 클라우드 환경에 애플리케이션 로드 밸런서가 있을 때 
    - Why? 속도 제한 기능, 캐싱, 사용자 인증, API 키 등의 기능을 추가할 수 있음
  - AWS Service
    - 어떤 AWS API라도 노출시킬 수 있음
    - 예시: 단계 함수 워크플로우를 시작할 수 있고, SQS에 직접 메시지를 게시할 수도 있음
    - Why? 인증을 추가하거나 API를 퍼블릭으로 배포하거나 속도 제한을 추가하기 위해 통합
- API Gateway - Endpoint Types (배포 유형형)
  - 엣지 최적화 (Edge-Optimized) (default)
    - 글로벌 클라이언트용
    - 모든 요청이 CloudFront 엣지 로케이션을 통해 라우팅되므로 지연 시간이 개선됨
    - API Gateway는 여전히 생성된 리전에 위치
  - 리전 (Regional)
    - 같은 리전에 있는 클라이언트용
    - 자체 CloudFront 배포를 생성할 수도 있음 (캐싱 전략과 Cloudfront 설정에 더 많은 권한을 가질 수 있음)
  - 프라이빗 (Private)
    - ENI같은 인터페이스 VPC 엔드포인트를 사용해서 VPC 내에서만 액세스가 가능
    - 액세스를 정의할 때는 리소스 정책을 사용
- API Gateway - Security
  - 사용자 식별 방법
    - IAM 역할 (EC2 인스턴스에서 실행되는 내부 애플리케이션에서 유용)
    - Amazon Cognito (모바일이나 웹 사용자에 대한 외부 사용자에 대한 보안 조치)
    - 사용자 지정 권한 부여자 (자체 로직을 실행)
  - 사용자 지정 도메인 이름 HTTPS 를 ACM과 통합할 수 있음
    - 엣지 최적화 엔드포인트를 사용할 경우 인증서는 us-east-1에 있어야 함
    - 리전 엔드포인트를 사용한다면 인증서는 API Gateway 단계와 동일한 리전에 있어야 함
    - Route 53에 CNAME이나 A-별칭 레코드를 설정해 도메인 및 API Gateway를 가르키도록 해야 함



### Step Functions

- AWS Step Functions
  - 서버리스 워크플로우를 시각적으로 구성할 수 있는 기능
  - 주로 람다 함수를 오케스트레이션 하는 데 활용
  - 기능: 시퀀싱, 병행 실핼, 조건 설정, 타임아웃, 에러 처리 등
  - 람다 함수만 처리하는 게 아니라 EC2와도 연동할 수 있고, ECS, 온프레미스 서버, API Gateway, SQS 큐 등 다양한 AWS 서비스를 워크플로우에 넣을 수 있음
  - 워크플로우에 사람이 개입해서 승인을 해야만 진행되는 단계를 설정할 수 있음
  - 사용 사례: 주문 이행, 데이터 처리, 웹 애플리케이션 등 구성하기 복잡한 워크플로우를 시각적으로 구성하려고 할 때



### Amazon Cognito 개요

- Amazon Cognito

  - 사용자에게 웹 및 모바일 앱과 상호 작용할 수 있는 자격 증명을 부여
  - Congnito 사용자 풀
    - 앱 사용자에게 가입 기능을 제공
    - API Gateway 및 애플리케이션 로드 밸런서와 원활히 통합됨
  - Congnito 자격 증명 풀 (Federated Identity)
    - 앱에 등록된 사용자에게 임시 AWS 자격 증명을 제공해서 일부 AWS 리소스에 직접 액세스할 수 있도록 해 줌
    - Cognito 사용자 풀과 원활히 통합됨
  - Congnito vs IAM: Congnito는 AWS 외부의 웹과 모바일 앱 사용자를 대상으로 함

- Cognito User Pools (CUP) 

  - 앱 및 모바일 앱을 대상으로 하는 서버리스 사용자 데이터베이스
  - 간단한 로그인 절차: 사용자 이름 (또는 이메일) / 비밀번호의 조합
  - 비밀번호 재설정 기능
  - 이메일 & 전화번호 검증 기능
  - 사용자 멀티팩터 인증 가능
  - Facebook, Goole, SAML과 통합 가능 (소셜 로그인)

  - CUP 통합은 API 게이트웨이, 애플리케이션 로드 밸런서와 통합됨

- Cognito Identity Pools (Faderated Identities)

  - 사용자에게 자격증명을 제공하지만 API Gateway나 애플리케이션 로드 밸런서를 통해서 애플리케이션에 액세스하지 않고 임시 AWS 자격 증명을 사용해 AWS 계정에 직접 액세스
  - 사용자는 Congnito 사용자 풀 내의 사용자가 될 수도 있고 타사 로그인이될 수도 있음
  - 직접 또는 API Gateway를 통해 서비스에 액세스할 수도 있음
  - 자격 증명에 적용되는 IAM 정책은 Cognito 자격 증명 풀 서비스에 사전 정의되어 있음
  - user_id를 기반으로 사용자 정의하여 세분화된 제어를 할 수도 있음
  - 원한다면 기본 IAM 역할을 정의할 수도 있음

- Cognito Identity Pools 행 수준 보안 (Row Level Security) in DynamoDB

  - 세분화된 액세스 제어를 통해 DynamoDB에서 행 수준 보안을 활성화 가능

